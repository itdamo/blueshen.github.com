<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>申艳超-博客</title>
  <subtitle>搜索引擎、自然语言处理、ElasticSearch、Solr</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://www.shenyanchao.cn/"/>
  <updated>2018-12-26T08:49:35.141Z</updated>
  <id>https://www.shenyanchao.cn/</id>
  
  <author>
    <name>申艳超</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>redis-IO模型</title>
    <link href="https://www.shenyanchao.cn/blog/2018/12/26/redis-io/"/>
    <id>https://www.shenyanchao.cn/blog/2018/12/26/redis-io/</id>
    <published>2018-12-26T07:18:49.000Z</published>
    <updated>2018-12-26T08:49:35.141Z</updated>
    
    <content type="html"><![CDATA[<p>TODO</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;TODO&lt;/p&gt;

    
    </summary>
    
      <category term="redis" scheme="https://www.shenyanchao.cn/categories/redis/"/>
    
    
      <category term="epoll" scheme="https://www.shenyanchao.cn/tags/epoll/"/>
    
      <category term="io" scheme="https://www.shenyanchao.cn/tags/io/"/>
    
      <category term="redis" scheme="https://www.shenyanchao.cn/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>Redis过期机制</title>
    <link href="https://www.shenyanchao.cn/blog/2018/12/26/redis-expire/"/>
    <id>https://www.shenyanchao.cn/blog/2018/12/26/redis-expire/</id>
    <published>2018-12-26T06:28:52.000Z</published>
    <updated>2018-12-26T08:49:01.080Z</updated>
    
    <content type="html"><![CDATA[<p>TODO</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;TODO&lt;/p&gt;

    
    </summary>
    
      <category term="redis" scheme="https://www.shenyanchao.cn/categories/redis/"/>
    
    
      <category term="redis" scheme="https://www.shenyanchao.cn/tags/redis/"/>
    
      <category term="expire" scheme="https://www.shenyanchao.cn/tags/expire/"/>
    
      <category term="lru" scheme="https://www.shenyanchao.cn/tags/lru/"/>
    
  </entry>
  
  <entry>
    <title>什么是epoll?</title>
    <link href="https://www.shenyanchao.cn/blog/2018/12/25/epoll/"/>
    <id>https://www.shenyanchao.cn/blog/2018/12/25/epoll/</id>
    <published>2018-12-25T02:54:24.000Z</published>
    <updated>2018-12-26T08:46:39.533Z</updated>
    
    <content type="html"><![CDATA[<p>同步IO和异步IO，阻塞IO和非阻塞IO分别是什么，到底有什么区别？不同的人在不同的上下文下给出的答案是不同的。所以先限定一下本文的上下文。</p>
<p>本文讨论的背景是Linux环境下的network IO。</p>
<h1 id="一-概念说明"><a href="#一-概念说明" class="headerlink" title="一 概念说明"></a>一 概念说明</h1><p>在进行解释之前，首先要说明几个概念：</p>
<ul>
<li>用户空间和内核空间</li>
<li>进程切换</li>
<li>进程的阻塞</li>
<li>文件描述符</li>
<li>缓存 I/O</li>
</ul>
<h2 id="用户空间与内核空间"><a href="#用户空间与内核空间" class="headerlink" title="用户空间与内核空间"></a>用户空间与内核空间</h2><p>现在操作系统都是采用虚拟存储器，那么对32位操作系统而言，它的寻址空间（虚拟存储空间）为4G（2的32次方）。操作系统的核心是内核，独立于普通的应用程序，可以访问受保护的内存空间，也有访问底层硬件设备的所有权限。为了保证用户进程不能直接操作内核（kernel），保证内核的安全，操心系统将虚拟空间划分为两部分，一部分为内核空间，一部分为用户空间。针对linux操作系统而言，将最高的1G字节（从虚拟地址0xC0000000到0xFFFFFFFF），供内核使用，称为内核空间，而将较低的3G字节（从虚拟地址0x00000000到0xBFFFFFFF），供各个进程使用，称为用户空间。</p>
<h2 id="进程切换"><a href="#进程切换" class="headerlink" title="进程切换"></a>进程切换</h2><p>为了控制进程的执行，内核必须有能力挂起正在CPU上运行的进程，并恢复以前挂起的某个进程的执行。这种行为被称为进程切换。因此可以说，任何进程都是在操作系统内核的支持下运行的，是与内核紧密相关的。</p>
<p>从一个进程的运行转到另一个进程上运行，这个过程中经过下面这些变化：</p>
<ol>
<li>保存处理机上下文，包括程序计数器和其他寄存器。</li>
<li>更新PCB信息。</li>
<li>把进程的PCB移入相应的队列，如就绪、在某事件阻塞等队列。</li>
<li>选择另一个进程执行，并更新其PCB。</li>
<li>更新内存管理的数据结构。</li>
<li>恢复处理机上下文。</li>
</ol>
<p>注：<strong>总而言之就是很耗资源</strong>，具体的可以参考这篇文章：<a href="http://guojing.me/linux-kernel-architecture/posts/process-switch/" target="_blank" rel="external">进程切换</a></p>
<h2 id="进程的阻塞"><a href="#进程的阻塞" class="headerlink" title="进程的阻塞"></a>进程的阻塞</h2><p>正在执行的进程，由于期待的某些事件未发生，如请求系统资源失败、等待某种操作的完成、新数据尚未到达或无新工作做等，则由系统自动执行阻塞原语(Block)，使自己由运行状态变为阻塞状态。可见，进程的阻塞是进程自身的一种主动行为，也因此只有处于运行态的进程（获得CPU），才可能将其转为阻塞状态。<code>当进程进入阻塞状态，是不占用CPU资源的</code>。</p>
<h2 id="文件描述符fd"><a href="#文件描述符fd" class="headerlink" title="文件描述符fd"></a>文件描述符fd</h2><p>文件描述符（File descriptor）是计算机科学中的一个术语，是一个用于表述指向文件的引用的抽象化概念。</p>
<p>文件描述符在形式上是一个非负整数。实际上，它是一个索引值，指向内核为每一个进程所维护的该进程打开文件的记录表。当程序打开一个现有文件或者创建一个新文件时，内核向进程返回一个文件描述符。在程序设计中，一些涉及底层的程序编写往往会围绕着文件描述符展开。但是文件描述符这一概念往往只适用于UNIX、Linux这样的操作系统。</p>
<h2 id="缓存-I-O"><a href="#缓存-I-O" class="headerlink" title="缓存 I/O"></a>缓存 I/O</h2><p>缓存 I/O 又被称作标准 I/O，大多数文件系统的默认 I/O 操作都是缓存 I/O。在 Linux 的缓存 I/O 机制中，操作系统会将 I/O 的数据缓存在文件系统的页缓存（ page cache ）中，也就是说，数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。</p>
<p><strong>缓存 I/O 的缺点：</strong><br>数据在传输过程中需要在应用程序地址空间和内核进行多次数据拷贝操作，这些数据拷贝操作所带来的 CPU 以及内存开销是非常大的。</p>
<h1 id="二-IO模式"><a href="#二-IO模式" class="headerlink" title="二 IO模式"></a>二 IO模式</h1><p>刚才说了，对于一次IO访问（以read举例），数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。所以说，当一个read操作发生时，它会经历两个阶段：<br>\1. 等待数据准备 (Waiting for the data to be ready)<br>\2. 将数据从内核拷贝到进程中 (Copying the data from the kernel to the process)</p>
<p>正式因为这两个阶段，linux系统产生了下面五种网络模式的方案。</p>
<ul>
<li>阻塞 I/O（blocking IO）</li>
<li>非阻塞 I/O（nonblocking IO）</li>
<li>I/O 多路复用（ IO multiplexing）</li>
<li>信号驱动 I/O（ signal driven IO）</li>
<li>异步 I/O（asynchronous IO）</li>
</ul>
<p>注：由于signal driven IO在实际中并不常用，所以我这只提及剩下的四种IO Model。</p>
<h2 id="阻塞-I-O（blocking-IO）"><a href="#阻塞-I-O（blocking-IO）" class="headerlink" title="阻塞 I/O（blocking IO）"></a>阻塞 I/O（blocking IO）</h2><p>在linux中，默认情况下所有的socket都是blocking，一个典型的读操作流n程大概是这样：<br><img src="/images/epoll/blocking-io.png" alt="blocking IO"></p>
<p>当用户进程调用了recvfrom这个系统调用，kernel就开始了IO的第一个阶段：准备数据（对于网络IO来说，很多时候数据在一开始还没有到达。比如，还没有收到一个完整的UDP包。这个时候kernel就要等待足够的数据到来）。这个过程需要等待，也就是说数据被拷贝到操作系统内核的缓冲区中是需要一个过程的。而在用户进程这边，整个进程会被阻塞（当然，是进程自己选择的阻塞）。当kernel一直等到数据准备好了，它就会将数据从kernel中拷贝到用户内存，然后kernel返回结果，用户进程才解除block的状态，重新运行起来。</p>
<blockquote>
<p>所以，blocking IO的特点就是在IO执行的两个阶段都被block了。</p>
</blockquote>
<h2 id="非阻塞-I-O（nonblocking-IO）"><a href="#非阻塞-I-O（nonblocking-IO）" class="headerlink" title="非阻塞 I/O（nonblocking IO）"></a>非阻塞 I/O（nonblocking IO）</h2><p>linux下，可以通过设置socket使其变为non-blocking。当对一个non-blocking socket执行读操作时，流程是这个样子：<br><img src="/images/epoll/non-blocking-io.png" alt="非阻塞 I/O"></p>
<p>当用户进程发出read操作时，如果kernel中的数据还没有准备好，那么它并不会block用户进程，而是立刻返回一个error。从用户进程角度io讲 ，它发起一个read操作后，并不需要等待，而是马上就得到了一个结果。用户进程判断结果是一个error时，它就知道数据还没有准备好，于是它可以再次发送read操作。一旦kernel中的数据准备好了，并且又再次收到了用户进程的system call，那么它马上就将数据拷贝到了用户内存，然后返回。</p>
<blockquote>
<p>所以，nonblocking IO的特点是用户进程需要<strong>不断的主动询问</strong>kernel数据好了没有。</p>
</blockquote>
<h2 id="I-O-多路复用（-IO-multiplexing）"><a href="#I-O-多路复用（-IO-multiplexing）" class="headerlink" title="I/O 多路复用（ IO multiplexing）"></a>I/O 多路复用（ IO multiplexing）</h2><p>IO multiplexing就是我们说的select，poll，epoll，有些地方也称这种IO方式为event driven IO。select/epoll的好处就在于单个process就可以同时处理多个网络连接的IO。它的基本原理就是select，poll，epoll这个function会不断的轮询所负责的所有socket，当某个socket有数据到达了，就通知用户进程。</p>
<p><img src="/images/epoll/io-multiplexing.png" alt="I/O多路复用"></p>
<p><code>当用户进程调用了select，那么整个进程会被block</code>，而同时，kernel会“监视”所有select负责的socket，当任何一个socket中的数据准备好了，select就会返回。这个时候用户进程再调用read操作，将数据从kernel拷贝到用户进程。</p>
<blockquote>
<p>所以，I/O 多路复用的特点是通过一种机制一个进程能同时等待多个文件描述符，而这些文件描述符（套接字描述符）其中的a任意一个进入读就绪状态，select()函数就可以返回。</p>
</blockquote>
<p>这个图和blocking IO的图其实并没有太大的不同，事实上，还更差一些。因为这里需要使用两个system call (select 和 recvfrom)，而blocking IO只调用了一个system call (recvfrom)。但是，用select的优势在于它可以同时处理多个connection。</p>
<p>所以，如果处理的连接数不是很高的话，使用select/epoll的web server不一定比使用multi-threading + blocking IO的web server性能更好，可能延迟还更大。select/epoll的优势并不是对于单个连接能处理得更快，而是在于能处理更多的连接。）</p>
<p>在IO multiplexing Model中，实际中，对于每一个socket，一般都设置成为non-blocking，但是，如上图所示，整个用户的process其实是一直被block的。只不过process是被select这个函数block，而不是被socket IO给block。</p>
<h2 id="异步-I-O（asynchronous-IO）"><a href="#异步-I-O（asynchronous-IO）" class="headerlink" title="异步 I/O（asynchronous IO）"></a>异步 I/O（asynchronous IO）</h2><p>Linux下的asynchronous IO其实用得很少。先看一下它的流程：<br><img src="/images/epoll/async-io.png" alt="异步IO"></p>
<p>I用户进程发起read操作之后，立刻就可以开始去做其它的事。而另一方面，从kernel的角度，当它受到一个asynchronous read之后，首先它会立刻返回，所以不会对用户进程产生任何block。然后，kernel会等待数据准备完成，然后将数据拷贝到用户内存，当这一切都完成之后，kernel会给用户进程发送一个signal，告诉它read操作完成了。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><h3 id="blocking和non-blocking的区别"><a href="#blocking和non-blocking的区别" class="headerlink" title="blocking和non-blocking的区别"></a>blocking和non-blocking的区别</h3><p>调用blocking IO会一直block住对应的进程直到操作完成，而non-blocking IO在kernel还准备数据的情况下会立刻返回。</p>
<h3 id="synchronous-IO和asynchronous-IO的区别"><a href="#synchronous-IO和asynchronous-IO的区别" class="headerlink" title="synchronous IO和asynchronous IO的区别"></a>synchronous IO和asynchronous IO的区别</h3><p>在说明synchronous IO和asynchronous IO的区别之前，需要先给出两者的定义。POSIX的定义是这样子的：<br>- A synchronous I/O operation causes the requesting process to be blocked until that I/O operation completes;<br>- An asynchronous I/O operation does not cause the requesting process to be blocked;</p>
<p>两者的区别就在于synchronous IO做”IO operation”的时候会将process阻塞。按照这个定义，之前所述的blocking IO，non-blocking IO，IO multiplexing都属于synchronous IO。</p>
<p>有人会说，non-blocking IO并没有被block啊。这里有个非常“狡猾”的地方，定义中所指的”IO operation”是指真实的IO操作，就是例子中的recvfrom这个system call。non-blocking IO在执行recvfrom这个system call的时候，如果kernel的数据没有准备好，这时候不会block进程。但是，当kernel中数据准备好的时候，recvfrom会将数据从kernel拷贝到用户内存中，这个时候进程是被block了，在这段时间内，进程是被block的。</p>
<p>而asynchronous IO则不一样，当进程发起IO 操作之后，就直接返回再也不理睬了，直到kernel发送一个信号，告诉进程说IO完成。在这整个过程中，进程完全没有被block。</p>
<p><strong>各个IO Model的比较如图所示：</strong><br><img src="/images/epoll/io-model-pk.png" alt="IO模型对比"></p>
<p>通过上面的图片，可以发现non-blocking IO和asynchronous IO的区别还是很明显的。在non-blocking IO中，虽然进程大部分时间都不会被block，但是它仍然要求进程去主动的check，并且当数据准备完成以后，也需要进程主动的再次调用recvfrom来将数据拷贝到用户内存。而asynchronous IO则完全不同。它就像是用户进程将整个IO操作交给了他人（kernel）完成，然后他人做完后发信号通知。在此期间，用户进程不需要去检查IO操作的状态，也不需要主动的去拷贝数据。</p>
<h1 id="三-I-O-多路复用之select、poll、epoll详解"><a href="#三-I-O-多路复用之select、poll、epoll详解" class="headerlink" title="三 I/O 多路复用之select、poll、epoll详解"></a>三 I/O 多路复用之select、poll、epoll详解</h1><p>select，poll，epoll都是IO多路复用的机制。I/O多路复用就是通过一种机制，一个进程可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。但select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。（这里啰嗦下）</p>
<h2 id="select"><a href="#select" class="headerlink" title="select"></a>select</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">int select (int n, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout);</div></pre></td></tr></table></figure>
<p>select 函数监视的文件描述符分3类，分别是writefds、readfds、和exceptfds。调用后select函数会阻塞，直到有描述副就绪（有数据 可读、可写、或者有except），或者超时（timeout指定等待时间，如果立即返回设为null即可），函数返回。当select函数返回后，可以 通过遍历fdset，来找到就绪的描述符。</p>
<p>select目前几乎在所有的平台上支持，其良好跨平台支持也是它的一个优点。select的一 个缺点在于单个进程能够监视的文件描述符的数量存在最大限制，在Linux上一般为1024，可以通过修改宏定义甚至重新编译内核的方式提升这一限制，但 是这样也会造成效率的降低。</p>
<h2 id="poll"><a href="#poll" class="headerlink" title="poll"></a>poll</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">int poll (struct pollfd *fds, unsigned int nfds, int timeout);</div></pre></td></tr></table></figure>
<p>不同与select使用三个位图来表示三个fdset的方式，poll使用一个 pollfd的指针实现。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">struct pollfd &#123;</div><div class="line">    int fd; /* file descriptor */</div><div class="line">    short events; /* requested events to watch */</div><div class="line">    short revents; /* returned events witnessed */</div><div class="line">&#125;;</div></pre></td></tr></table></figure>
<p>pollfd结构包含了要监视的event和发生的event，不再使用select“参数-值”传递的方式。同时，pollfd并没有最大数量限制（但是数量过大后性能也是会下降）。 和select函数一样，poll返回后，需要轮询pollfd来获取就绪的描述符。</p>
<blockquote>
<p>从上面看，select和poll都需要在返回后，<code>通过遍历文件描述符来获取已经就绪的socket</code>。事实上，同时连接的大量客户端在一时刻可能只有很少的处于就绪状态，因此随着监视的描述符数量的增长，其效率也会线性下降。</p>
</blockquote>
<h2 id="epoll"><a href="#epoll" class="headerlink" title="epoll"></a>epoll</h2><p>epoll是在2.6内核中提出的，是之前的select和poll的增强版本。相对于select和poll来说，epoll更加灵活，没有描述符限制。epoll使用一个文件描述符管理多个描述符，将用户关系的文件描述符的事件存放到内核的一个事件表中，这样在用户空间和内核空间的copy只需一次。</p>
<h3 id="一-epoll操作过程"><a href="#一-epoll操作过程" class="headerlink" title="一 epoll操作过程"></a>一 epoll操作过程</h3><p>epoll操作过程需要三个接口，分别如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">int epoll_create(int size)；//创建一个epoll的句柄，size用来告诉内核这个监听的数目一共有多大</div><div class="line">int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)；</div><div class="line">int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout);</div></pre></td></tr></table></figure>
<p><strong>1. int epoll_create(int size);</strong><br>创建一个epoll的句柄，size用来告诉内核这个监听的数目一共有多大，这个参数不同于select()中的第一个参数，给出最大监听的fd+1的值，<code>参数size并不是限制了epoll所能监听的描述符最大个数，只是对内核初始分配内部数据结构的一个建议</code>。<br>当创建好epoll句柄后，它就会占用一个fd值，在linux下如果查看/proc/进程id/fd/，是能够看到这个fd的，所以在使用完epoll后，必须调用close()关闭，否则可能导致fd被耗尽。</p>
<p><strong>2. int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)；</strong><br>函数是对指定描述符fd执行op操作。</p>
<ul>
<li>epfd：是epoll_create()的返回值。</li>
<li>op：表示op操作，用三个宏来表示：添加EPOLL_CTL_ADD，删除EPOLL_CTL_DEL，修改EPOLL_CTL_MOD。分别添加、删除和修改对fd的监听事件。</li>
<li>fd：是需要监听的fd（文件描述符）</li>
<li>epoll_event：是告诉内核需要监听什么事，struct epoll_event结构如下：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">struct epoll_event &#123;</div><div class="line">  __uint32_t events;  /* Epoll events */</div><div class="line">  epoll_data_t data;  /* User data variable */</div><div class="line">&#125;;</div></pre></td></tr></table></figure>
<p>events可以是以下几个宏的集合：<br>EPOLLIN ：表示对应的文件描述符可以读（包括对端SOCKET正常关闭）；<br>EPOLLOUT：表示对应的文件描述符可以写；<br>EPOLLPRI：表示对应的文件描述符有紧急的数据可读（这里应该表示有带外数据到来）；<br>EPOLLERR：表示对应的文件描述符发生错误；<br>EPOLLHUP：表示对应的文件描述符被挂断；<br>EPOLLET： 将EPOLL设为边缘触发(Edge Triggered)模式，这是相对于水平触发(Level Triggered)来说的。<br>EPOLLONESHOT：只监听一次事件，当监听完这次事件之后，如果还需要继续监听这个socket的话，需要再次把这个socket加入到EPOLL队列里</p>
<p><strong>3. int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout);</strong><br>等待epfd上的io事件，最多返回maxevents个事件。<br>参数events用来从内核得到事件的集合，maxevents告之内核这个events有多大，这个maxevents的值不能大于创建epoll_create()时的size，参数timeout是超时时间（毫秒，0会立即返回，-1将不确定，也有说法说是永久阻塞）。该函数返回需要处理的事件数目，如返回0表示已超时。</p>
<h3 id="二-工作模式"><a href="#二-工作模式" class="headerlink" title="二 工作模式"></a>二 工作模式</h3><p>　epoll对文件描述符的操作有两种模式：<strong>LT（level trigger）</strong>和<strong>ET（edge trigger）</strong>。LT模式是默认模式，LT模式与ET模式的区别如下：<br>　　<strong>LT模式</strong>：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，<code>应用程序可以不立即处理该事件</code>。下次调用epoll_wait时，会再次响应应用程序并通知此事件。<br>　　<strong>ET模式</strong>：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，<code>应用程序必须立即处理该事件</code>。如果不处理，下次调用epoll_wait时，不会再次响应应用程序并通知此事件。</p>
<h4 id="1-LT模式"><a href="#1-LT模式" class="headerlink" title="1. LT模式"></a>1. LT模式</h4><p>LT(level triggered)是缺省的工作方式，并且同时支持block和no-block socket.在这种做法中，内核告诉你一个文件描述符是否就绪了，然后你可以对这个就绪的fd进行IO操作。如果你不作任何操作，内核还是会继续通知你的。</p>
<h4 id="2-ET模式"><a href="#2-ET模式" class="headerlink" title="2. ET模式"></a>2. ET模式</h4><p>ET(edge-triggered)是高速工作方式，只支持no-block socket。在这种模式下，当描述符从未就绪变为就绪时，内核通过epoll告诉你。然后它会假设你知道文件描述符已经就绪，并且不会再为那个文件描述符发送更多的就绪通知，直到你做了某些操作导致那个文件描述符不再为就绪状态了(比如，你在发送，接收或者接收请求，或者发送接收的数据少于一定量时导致了一个EWOULDBLOCK 错误）。但是请注意，如果一直不对这个fd作IO操作(从而导致它再次变成未就绪)，内核不会发送更多的通知(only once)</p>
<p>ET模式在很大程度上减少了epoll事件被重复触发的次数，因此效率要比LT模式高。epoll工作在ET模式的时候，必须使用非阻塞套接口，以避免由于一个文件句柄的阻塞读/阻塞写操作把处理多个文件描述符的任务饿死。</p>
<h4 id="3-总结"><a href="#3-总结" class="headerlink" title="3. 总结"></a>3. 总结</h4><p>假如有这样一个例子：</p>
<ol>
<li>我们已经把一个用来从管道中读取数据的文件句柄(RFD)添加到epoll描述符</li>
<li>这个时候从管道的另一端被写入了2KB的数据</li>
<li>调用epoll_wait(2)，并且它会返回RFD，说明它已经准备好读取操作</li>
<li>然后我们读取了1KB的数据</li>
<li>调用epoll_wait(2)……</li>
</ol>
<p><strong>LT模式：</strong><br>如果是LT模式，那么在第5步调用epoll_wait(2)之后，仍然能受到通知。</p>
<p><strong>ET模式：</strong><br>如果我们在第1步将RFD添加到epoll描述符的时候使用了EPOLLET标志，那么在第5步调用epoll_wait(2)之后将有可能会挂起，因为剩余的数据还存在于文件的输入缓冲区内，而且数据发出端还在等待一个针对已经发出数据的反馈信息。只有在监视的文件句柄上发生了某个事件的时候 ET 工作模式才会汇报事件。因此在第5步的时候，调用者可能会放弃等待仍在存在于文件输入缓冲区内的剩余数据。</p>
<p>当使用epoll的ET模型来工作时，当产生了一个EPOLLIN事件后，<br>读数据的时候需要考虑的是当recv()返回的大小如果等于请求的大小，那么很有可能是缓冲区还有数据未读完，也意味着该次事件还没有处理完，所以还需要再次读取：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line">while(rs)&#123;</div><div class="line">  buflen = recv(activeevents[i].data.fd, buf, sizeof(buf), 0);</div><div class="line">  if(buflen &lt; 0)&#123;</div><div class="line">    // 由于是非阻塞的模式,所以当errno为EAGAIN时,表示当前缓冲区已无数据可读</div><div class="line">    // 在这里就当作是该次事件已处理处.</div><div class="line">    if(errno == EAGAIN)&#123;</div><div class="line">        break;</div><div class="line">    &#125;</div><div class="line">    else&#123;</div><div class="line">        return;</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">  else if(buflen == 0)&#123;</div><div class="line">     // 这里表示对端的socket已正常关闭.</div><div class="line">  &#125;</div><div class="line"></div><div class="line"> if(buflen == sizeof(buf)&#123;</div><div class="line">      rs = 1;   // 需要再次读取</div><div class="line"> &#125;</div><div class="line"> else&#123;</div><div class="line">      rs = 0;</div><div class="line"> &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<blockquote>
<p><strong>Linux中的EAGAIN含义</strong></p>
</blockquote>
<p>Linux环境下开发经常会碰到很多错误(设置errno)，其中EAGAIN是其中比较常见的一个错误(比如用在非阻塞操作中)。<br>从字面上来看，是提示再试一次。这个错误经常出现在当应用程序进行一些非阻塞(non-blocking)操作(对文件或socket)的时候。</p>
<p>例如，以 O_NONBLOCK的标志打开文件/socket/FIFO，如果你连续做read操作而没有数据可读。此时程序不会阻塞起来等待数据准备就绪返回，read函数会返回一个错误EAGAIN，提示你的应用程序现在没有数据可读请稍后再试。<br>又例如，当一个系统调用(比如fork)因为没有足够的资源(比如虚拟内存)而执行失败，返回EAGAIN提示其再调用一次(也许下次就能成功)。</p>
<h3 id="三-代码演示"><a href="#三-代码演示" class="headerlink" title="三 代码演示"></a>三 代码演示</h3><p>下面是一段不完整的代码且格式不对，意在表述上面的过程，去掉了一些模板代码。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#<span class="meta-keyword">define</span> IPADDRESS   <span class="meta-string">"127.0.0.1"</span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">define</span> PORT        8787</span></div><div class="line"><span class="meta">#<span class="meta-keyword">define</span> MAXSIZE     1024</span></div><div class="line"><span class="meta">#<span class="meta-keyword">define</span> LISTENQ     5</span></div><div class="line"><span class="meta">#<span class="meta-keyword">define</span> FDSIZE      1000</span></div><div class="line"><span class="meta">#<span class="meta-keyword">define</span> EPOLLEVENTS 100</span></div><div class="line"></div><div class="line">listenfd = socket_bind(IPADDRESS,PORT);</div><div class="line"></div><div class="line"><span class="keyword">struct</span> epoll_event events[EPOLLEVENTS];</div><div class="line"></div><div class="line"><span class="comment">//创建一个描述符</span></div><div class="line">epollfd = epoll_create(FDSIZE);</div><div class="line"></div><div class="line"><span class="comment">//添加监听描述符事件</span></div><div class="line">add_event(epollfd,listenfd,EPOLLIN);</div><div class="line"></div><div class="line"><span class="comment">//循环等待</span></div><div class="line"><span class="keyword">for</span> ( ; ; )&#123;</div><div class="line">    <span class="comment">//该函数返回已经准备好的描述符事件数目</span></div><div class="line">    ret = epoll_wait(epollfd,events,EPOLLEVENTS,<span class="number">-1</span>);</div><div class="line">    <span class="comment">//处理接收到的连接</span></div><div class="line">    handle_events(epollfd,events,ret,listenfd,buf);</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">//事件处理函数</span></div><div class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">handle_events</span><span class="params">(<span class="keyword">int</span> epollfd,<span class="keyword">struct</span> epoll_event *events,<span class="keyword">int</span> num,<span class="keyword">int</span> listenfd,<span class="keyword">char</span> *buf)</span></span></div><div class="line">&#123;</div><div class="line">     <span class="keyword">int</span> i;</div><div class="line">     <span class="keyword">int</span> fd;</div><div class="line">     <span class="comment">//进行遍历;这里只要遍历已经准备好的io事件。num并不是当初epoll_create时的FDSIZE。</span></div><div class="line">     <span class="keyword">for</span> (i = <span class="number">0</span>;i &lt; num;i++)</div><div class="line">     &#123;</div><div class="line">         fd = events[i].data.fd;</div><div class="line">        <span class="comment">//根据描述符的类型和事件类型进行处理</span></div><div class="line">         <span class="keyword">if</span> ((fd == listenfd) &amp;&amp;(events[i].events &amp; EPOLLIN))</div><div class="line">            handle_accpet(epollfd,listenfd);</div><div class="line">         <span class="keyword">else</span> <span class="keyword">if</span> (events[i].events &amp; EPOLLIN)</div><div class="line">            do_read(epollfd,fd,buf);</div><div class="line">         <span class="keyword">else</span> <span class="keyword">if</span> (events[i].events &amp; EPOLLOUT)</div><div class="line">            do_write(epollfd,fd,buf);</div><div class="line">     &#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">//添加事件</span></div><div class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">add_event</span><span class="params">(<span class="keyword">int</span> epollfd,<span class="keyword">int</span> fd,<span class="keyword">int</span> state)</span></span>&#123;</div><div class="line">    <span class="keyword">struct</span> epoll_event ev;</div><div class="line">    ev.events = state;</div><div class="line">    ev.data.fd = fd;</div><div class="line">    epoll_ctl(epollfd,EPOLL_CTL_ADD,fd,&amp;ev);</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">//处理接收到的连接</span></div><div class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">handle_accpet</span><span class="params">(<span class="keyword">int</span> epollfd,<span class="keyword">int</span> listenfd)</span></span>&#123;</div><div class="line">     <span class="keyword">int</span> clifd;     </div><div class="line">     <span class="keyword">struct</span> sockaddr_in cliaddr;     </div><div class="line">     <span class="keyword">socklen_t</span>  cliaddrlen;     </div><div class="line">     clifd = accept(listenfd,(<span class="keyword">struct</span> sockaddr*)&amp;cliaddr,&amp;cliaddrlen);     </div><div class="line">     <span class="keyword">if</span> (clifd == <span class="number">-1</span>)         </div><div class="line">     perror(<span class="string">"accpet error:"</span>);     </div><div class="line">     <span class="keyword">else</span> &#123;         </div><div class="line">         <span class="built_in">printf</span>(<span class="string">"accept a new client: %s:%d\n"</span>,inet_ntoa(cliaddr.sin_addr),cliaddr.sin_port);                       <span class="comment">//添加一个客户描述符和事件         </span></div><div class="line">         add_event(epollfd,clifd,EPOLLIN);     </div><div class="line">     &#125; </div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">//读处理</span></div><div class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">do_read</span><span class="params">(<span class="keyword">int</span> epollfd,<span class="keyword">int</span> fd,<span class="keyword">char</span> *buf)</span></span>&#123;</div><div class="line">    <span class="keyword">int</span> nread;</div><div class="line">    nread = read(fd,buf,MAXSIZE);</div><div class="line">    <span class="keyword">if</span> (nread == <span class="number">-1</span>)     &#123;         </div><div class="line">        perror(<span class="string">"read error:"</span>);         </div><div class="line">        close(fd); <span class="comment">//记住close fd        </span></div><div class="line">        delete_event(epollfd,fd,EPOLLIN); <span class="comment">//删除监听 </span></div><div class="line">    &#125;</div><div class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (nread == <span class="number">0</span>)     &#123;         </div><div class="line">        <span class="built_in">fprintf</span>(<span class="built_in">stderr</span>,<span class="string">"client close.\n"</span>);</div><div class="line">        close(fd); <span class="comment">//记住close fd       </span></div><div class="line">        delete_event(epollfd,fd,EPOLLIN); <span class="comment">//删除监听 </span></div><div class="line">    &#125;     </div><div class="line">    <span class="keyword">else</span> &#123;         </div><div class="line">        <span class="built_in">printf</span>(<span class="string">"read message is : %s"</span>,buf);        </div><div class="line">        <span class="comment">//修改描述符对应的事件，由读改为写         </span></div><div class="line">        modify_event(epollfd,fd,EPOLLOUT);     </div><div class="line">    &#125; </div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">//写处理</span></div><div class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">do_write</span><span class="params">(<span class="keyword">int</span> epollfd,<span class="keyword">int</span> fd,<span class="keyword">char</span> *buf)</span> </span>&#123;     </div><div class="line">    <span class="keyword">int</span> nwrite;     </div><div class="line">    nwrite = write(fd,buf,<span class="built_in">strlen</span>(buf));     </div><div class="line">    <span class="keyword">if</span> (nwrite == <span class="number">-1</span>)&#123;         </div><div class="line">        perror(<span class="string">"write error:"</span>);        </div><div class="line">        close(fd);   <span class="comment">//记住close fd       </span></div><div class="line">        delete_event(epollfd,fd,EPOLLOUT);  <span class="comment">//删除监听    </span></div><div class="line">    &#125;<span class="keyword">else</span>&#123;</div><div class="line">        modify_event(epollfd,fd,EPOLLIN); </div><div class="line">    &#125;    </div><div class="line">    <span class="built_in">memset</span>(buf,<span class="number">0</span>,MAXSIZE); </div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">//删除事件</span></div><div class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">delete_event</span><span class="params">(<span class="keyword">int</span> epollfd,<span class="keyword">int</span> fd,<span class="keyword">int</span> state)</span> </span>&#123;</div><div class="line">    <span class="keyword">struct</span> epoll_event ev;</div><div class="line">    ev.events = state;</div><div class="line">    ev.data.fd = fd;</div><div class="line">    epoll_ctl(epollfd,EPOLL_CTL_DEL,fd,&amp;ev);</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">//修改事件</span></div><div class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">modify_event</span><span class="params">(<span class="keyword">int</span> epollfd,<span class="keyword">int</span> fd,<span class="keyword">int</span> state)</span></span>&#123;     </div><div class="line">    <span class="keyword">struct</span> epoll_event ev;</div><div class="line">    ev.events = state;</div><div class="line">    ev.data.fd = fd;</div><div class="line">    epoll_ctl(epollfd,EPOLL_CTL_MOD,fd,&amp;ev);</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">//注：另外一端我就省了</span></div></pre></td></tr></table></figure>
<h3 id="四-epoll总结"><a href="#四-epoll总结" class="headerlink" title="四 epoll总结"></a>四 epoll总结</h3><p>在 select/poll中，进程只有在调用一定的方法后，内核才对所有监视的文件描述符进行扫描，而<strong>epoll事先通过epoll_ctl()来注册一 个文件描述符，一旦基于某个文件描述符就绪时，内核会采用类似callback的回调机制，迅速激活这个文件描述符，当进程调用epoll_wait() 时便得到通知</strong>。(<code>此处去掉了遍历文件描述符，而是通过监听回调的的机制</code>。这正是epoll的魅力所在。)</p>
<p><strong>epoll的优点主要是一下几个方面：</strong></p>
<ol>
<li><p>监视的描述符数量不受限制，它所支持的FD上限是最大可以打开文件的数目，这个数字一般远大于2048,举个例子,在1GB内存的机器上大约是10万左 右，具体数目可以cat /proc/sys/fs/file-max察看,一般来说这个数目和系统内存关系很大。select的最大缺点就是进程打开的fd是有数量限制的。这对 于连接数量比较大的服务器来说根本不能满足。虽然也可以选择多进程的解决方案( Apache就是这样实现的)，不过虽然linux上面创建进程的代价比较小，但仍旧是不可忽视的，加上进程间数据同步远比不上线程间同步的高效，所以也不是一种完美的方案。</p>
</li>
<li><p>IO的效率不会随着监视fd的数量的增长而下降。epoll不同于select和poll轮询的方式，而是通过每个fd定义的回调函数来实现的。只有就绪的fd才会执行回调函数。</p>
</li>
</ol>
<blockquote>
<p>如果没有大量的idle -connection或者dead-connection，epoll的效率并不会比select/poll高很多，但是当遇到大量的idle- connection，就会发现epoll的效率大大高于select/poll。</p>
</blockquote>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;同步IO和异步IO，阻塞IO和非阻塞IO分别是什么，到底有什么区别？不同的人在不同的上下文下给出的答案是不同的。所以先限定一下本文的上下文。&lt;/p&gt;
&lt;p&gt;本文讨论的背景是Linux环境下的network IO。&lt;/p&gt;
&lt;h1 id=&quot;一-概念说明&quot;&gt;&lt;a href=&quot;#
    
    </summary>
    
      <category term="epoll" scheme="https://www.shenyanchao.cn/categories/epoll/"/>
    
    
      <category term="epoll" scheme="https://www.shenyanchao.cn/tags/epoll/"/>
    
      <category term="linux" scheme="https://www.shenyanchao.cn/tags/linux/"/>
    
      <category term="io" scheme="https://www.shenyanchao.cn/tags/io/"/>
    
  </entry>
  
  <entry>
    <title>Redis数据模型详解</title>
    <link href="https://www.shenyanchao.cn/blog/2018/12/25/redis-inside/"/>
    <id>https://www.shenyanchao.cn/blog/2018/12/25/redis-inside/</id>
    <published>2018-12-25T02:47:52.000Z</published>
    <updated>2018-12-26T08:50:47.654Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Redis对象"><a href="#Redis对象" class="headerlink" title="Redis对象"></a>Redis对象</h3><p>在Redis的世界里，存储的所有值都是这个RedisObject对象。</p>
<p>源码定义如下：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span> redisObject &#123;</div><div class="line"></div><div class="line">    <span class="comment">// 类型</span></div><div class="line">    <span class="keyword">unsigned</span> type:<span class="number">4</span>;</div><div class="line">    <span class="comment">// 编码</span></div><div class="line">    <span class="keyword">unsigned</span> encoding:<span class="number">4</span>;</div><div class="line">    <span class="comment">// 对象最后一次被访问的时间</span></div><div class="line">    <span class="keyword">unsigned</span> lru:REDIS_LRU_BITS; <span class="comment">/* lru time (relative to server.lruclock) */</span></div><div class="line">    <span class="comment">// 引用计数</span></div><div class="line">    <span class="keyword">int</span> refcount;</div><div class="line">    <span class="comment">// 指向实际值的指针</span></div><div class="line">    <span class="keyword">void</span> *ptr;</div><div class="line"></div><div class="line">&#125; robj;</div></pre></td></tr></table></figure>
<p>其中type可以取值枚举如下：</p>
<table>
<thead>
<tr>
<th>TYPE枚举</th>
<th>VALUE值</th>
<th>代表</th>
</tr>
</thead>
<tbody>
<tr>
<td>OBJ_STRING</td>
<td>0</td>
<td>STRING</td>
</tr>
<tr>
<td>OBJ_LIST</td>
<td>1</td>
<td>LIST</td>
</tr>
<tr>
<td>OBJ_SET</td>
<td>2</td>
<td>SET</td>
</tr>
<tr>
<td>OBJ_ZSET</td>
<td>3</td>
<td>ZSET</td>
</tr>
<tr>
<td>OBJ_HASH</td>
<td>4</td>
<td>HASH</td>
</tr>
<tr>
<td>OBJ_MODULE</td>
<td>5</td>
<td>—</td>
</tr>
<tr>
<td>OBJ_STREAM</td>
<td>6</td>
<td>—</td>
</tr>
</tbody>
</table>
<p>不同类型Type，它的底层实现/编码方式也是不一样的。枚举类型如下：</p>
<table>
<thead>
<tr>
<th>encoding枚举</th>
<th>VALUE值</th>
<th>str描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>OBJ_ENCODING_RAW</td>
<td>0</td>
<td>raw</td>
</tr>
<tr>
<td>OBJ_ENCODING_INT</td>
<td>1</td>
<td>int</td>
</tr>
<tr>
<td>OBJ_ENCODING_HT</td>
<td>2</td>
<td>hashtable</td>
</tr>
<tr>
<td>OBJ_ENCODING_ZIPMAP</td>
<td>3</td>
<td>不再使用, 转为ZIPLIST</td>
</tr>
<tr>
<td>OBJ_ENCODING_LINKEDLIST</td>
<td>4</td>
<td>不再使用,转为QUICKLIST</td>
</tr>
<tr>
<td>OBJ_ENCODING_ZIPLIST</td>
<td>5</td>
<td>ziplist</td>
</tr>
<tr>
<td>OBJ_ENCODING_INTSET</td>
<td>6</td>
<td>intset</td>
</tr>
<tr>
<td>OBJ_ENCODING_SKIPLIST</td>
<td>7</td>
<td>skiplist</td>
</tr>
<tr>
<td>OBJ_ENCODING_EMBSTR</td>
<td>8</td>
<td>embstr</td>
</tr>
<tr>
<td>OBJ_ENCODING_QUICKLIST</td>
<td>9</td>
<td>quicklist</td>
</tr>
<tr>
<td>define OBJ_ENCODING_STREAM</td>
<td>10</td>
</tr>
</tbody>
</table>
<a id="more"></a>
<h3 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h3><h3 id="String"><a href="#String" class="headerlink" title="String"></a>String</h3><p>Redis引入了一个SDS(Simple Dynamic String)类型，来表示String对象。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">struct</span> sdshdr &#123;</div><div class="line">    </div><div class="line">    <span class="comment">// buf 中已占用空间的长度</span></div><div class="line">    <span class="keyword">int</span> len;</div><div class="line">    <span class="comment">// buf 中剩余可用空间的长度</span></div><div class="line">    <span class="keyword">int</span> <span class="built_in">free</span>;</div><div class="line">    <span class="comment">// 数据空间</span></div><div class="line">    <span class="keyword">char</span> buf[];</div><div class="line">&#125;;</div></pre></td></tr></table></figure>
<p>自<strong>Redis3.2</strong>版本之后，为了更好的优化内存，把sdshdr分为sdshdr5、sdshdr8、sdshdr16、sdshdr32、sdrhdr64。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/* Note: sdshdr5 is never used, we just access the flags byte directly.</span></div><div class="line"> * However is here to document the layout of type 5 SDS strings. */</div><div class="line"><span class="keyword">struct</span> <span class="number">__</span>attribute__ ((<span class="number">__</span>packed__)) sdshdr5 &#123;</div><div class="line">    <span class="keyword">unsigned</span> <span class="keyword">char</span> flags; <span class="comment">/* 3 lsb of type, and 5 msb of string length */</span></div><div class="line">    <span class="keyword">char</span> buf[];</div><div class="line">&#125;;</div><div class="line"><span class="keyword">struct</span> <span class="number">__</span>attribute__ ((<span class="number">__</span>packed__)) sdshdr8 &#123;</div><div class="line">    <span class="keyword">uint8_t</span> len; <span class="comment">/* used */</span></div><div class="line">    <span class="keyword">uint8_t</span> alloc; <span class="comment">/* excluding the header and null terminator */</span></div><div class="line">    <span class="keyword">unsigned</span> <span class="keyword">char</span> flags; <span class="comment">/* 3 lsb of type, 5 unused bits */</span></div><div class="line">    <span class="keyword">char</span> buf[];</div><div class="line">&#125;;</div><div class="line"><span class="keyword">struct</span> <span class="number">__</span>attribute__ ((<span class="number">__</span>packed__)) sdshdr16 &#123;</div><div class="line">    <span class="keyword">uint16_t</span> len; <span class="comment">/* used */</span></div><div class="line">    <span class="keyword">uint16_t</span> alloc; <span class="comment">/* excluding the header and null terminator */</span></div><div class="line">    <span class="keyword">unsigned</span> <span class="keyword">char</span> flags; <span class="comment">/* 3 lsb of type, 5 unused bits */</span></div><div class="line">    <span class="keyword">char</span> buf[];</div><div class="line">&#125;;</div><div class="line"><span class="keyword">struct</span> <span class="number">__</span>attribute__ ((<span class="number">__</span>packed__)) sdshdr32 &#123;</div><div class="line">    <span class="keyword">uint32_t</span> len; <span class="comment">/* used */</span></div><div class="line">    <span class="keyword">uint32_t</span> alloc; <span class="comment">/* excluding the header and null terminator */</span></div><div class="line">    <span class="keyword">unsigned</span> <span class="keyword">char</span> flags; <span class="comment">/* 3 lsb of type, 5 unused bits */</span></div><div class="line">    <span class="keyword">char</span> buf[];</div><div class="line">&#125;;</div><div class="line"><span class="keyword">struct</span> <span class="number">__</span>attribute__ ((<span class="number">__</span>packed__)) sdshdr64 &#123;</div><div class="line">    <span class="keyword">uint64_t</span> len; <span class="comment">/* used */</span></div><div class="line">    <span class="keyword">uint64_t</span> alloc; <span class="comment">/* excluding the header and null terminator */</span></div><div class="line">    <span class="keyword">unsigned</span> <span class="keyword">char</span> flags; <span class="comment">/* 3 lsb of type, 5 unused bits */</span></div><div class="line">    <span class="keyword">char</span> buf[];</div><div class="line">&#125;;</div></pre></td></tr></table></figure>
<h4 id="字典结构"><a href="#字典结构" class="headerlink" title="字典结构"></a>字典结构</h4><p>dictEntry表示hash表的节点。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/*</span></div><div class="line"> * 哈希表节点</div><div class="line"> */</div><div class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span> dictEntry &#123;</div><div class="line">    <span class="comment">// 键</span></div><div class="line">    <span class="keyword">void</span> *key;</div><div class="line">    <span class="comment">// 值</span></div><div class="line">    <span class="keyword">union</span> &#123;</div><div class="line">        <span class="keyword">void</span> *val;</div><div class="line">        <span class="keyword">uint64_t</span> u64;</div><div class="line">        <span class="keyword">int64_t</span> s64;</div><div class="line">    &#125; v;</div><div class="line">    <span class="comment">// 指向下个哈希表节点，形成链表</span></div><div class="line">    <span class="keyword">struct</span> dictEntry *next;</div><div class="line"></div><div class="line">&#125; dictEntry;</div></pre></td></tr></table></figure>
<p>dictht表示一个哈希表。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/*</span></div><div class="line"> * 哈希表</div><div class="line"> *</div><div class="line"> * 每个字典都使用两个哈希表，从而实现渐进式 rehash 。</div><div class="line"> */</div><div class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span> dictht &#123;</div><div class="line">    </div><div class="line">    <span class="comment">// 哈希表数组</span></div><div class="line">    dictEntry **table;</div><div class="line">    <span class="comment">// 哈希表大小</span></div><div class="line">    <span class="keyword">unsigned</span> <span class="keyword">long</span> size;</div><div class="line">    <span class="comment">// 哈希表大小掩码，用于计算索引值</span></div><div class="line">    <span class="comment">// 总是等于 size - 1</span></div><div class="line">    <span class="keyword">unsigned</span> <span class="keyword">long</span> sizemask;</div><div class="line">    <span class="comment">// 该哈希表已有节点的数量</span></div><div class="line">    <span class="keyword">unsigned</span> <span class="keyword">long</span> used;</div><div class="line"></div><div class="line">&#125; dictht;</div></pre></td></tr></table></figure></p>
<p>dict代表了一个字典，需要注意的是dictht有2个，这个用来实现渐进式rehash。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/*</span></div><div class="line"> * 字典</div><div class="line"> */</div><div class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span> dict &#123;</div><div class="line"></div><div class="line">    <span class="comment">// 类型特定函数</span></div><div class="line">    dictType *type;</div><div class="line">    <span class="comment">// 私有数据</span></div><div class="line">    <span class="keyword">void</span> *privdata;</div><div class="line">    <span class="comment">// 哈希表</span></div><div class="line">    dictht ht[<span class="number">2</span>];</div><div class="line">    <span class="comment">// rehash 索引</span></div><div class="line">    <span class="comment">// 当 rehash 不在进行时，值为 -1</span></div><div class="line">    <span class="keyword">int</span> rehashidx; <span class="comment">/* rehashing not in progress if rehashidx == -1 */</span></div><div class="line">    <span class="comment">// 目前正在运行的安全迭代器的数量</span></div><div class="line">    <span class="keyword">int</span> iterators; <span class="comment">/* number of iterators currently running */</span></div><div class="line"></div><div class="line">&#125; dict;</div></pre></td></tr></table></figure>
<p>相关结构图示如下：</p>
<p><img src="/images/redis-inside/redis-dict.png" alt="Redis 字典 dict"></p>
<h4 id="INTSET结构"><a href="#INTSET结构" class="headerlink" title="INTSET结构"></a>INTSET结构</h4><p>用于保存INT类型集合的结构，很简单：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span> intset &#123;</div><div class="line">    </div><div class="line">    <span class="comment">// 编码方式</span></div><div class="line">    <span class="keyword">uint32_t</span> encoding;</div><div class="line">    <span class="comment">// 集合包含的元素数量</span></div><div class="line">    <span class="keyword">uint32_t</span> length;</div><div class="line">    <span class="comment">// 保存元素的数组</span></div><div class="line">    <span class="keyword">int8_t</span> contents[];</div><div class="line"></div><div class="line">&#125; intset;</div></pre></td></tr></table></figure>
<p>内部维护了一个contents数组来保存具体的类型。</p>
<h4 id="SKIPLIST-跳表"><a href="#SKIPLIST-跳表" class="headerlink" title="SKIPLIST(跳表)"></a>SKIPLIST(跳表)</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/* ZSETs use a specialized version of Skiplists */</span></div><div class="line"><span class="comment">/*</span></div><div class="line"> * 跳跃表节点</div><div class="line"> */</div><div class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span> zskiplistNode &#123;</div><div class="line"></div><div class="line">    <span class="comment">// 成员对象</span></div><div class="line">    robj *obj;</div><div class="line">    <span class="comment">// 分值</span></div><div class="line">    <span class="keyword">double</span> score;</div><div class="line">    <span class="comment">// 后退指针</span></div><div class="line">    <span class="keyword">struct</span> zskiplistNode *backward;</div><div class="line">    <span class="comment">// 层</span></div><div class="line">    <span class="keyword">struct</span> zskiplistLevel &#123;</div><div class="line">        <span class="comment">// 前进指针</span></div><div class="line">        <span class="keyword">struct</span> zskiplistNode *forward;</div><div class="line">        <span class="comment">// 跨度</span></div><div class="line">        <span class="keyword">unsigned</span> <span class="keyword">int</span> span;</div><div class="line">    &#125; level[];</div><div class="line"></div><div class="line">&#125; zskiplistNode;</div><div class="line"></div><div class="line"><span class="comment">/*</span></div><div class="line"> * 跳跃表</div><div class="line"> */</div><div class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span> zskiplist &#123;</div><div class="line"></div><div class="line">    <span class="comment">// 表头节点和表尾节点</span></div><div class="line">    <span class="keyword">struct</span> zskiplistNode *header, *tail;</div><div class="line">    <span class="comment">// 表中节点的数量</span></div><div class="line">    <span class="keyword">unsigned</span> <span class="keyword">long</span> length;</div><div class="line">    <span class="comment">// 表中层数最大的节点的层数</span></div><div class="line">    <span class="keyword">int</span> level;</div><div class="line"></div><div class="line">&#125; zskiplist;</div></pre></td></tr></table></figure>
<p>图示表示为：</p>
<p><img src="/images/redis-inside/redis-skiplist.png" alt="redis skiplist 跳表"></p>
<p>这个和常规意义上的跳表并没有区别。</p>
<h4 id="LINKEDLIST"><a href="#LINKEDLIST" class="headerlink" title="LINKEDLIST"></a>LINKEDLIST</h4><p>这是一个双向链表结构(adlist.h)。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span> listNode &#123;</div><div class="line"></div><div class="line">    <span class="comment">// 前置节点</span></div><div class="line">    <span class="keyword">struct</span> listNode *prev;</div><div class="line">    <span class="comment">// 后置节点</span></div><div class="line">    <span class="keyword">struct</span> listNode *next;</div><div class="line">    <span class="comment">// 节点的值</span></div><div class="line">    <span class="keyword">void</span> *value;</div><div class="line"></div><div class="line">&#125; listNode;</div></pre></td></tr></table></figure>
<p>具体的双向链表定义如下：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/*</span></div><div class="line"> * 双端链表结构</div><div class="line"> */</div><div class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span> <span class="built_in">list</span> &#123;</div><div class="line">    <span class="comment">// 表头节点</span></div><div class="line">    listNode *head;</div><div class="line">    <span class="comment">// 表尾节点</span></div><div class="line">    listNode *tail;</div><div class="line">    <span class="comment">// 节点值复制函数</span></div><div class="line">    <span class="keyword">void</span> *(*dup)(<span class="keyword">void</span> *ptr);</div><div class="line">    <span class="comment">// 节点值释放函数</span></div><div class="line">    <span class="keyword">void</span> (*<span class="built_in">free</span>)(<span class="keyword">void</span> *ptr);</div><div class="line">    <span class="comment">// 节点值对比函数</span></div><div class="line">    <span class="keyword">int</span> (*match)(<span class="keyword">void</span> *ptr, <span class="keyword">void</span> *key);</div><div class="line">    <span class="comment">// 链表所包含的节点数量</span></div><div class="line">    <span class="keyword">unsigned</span> <span class="keyword">long</span> len;</div><div class="line"></div><div class="line">&#125; <span class="built_in">list</span>;</div></pre></td></tr></table></figure>
<p>链表操作的具体实现在adlist.c里实现，同正常的双向链表没有区别。</p>
<h4 id="ZIPLIST"><a href="#ZIPLIST" class="headerlink" title="ZIPLIST"></a>ZIPLIST</h4><p>什么时候使用<strong>ZIPLIST</strong>编码呢？如何实现的呢？</p>
<p><img src="/images/redis-inside/redis-ziplist.png" alt="Redis ZIPLIST格式"></p>
<table>
<thead>
<tr>
<th>字段</th>
<th>含义</th>
</tr>
</thead>
<tbody>
<tr>
<td>zlbytes</td>
<td>该字段是压缩链表的第一个字段，是无符号整型，占用4个字节。用于表示整个压缩链表占用的<strong>字节数</strong>（包括它自己）。</td>
</tr>
<tr>
<td>zltail</td>
<td>无符号整型，占用4个字节。用于存储从压缩链表头部到最后一个entry<strong>（不是尾元素zlend）</strong>的偏移量，在快速跳转到链表尾部的场景使用。</td>
</tr>
<tr>
<td>zllen</td>
<td>无符号整型，占用2个字节。用于存储压缩链表中包含的entry总数。</td>
</tr>
<tr>
<td>zlend</td>
<td>特殊的entry，用来表示压缩链表的末尾。<strong>占用一个字节</strong>，值为255（0xFF）。</td>
</tr>
</tbody>
</table>
<p>Entry部分：</p>
<p>一般来说，一个entry由prevlen，encoding，entry-data三个字段组成，但当entry是个很小的整数时，会根据编码省略掉entry-data字段。</p>
<p><strong>prevlen</strong>表示前一个entry的长度。</p>
<ul>
<li>当长度小于255字节的时候，用一个字节存储。</li>
<li>当长度大于等于255字节的时候，用5个字节来存储。第1个字节设置为255（0xFF）,后4个字节来存储前一个entry的长度。</li>
</ul>
<p><strong>encoding</strong>存储分为以下情况。</p>
<p>1.如果元素内容为<strong>字符串</strong>，encoding这样来表示。</p>
<table>
<thead>
<tr>
<th>encoding值</th>
<th>可表示长度</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>00xx xxxx</td>
<td>6bit</td>
<td></td>
</tr>
<tr>
<td>01xx xxxx\</td>
<td>xxxx xxxx</td>
<td>14bit</td>
<td>大端存储</td>
</tr>
<tr>
<td>1000 0000\</td>
<td>xxxx xxxx\</td>
<td>xxxx xxxx\</td>
<td>xxxx xxxx\</td>
<td>xxxx xxxx</td>
<td>32bit</td>
<td>大端存储</td>
</tr>
</tbody>
</table>
<p>2.如果元素为整数，encoding这样表示：</p>
<table>
<thead>
<tr>
<th>encoding</th>
<th>解释</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>1100 0000</td>
<td>表示数字占用后面2个字节</td>
<td></td>
</tr>
<tr>
<td>1101 0000</td>
<td>表示数字占用后面4个字节</td>
<td></td>
</tr>
<tr>
<td>1110 0000</td>
<td>表示数字占用后面8个字节</td>
<td></td>
</tr>
<tr>
<td>1111 0000</td>
<td>表示数字占用后面3个字节</td>
<td></td>
</tr>
<tr>
<td>1111 1110</td>
<td>表示数字占用后面1个字节</td>
<td></td>
</tr>
<tr>
<td>1111 1111</td>
<td>表示压缩链表中最后一个元素（特殊编码0xFF）。即zlend</td>
<td></td>
</tr>
<tr>
<td>1111 xxxx</td>
<td>表示只用后4位表示0~12的整数，由于0000，1110跟1111三种已经被占用，也就是说这里的xxxx四位只能表示0001~1101，转换成十进制就是数字1~13，但是redis规定它用来表示0~12，因此当遇到这个编码时，我们需要取出后四位然后减1来得到正确的值。</td>
</tr>
</tbody>
</table>
<p>源码文档里举了这样的一个包含”2”和“5”的ZIPLIST来说明：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"> 0  1  2  3    4  5  6  7    8  9    10 11   12 13   14</div><div class="line">[0f 00 00 00] [0c 00 00 00] [02 00] [00 f3] [02 f6] [ff]</div><div class="line">       |             |          |       |       |     |</div><div class="line">    zlbytes        zltail    entries   &quot;2&quot;     &quot;5&quot;   zlend</div></pre></td></tr></table></figure>
<p>前4字节，表示为0x0f, 说明总共占用15字节。</p>
<p>接下来的4个字节，表示为0x0c，说明最后一个entry（这里是“5”）的offset是12.</p>
<p>接下来的2个字节表示zllen总共有0x02=2个entry。</p>
<p>接下来的2个字节00，前面一个长度为0（目前是第1个entry），接下来0xf3(1111<u>0011</u>),  按上面的分析，这里3-1=2.</p>
<p>接下来的2个字节，02表示前一个entry长度为2， 0xf6（1111<u>0110</u>）代表6-1=5。</p>
<p>最后一个字节0xff代表结束，最后一个。</p>
<p>接下来，如果在“5”后面插入“hello world”</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"> 0  1  2  3    4  5  6  7    8  9    10 11   12 13  14   15    16 17 18 19 20 21 22 23 24 25 26   27</div><div class="line">[1b 00 00 00] [0e 00 00 00] [03 00] [00 f3] [02 f6] [02] [0b] [48 65 6c 6c 6f 20 57 6f 72 6c 64] [ff]</div><div class="line">       |             |          |       |       |                          |                      |</div><div class="line">    zlbytes        zltail    entries   &quot;2&quot;     &quot;5&quot;                      &quot;hello world&quot;            zlend</div></pre></td></tr></table></figure>
<p>注意到zlbytes变成了28， zltail变成了14, entries变成了3。新加入的entry“hello word”,02表示前一个长度为2. 0x0b(00<u>00 1011</u>)表示后面有数据有11个字节。紧跟其后的就是11个字节的“hello world”ASCII码。</p>
<h4 id="QUICKLIST"><a href="#QUICKLIST" class="headerlink" title="QUICKLIST"></a>QUICKLIST</h4><p>QUICKLIST是一个ziplist的双向链表，这个定义很准确。它综合了LINKEDLIST和ZIPLIST. </p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/* quicklistNode is a 32 byte struct describing a ziplist for a quicklist.</span></div><div class="line"> * We use bit fields keep the quicklistNode at 32 bytes.</div><div class="line"> * count: 16 bits, max 65536 (max zl bytes is 65k, so max count actually &lt; 32k).</div><div class="line"> * encoding: 2 bits, RAW=1, LZF=2.</div><div class="line"> * container: 2 bits, NONE=1, ZIPLIST=2.</div><div class="line"> * recompress: 1 bit, bool, true if node is temporarry decompressed for usage.</div><div class="line"> * attempted_compress: 1 bit, boolean, used for verifying during testing.</div><div class="line"> * extra: 10 bits, free for future use; pads out the remainder of 32 bits */</div><div class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span> quicklistNode &#123;</div><div class="line">    <span class="keyword">struct</span> quicklistNode *prev;</div><div class="line">    <span class="keyword">struct</span> quicklistNode *next;</div><div class="line">    <span class="keyword">unsigned</span> <span class="keyword">char</span> *zl;</div><div class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span> sz;             <span class="comment">/* ziplist size in bytes */</span></div><div class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span> count : <span class="number">16</span>;     <span class="comment">/* count of items in ziplist */</span></div><div class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span> encoding : <span class="number">2</span>;   <span class="comment">/* RAW==1 or LZF==2 */</span></div><div class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span> container : <span class="number">2</span>;  <span class="comment">/* NONE==1 or ZIPLIST==2 */</span></div><div class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span> recompress : <span class="number">1</span>; <span class="comment">/* was this node previous compressed? */</span></div><div class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span> attempted_compress : <span class="number">1</span>; <span class="comment">/* node can't compress; too small */</span></div><div class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span> extra : <span class="number">10</span>; <span class="comment">/* more bits to steal for future usage */</span></div><div class="line">&#125; quicklistNode;</div></pre></td></tr></table></figure>
<p>其中：</p>
<p>prev,next：分别指向前一个和后一个node，典型的双链表。</p>
<p>zl：指向ziplist结构，如果启用了压缩，那么指向的就是quicklistLZF结构了。</p>
<p>sz：表示指向ziplist的总大小。即使被压缩，也仍旧是未压缩的大小。</p>
<p>count：表示ziplist里面数据项的个数。</p>
<p>encoding：表示是否压缩（2表示LZF，1为RAW）。</p>
<p>container: 表示使用什么类型存数据。目前（NONE=1, ZIPLIST=2）</p>
<p>recompress:  表明这个数据是否压缩过。</p>
<p>attempted_compress: 测试用</p>
<p>extra: 扩展字段。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/* quicklistLZF is a 4+N byte struct holding 'sz' followed by 'compressed'.</span></div><div class="line"> * 'sz' is byte length of 'compressed' field.</div><div class="line"> * 'compressed' is LZF data with total (compressed) length 'sz'</div><div class="line"> * <span class="doctag">NOTE:</span> uncompressed length is stored in quicklistNode-&gt;sz.</div><div class="line"> * When quicklistNode-&gt;zl is compressed, node-&gt;zl points to a quicklistLZF */</div><div class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span> quicklistLZF &#123;</div><div class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span> sz; <span class="comment">/* LZF size in bytes*/</span></div><div class="line">    <span class="keyword">char</span> compressed[];</div><div class="line">&#125; quicklistLZF;</div></pre></td></tr></table></figure>
<p>sz: LZF压缩后的大小。</p>
<p>compressed: 存放压缩后ZIPLIST的char数组。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/* quicklist is a 40 byte struct (on 64-bit systems) describing a quicklist.</span></div><div class="line"> * 'count' is the number of total entries.</div><div class="line"> * 'len' is the number of quicklist nodes.</div><div class="line"> * 'compress' is: -1 if compression disabled, otherwise it's the number</div><div class="line"> *                of quicklistNodes to leave uncompressed at ends of quicklist.</div><div class="line"> * 'fill' is the user-requested (or default) fill factor. */</div><div class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span> quicklist &#123;</div><div class="line">    quicklistNode *head;</div><div class="line">    quicklistNode *tail;</div><div class="line">    <span class="keyword">unsigned</span> <span class="keyword">long</span> count;        <span class="comment">/* total count of all entries in all ziplists */</span></div><div class="line">    <span class="keyword">unsigned</span> <span class="keyword">long</span> len;          <span class="comment">/* number of quicklistNodes */</span></div><div class="line">    <span class="keyword">int</span> fill : <span class="number">16</span>;              <span class="comment">/* fill factor for individual nodes */</span></div><div class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span> compress : <span class="number">16</span>; <span class="comment">/* depth of end nodes not to compress;0=off */</span></div><div class="line">&#125; quicklist;</div></pre></td></tr></table></figure>
<p>head,tail：分别指向头、尾</p>
<p>count: 所有ziplist数据项总和。</p>
<p>len: quicklistNode的总个数</p>
<p>fill: 16bit，ziplist大小设置。存放<code>list-max-ziplist-size</code>参数的值</p>
<p>compress: 16bit, 压缩深度设置。存放<code>list-compress-depth</code>参数的值。</p>
<p>简略图示如下：</p>
<p><img src="/images/redis-inside/redis-quicklist.png" alt="Redis quicklist"></p>
<p>上图中redis.conf中配置如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"># 每个ziplist最大存多少个</div><div class="line">list-max-ziplist-size 3  </div><div class="line"># 代表头尾有2个不压缩(黄色部分)。默认是0，都不压缩。通常认为头尾是需要经常操作的</div><div class="line">list-compress-depth 2</div></pre></td></tr></table></figure>
<p>quicklist总分利用了ziplist的压缩比高，规避了量大效率低的问题。redis 3.2之后，默认使用QUICKLIST来实现.</p>
<h4 id="ZIPMAP"><a href="#ZIPMAP" class="headerlink" title="ZIPMAP"></a>ZIPMAP</h4><p>格式如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">&lt;zmlen&gt;&lt;len&gt;&quot;foo&quot;&lt;len&gt;&lt;free&gt;&quot;bar&quot;&lt;len&gt;&quot;hello&quot;&lt;len&gt;&lt;free&gt;&quot;world&quot;0XFF</div></pre></td></tr></table></figure>
<p>zmlen: 1byte, 表示当前zipmap的长度。当长度&gt;254的时候，这个不需要。总长度需要遍历拿到</p>
<p>len: 后面跟着值的长度。如果第1字节在0-253，代表是一个单字节产股。如果第1字节是254，表示后面有4字节表示具体长度。遇到255(0xFF)表示结尾。</p>
<p>free: 表示未用的字符串。这种情况存在于修改内容的时候，比如foo-&gt;hi，则有1个的空白。</p>
<h3 id="数据编码一览"><a href="#数据编码一览" class="headerlink" title="数据编码一览"></a>数据编码一览</h3><table>
<thead>
<tr>
<th>数据类型</th>
<th>一般情况编码</th>
<th>少量数据编码</th>
<th>数据为整形</th>
</tr>
</thead>
<tbody>
<tr>
<td>String</td>
<td>RAW</td>
<td>EMBSTR</td>
<td>INT</td>
</tr>
<tr>
<td>List</td>
<td>LINKEDLIST(3.2前)/QUICKLIST(3.2后)</td>
<td>ZIPLIST(3.2前)</td>
<td></td>
</tr>
<tr>
<td>Set</td>
<td>HT</td>
<td></td>
<td>INTSET</td>
</tr>
<tr>
<td>Hash</td>
<td>HT</td>
<td>ZIPMAP</td>
<td></td>
</tr>
<tr>
<td>ZSET</td>
<td>SKIPLIST</td>
<td>ZIPLIST</td>
</tr>
</tbody>
</table>
<h4 id="String-OBJ-STRING-类型"><a href="#String-OBJ-STRING-类型" class="headerlink" title="String(OBJ_STRING)类型"></a>String(OBJ_STRING)类型</h4><p><strong>EMBSTR</strong>(OBJ_ENCODING_EMBSTR)编码(长度小于&lt;39/44使用这种类型):</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">jemalloc chunk size = <span class="number">64</span>;</div><div class="line"><span class="keyword">sizeof</span>(robj)=<span class="number">16</span>;</div><div class="line"><span class="keyword">sizeof</span>(sdshdr)=<span class="number">8</span>;  <span class="comment">// 3.2之前</span></div><div class="line"><span class="keyword">sizeof</span>(sdshdr8)=<span class="number">3</span>; <span class="comment">// 3.2之后</span></div><div class="line"><span class="keyword">sizeof</span>(<span class="string">'\0'</span>)=<span class="number">1</span>;</div></pre></td></tr></table></figure>
<p>所以：</p>
<p>Redis3.2前，64-16-8-1=39。</p>
<p>Redis3.2之后，64-16-3-1=44.</p>
<p>长度在39/44以内的话，可以直接存放在连续内存，省去了多次分配。</p>
<p><strong>INT</strong>(OBJ_ENCODING_INT): 如果字符串都是整数的时候，使用INT编码。</p>
<p>ptr指针直接代表字符串的值。实际上Redis启动后，会默认创建10000个RedisObject, 用于代表地1-10000的整形，这个大小是可以配置的。</p>
<p>如果以上都不满足, 使用<strong>OBJ_ENCODING_RAW</strong>编码，即SDS类型。</p>
<h4 id="List-OBJ-LIST-类型"><a href="#List-OBJ-LIST-类型" class="headerlink" title="List(OBJ_LIST)类型"></a>List(OBJ_LIST)类型</h4><p>在Redis3.2之后，统一使用<strong>OBJ_ENCODING_QUICKLIST</strong>来实现。</p>
<h3 id="SET-OBJ-SET-类型"><a href="#SET-OBJ-SET-类型" class="headerlink" title="SET(OBJ_SET)类型"></a>SET(OBJ_SET)类型</h3><p>redis.conf配置文件里：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">set-max-intset-entries  512</div></pre></td></tr></table></figure>
<p>意思是如果整数集合的元素个数超过512，则转为HT编码。当然，如果插入的是字符串，那也会直接转码，无视这个限制的。</p>
<h3 id="HASH-OBJ-HASH-类型"><a href="#HASH-OBJ-HASH-类型" class="headerlink" title="HASH(OBJ_HASH)类型"></a>HASH(OBJ_HASH)类型</h3><p>redis.conf配置文件里：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">hash-max-ziplist-value 64 // ziplist中最大能存放的值长度</div><div class="line">hash-max-ziplist-entries 512 // ziplist中最多能存放的entry节点数量</div></pre></td></tr></table></figure>
<p>这些阈值，用于决定什么情况下使用何种类型编码。</p>
<p>以上可以看出。entry个数小于等于512并且value长度小于等于64的话才使用ZIPLIST，超出则选择HASHTABLE.</p>
<h3 id="SortedSet-OBJ-ZSET-类型"><a href="#SortedSet-OBJ-ZSET-类型" class="headerlink" title="SortedSet(OBJ_ZSET)类型"></a>SortedSet(OBJ_ZSET)类型</h3><p>有序集合定义为zset</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/*</span></div><div class="line"> * 有序集合</div><div class="line"> */</div><div class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span> zset &#123;</div><div class="line">    <span class="comment">// 字典，键为成员，值为分值</span></div><div class="line">    <span class="comment">// 用于支持 O(1) 复杂度的按成员取分值操作</span></div><div class="line">    dict *dict;</div><div class="line">    <span class="comment">// 跳跃表，按分值排序成员</span></div><div class="line">    <span class="comment">// 用于支持平均复杂度为 O(log N) 的按分值定位成员操作</span></div><div class="line">    <span class="comment">// 以及范围操作</span></div><div class="line">    zskiplist *zsl;</div><div class="line"></div><div class="line">&#125; zset;</div></pre></td></tr></table></figure>
<p>可以看出，里面由一个dict和一个zskiplist来实现。dict用来存储key-score对， zskiplist用于快速定位查找。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#<span class="meta-keyword">define</span> OBJ_ZSET_MAX_ZIPLIST_ENTRIES 128    <span class="comment">// ziplist中最多存放的节点数</span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">define</span> OBJ_ZSET_MAX_ZIPLIST_VALUE 64       <span class="comment">// ziplist中最大存放的数据长度</span></span></div></pre></td></tr></table></figure>
<p>在entry个数&lt;=128并且value长度&lt;=64的时候，使用的是ziplist，否则使用SKIPLIST格式。</p>
<p><img src="/images/redis-inside/redis-zset.png" alt="Redis 有序集合 zset"></p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>Redis为了更大程度的提升性能，压缩数据大小， 在内存模型和数据结构上做了很多努力。</p>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;Redis对象&quot;&gt;&lt;a href=&quot;#Redis对象&quot; class=&quot;headerlink&quot; title=&quot;Redis对象&quot;&gt;&lt;/a&gt;Redis对象&lt;/h3&gt;&lt;p&gt;在Redis的世界里，存储的所有值都是这个RedisObject对象。&lt;/p&gt;
&lt;p&gt;源码定义如下：&lt;/p&gt;
&lt;figure class=&quot;highlight c&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;5&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;6&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;7&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;8&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;9&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;10&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;11&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;12&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;13&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;14&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;typedef&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;struct&lt;/span&gt; redisObject &amp;#123;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &lt;span class=&quot;comment&quot;&gt;// 类型&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;unsigned&lt;/span&gt; type:&lt;span class=&quot;number&quot;&gt;4&lt;/span&gt;;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &lt;span class=&quot;comment&quot;&gt;// 编码&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;unsigned&lt;/span&gt; encoding:&lt;span class=&quot;number&quot;&gt;4&lt;/span&gt;;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &lt;span class=&quot;comment&quot;&gt;// 对象最后一次被访问的时间&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;unsigned&lt;/span&gt; lru:REDIS_LRU_BITS; &lt;span class=&quot;comment&quot;&gt;/* lru time (relative to server.lruclock) */&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &lt;span class=&quot;comment&quot;&gt;// 引用计数&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt; refcount;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &lt;span class=&quot;comment&quot;&gt;// 指向实际值的指针&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;void&lt;/span&gt; *ptr;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&amp;#125; robj;&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;其中type可以取值枚举如下：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;TYPE枚举&lt;/th&gt;
&lt;th&gt;VALUE值&lt;/th&gt;
&lt;th&gt;代表&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;OBJ_STRING&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;STRING&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;OBJ_LIST&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;LIST&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;OBJ_SET&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;SET&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;OBJ_ZSET&lt;/td&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;ZSET&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;OBJ_HASH&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;HASH&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;OBJ_MODULE&lt;/td&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;—&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;OBJ_STREAM&lt;/td&gt;
&lt;td&gt;6&lt;/td&gt;
&lt;td&gt;—&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;不同类型Type，它的底层实现/编码方式也是不一样的。枚举类型如下：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;encoding枚举&lt;/th&gt;
&lt;th&gt;VALUE值&lt;/th&gt;
&lt;th&gt;str描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;OBJ_ENCODING_RAW&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;raw&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;OBJ_ENCODING_INT&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;int&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;OBJ_ENCODING_HT&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;hashtable&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;OBJ_ENCODING_ZIPMAP&lt;/td&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;不再使用, 转为ZIPLIST&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;OBJ_ENCODING_LINKEDLIST&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;不再使用,转为QUICKLIST&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;OBJ_ENCODING_ZIPLIST&lt;/td&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;ziplist&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;OBJ_ENCODING_INTSET&lt;/td&gt;
&lt;td&gt;6&lt;/td&gt;
&lt;td&gt;intset&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;OBJ_ENCODING_SKIPLIST&lt;/td&gt;
&lt;td&gt;7&lt;/td&gt;
&lt;td&gt;skiplist&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;OBJ_ENCODING_EMBSTR&lt;/td&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;td&gt;embstr&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;OBJ_ENCODING_QUICKLIST&lt;/td&gt;
&lt;td&gt;9&lt;/td&gt;
&lt;td&gt;quicklist&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;define OBJ_ENCODING_STREAM&lt;/td&gt;
&lt;td&gt;10&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
    
    </summary>
    
      <category term="redis" scheme="https://www.shenyanchao.cn/categories/redis/"/>
    
    
      <category term="redis" scheme="https://www.shenyanchao.cn/tags/redis/"/>
    
      <category term="ziplist" scheme="https://www.shenyanchao.cn/tags/ziplist/"/>
    
      <category term="quicklist" scheme="https://www.shenyanchao.cn/tags/quicklist/"/>
    
      <category term="sds" scheme="https://www.shenyanchao.cn/tags/sds/"/>
    
  </entry>
  
  <entry>
    <title>ElasticSearch线上故障-持续Yellow状态</title>
    <link href="https://www.shenyanchao.cn/blog/2018/12/13/elasticsearch-yellow-exception/"/>
    <id>https://www.shenyanchao.cn/blog/2018/12/13/elasticsearch-yellow-exception/</id>
    <published>2018-12-13T06:12:07.000Z</published>
    <updated>2018-12-20T12:02:48.981Z</updated>
    
    <content type="html"><![CDATA[<h3 id="现象"><a href="#现象" class="headerlink" title="现象"></a>现象</h3><p>ES集群，状态持续Yellow。出现部分replica一直在追primary的索引数据，追不上。</p>
<p>仔细排查：固定的几个ES节点，出现间歇性被<strong>踢出</strong>Cluster，随后又<strong>加入</strong>Cluster。这是导致出现yellow原因，并且一直不能恢复到Green状态。</p>
<h3 id="日志排查"><a href="#日志排查" class="headerlink" title="日志排查"></a>日志排查</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"> [2018-12-08T19:25:29,993][WARN ][o.e.x.s.t.n.SecurityNetty4Transport] [es35-search.mars.ljnode.com] write and flush on the network layer failed (channel: [id: 0x0e6ac038, L:0.0.0.0/0.0.0.0:8309 ! R:/10.200.24.96:46802])</div><div class="line">java.nio.channels.ClosedChannelException: null</div><div class="line">         at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source) ~[?:?]</div><div class="line"> [2018-12-08T19:25:29,994][WARN ][o.e.x.s.t.n.SecurityNetty4Transport] [es35-search.mars.ljnode.com] write and flush on the network layer failed (channel: [id: 0x0e6ac038, L:0.0.0.0/0.0.0.0:8309 ! R:/10.200.24.96:46802])</div><div class="line"> java.nio.channels.ClosedChannelException: null</div><div class="line">         at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source) ~[?:?]</div><div class="line"> [2018-12-08T19:25:31,111][DEBUG][o.e.a.a.c.n.i.TransportNodesInfoAction] [es35-search.mars.ljnode.com] failed to execute on node [_TS9PjOLRke8j12-d59iGA]</div><div class="line"> org.elasticsearch.transport.ReceiveTimeoutTransportException: [es39-search.mars.ljnode.com_node0][10.200.24.86:8309][cluster:monitor/nodes/info[n]] request_id [203863696] timed out after [5000ms]</div><div class="line">         at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:961) [elasticsearch-5.6.9.jar:5.6.9]</div><div class="line">         at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:575) [elasticsearch-5.6.9.jar:5.6.9]</div><div class="line">         at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_172]</div><div class="line">         at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_172]</div><div class="line">         at java.lang.Thread.run(Thread.java:748) [?:1.8.0_172]</div><div class="line"> [2018-12-08T19:25:32,305][DEBUG][o.e.a.a.c.n.i.TransportNodesInfoAction] [es35-search.mars.ljnode.com] failed to execute on node [yt3RGpgJStKwtOENBe5Trw]</div><div class="line"> org.elasticsearch.transport.ReceiveTimeoutTransportException: [es38-search.mars.ljnode.com_node0][10.200.24.97:8309][cluster:monitor/nodes/info[n]] request_id [203863752] timed out after [5000ms]</div><div class="line">         at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:961) [elasticsearch-5.6.9.jar:5.6.9]</div></pre></td></tr></table></figure>
<h3 id="原因"><a href="#原因" class="headerlink" title="原因"></a>原因</h3><p>网络是千兆的网卡，堵塞导致超时。</p>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;现象&quot;&gt;&lt;a href=&quot;#现象&quot; class=&quot;headerlink&quot; title=&quot;现象&quot;&gt;&lt;/a&gt;现象&lt;/h3&gt;&lt;p&gt;ES集群，状态持续Yellow。出现部分replica一直在追primary的索引数据，追不上。&lt;/p&gt;
&lt;p&gt;仔细排查：固定的几个ES节点
    
    </summary>
    
      <category term="elasticsearch" scheme="https://www.shenyanchao.cn/categories/elasticsearch/"/>
    
    
      <category term="elasticsearch" scheme="https://www.shenyanchao.cn/tags/elasticsearch/"/>
    
  </entry>
  
  <entry>
    <title>lucene-bkm</title>
    <link href="https://www.shenyanchao.cn/blog/2018/12/04/lucene-bkm/"/>
    <id>https://www.shenyanchao.cn/blog/2018/12/04/lucene-bkm/</id>
    <published>2018-12-04T14:03:21.000Z</published>
    <updated>2018-12-04T14:03:21.754Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Lucene索引过程&amp;索引文件格式详解</title>
    <link href="https://www.shenyanchao.cn/blog/2018/12/04/lucene-index-files/"/>
    <id>https://www.shenyanchao.cn/blog/2018/12/04/lucene-index-files/</id>
    <published>2018-12-04T04:36:09.000Z</published>
    <updated>2018-12-07T13:56:26.089Z</updated>
    
    <content type="html"><![CDATA[<p>最近2年，整个开源搜索引擎领域，发展迅速，版本迭代很快。 Lucene最近两年从4.0版本已经发布到最新的7.5.0版本，Solr和Elasticsearch也不断跟进升级。Lucene作为核心包，互联网上或者是书籍上关于它的介绍和分析都比较陈旧了，很多都是基于Lucene3.x来。是时候，从底层来分析下最新的Lucene发展情况了。</p>
<p>本文，依Lucene 7.5.0（当时最新）版本描述。</p>
<h3 id="Lucene索引文件的表现"><a href="#Lucene索引文件的表现" class="headerlink" title="Lucene索引文件的表现"></a>Lucene索引文件的表现</h3><p>Lucene索引在硬盘上的<strong>表现</strong>就是一系列的文件，后缀名不同，下面是一个样例：</p>
<p><img src="/images/lucene-index-files/lucene-index-on-disk.jpg" alt="lucene 索引文件"></p>
<p>通常，看到这些文件，我们就想打开看看，发现根本无法直接查看。这里存的到底是什么，都有什么作用。很多时候是一脸的懵。为了更好的理解这些文件，下面将一步步进行细致的分析。</p>
<a id="more"></a>
<h3 id="Lucene构建索引过程"><a href="#Lucene构建索引过程" class="headerlink" title="Lucene构建索引过程"></a>Lucene构建索引过程</h3><p>Lucene源码读起来是比较晦涩的，毕竟它写于20年前，而且作者也是一个具备很多工作经验的老手，读源码是需要一定的时间的。    </p>
<p>做索引的入口是<code>IndexWriter.addDocument*()</code>, 当新索引N个Document的时候，是如何生成一系列的索引文件呢。</p>
<p>下面是一个源码导读图：</p>
<p><img src="/images/lucene-index-files/lucene-index-process.png" alt="Lucene 索引构建"></p>
<p>以上重点关注<code>DefaultIndexingChain</code>这个类，<code>processDocument()</code>方法主要是用来构建<strong>正排信息</strong>。而针对每个Field的<code>processField()</code>则通过一系列的操作，构建出了<strong>倒排信息</strong>。</p>
<p>什么时候写入磁盘文件中呢？触发点是DocumentsWriterPerThread(DWPT)的flush()方法。触发时间可能是以下条件：</p>
<ul>
<li>超过MaxBufferedDocs限制</li>
<li>超过RAMBufferSizeMB限制</li>
<li>人为flush()或commit()</li>
<li>MergePolicy触发</li>
</ul>
<p>经过以上的处理，就生成了一个最小的<strong>独立索引单元</strong>，称之为Segment。一个逻辑上的索引（表现为一个目录），是由N多个Segment构成的。</p>
<h3 id="Lucene索引文件"><a href="#Lucene索引文件" class="headerlink" title="Lucene索引文件"></a>Lucene索引文件</h3><p>以下描述在<a href="https://lucene.apache.org/core/7_5_0/core/org/apache/lucene/codecs/lucene70/package-summary.html" target="_blank" rel="external">Lucene JavaDoc</a>里有详细的介绍，为方便理解，介绍如下：</p>
<table>
<thead>
<tr>
<th>名称</th>
<th>扩展名</th>
<th>简要描述</th>
<th>相关源码</th>
</tr>
</thead>
<tbody>
<tr>
<td>Segment File</td>
<td>segments_N</td>
<td>commit点信息，其中N是一个36进制表示的值</td>
<td>SegmentInfos</td>
</tr>
<tr>
<td>Lock File</td>
<td>write.lock</td>
<td>文件锁，避免多个writer同时写；默认和索引文件一个目录。</td>
<td></td>
</tr>
<tr>
<td>Segment Info</td>
<td>.si</td>
<td>segment的元数据信息，指明这个segment都包含哪些文件</td>
<td>Lucene70SegmentInfoFormat</td>
</tr>
<tr>
<td>Compound File</td>
<td>.cfs, .cfe</td>
<td>如果启用compound功能，会压缩索引到2个文件内</td>
<td>Lucene50CompoundFormat</td>
</tr>
<tr>
<td>Fields</td>
<td>.fnm</td>
<td>存储有哪些Field,以及相关信息</td>
<td>Lucene60FieldInfosFormat</td>
</tr>
<tr>
<td>Field Index</td>
<td>.fdx</td>
<td>Field数据文件的索引</td>
<td>Lucene50StoredFieldsFormat</td>
</tr>
<tr>
<td>Field Data</td>
<td>.fdt</td>
<td>Field数据文件</td>
<td>Lucene50StoredFieldsFormat</td>
</tr>
<tr>
<td>Term Dictionary</td>
<td>.tim</td>
<td>Term词典</td>
<td>BlockTreeTermsWriter</td>
</tr>
<tr>
<td>Term Index</td>
<td>.tip</td>
<td>指向Term词典的索引</td>
<td>BlockTreeTermsWriter</td>
</tr>
<tr>
<td>Frequencies</td>
<td>.doc</td>
<td>保留包含每个Term的文档列表</td>
<td>Lucene50PostingsWriter</td>
</tr>
<tr>
<td>Positions</td>
<td>.pos</td>
<td>Term在文章中出现的位置信息</td>
<td>Lucene50PostingsWriter</td>
</tr>
<tr>
<td>Payloads</td>
<td>.pay</td>
<td>offset偏移/payload附加信息</td>
<td>Lucene50PostingsWriter</td>
</tr>
<tr>
<td>Norms</td>
<td>.nvd, .nvm</td>
<td>.nvm保存加权因子元数据；.nvd存储加权数据</td>
<td>Lucene70NormsFormat</td>
</tr>
<tr>
<td>Per-Document Values</td>
<td>.dvd, .dvm</td>
<td>.dvm存文档正排元数据；.dvd存文档正排数据</td>
<td>Lucene70DocValuesFormat</td>
</tr>
<tr>
<td>Term Vector Index</td>
<td>.tvx</td>
<td>指向tvd的offset</td>
<td>Lucene50TermVectorsFormat</td>
</tr>
<tr>
<td>Term Vector Data</td>
<td>.tvd</td>
<td>存储term vector信息</td>
<td>Lucene50TermVectorsFormat</td>
</tr>
<tr>
<td>Live Documents</td>
<td>.liv</td>
<td>活着的文档列表。位图形式</td>
<td>Lucene50LiveDocsFormat</td>
</tr>
<tr>
<td>Point Values</td>
<td>.dii, .dim</td>
<td>多维数据，地理位置等信息，用于处理数值型的查询</td>
<td>Lucene60PointsFormat</td>
</tr>
</tbody>
</table>
<h4 id="Segment-N"><a href="#Segment-N" class="headerlink" title="Segment_N"></a>Segment_N</h4><p>格式：</p>
<p><img src="/images/lucene-index-files/lucene-segments-n.png" alt="Lucene Segment_N"></p>
<p>其中N作为后缀，是36进制的数字, 实现方式为：<code>Long.toString(gen, Character.MAX_RADIX)</code>。</p>
<p>segments_N里通过SegName记录了这索引里<strong>所有.si文件名</strong>。</p>
<h4 id="segment格式（-si）"><a href="#segment格式（-si）" class="headerlink" title="segment格式（.si）"></a>segment格式（.si）</h4><p>格式：</p>
<p><img src="/images/lucene-index-files/lucene-si.png" alt="Lucene segment"></p>
<p>由于一个segment文件，就是一个独立的子索引，其中Files是一个列表，里面存储了本segment所有相关的索引文件。类似长这样：</p>
<pre><code>_8qh.dii
_8qh.dim
_8qh.fdt
_8qh.fdx
_8qh.fnm
_8qh_Lucene50_0.doc
_8qh_Lucene50_0.pos
_8qh_Lucene50_0.tim
_8qh_Lucene50_0.tip
_8qh_Lucene70_0.dvd
_8qh_Lucene70_0.dvm
_8qh.si    
</code></pre><p>IndexSort作为新加入的一个特性，也直接体现在了.si文件里。IndexSort可以加速排序，极大提升性能。</p>
<h4 id="Field-info格式（-fnm）"><a href="#Field-info格式（-fnm）" class="headerlink" title="Field info格式（.fnm）"></a>Field info格式（.fnm）</h4><p>格式：</p>
<p><img src="/images/lucene-index-files/lucene-fnm.png" alt="Lucene Filed info"></p>
<p>存储了Document所包含的FieldName以及Field的内部表示FieldNumber（可以理解为ID）。 同时，每个Field相关索引配置，都通过byte来存储保存下来。</p>
<p>其中DocValueBits里，不同类型的Field, 处理DocValue数据是不一样的，此处暂时按下不表。后续产出</p>
<h4 id="Field-Data格式（-fdx-fdt）"><a href="#Field-Data格式（-fdx-fdt）" class="headerlink" title="Field Data格式（.fdx, .fdt）"></a>Field Data格式（.fdx, .fdt）</h4><p>格式如下所示：</p>
<p><img src="/images/lucene-index-files/lucene-fdt.png" alt=""></p>
<p>由于fdt正排信息很多，在存到磁盘的时候，使用<strong>LZ4算法</strong>进行了压缩。每个Chunk大小16KB(<code>1&lt;&lt;14</code>), Doc个数不能超过128个。在fdx中每个Block有1024个Chunk。</p>
<p>CompressDocs是压缩后进行存储的，为了方便理解，可以认为就是一系列的Doc构成的。每个Doc又包含FieldNumAndType和实际的Field Value。</p>
<p>其中FieldNumAndType是一个VLong: <strong>低3位</strong>表示Field Type, 其余<strong>高位</strong>用来表示FieldNumber.  可见Lucene为了最大程度的节省空间，做了很多的Trick.</p>
<h4 id="Term-Index格式（-tip-tim）"><a href="#Term-Index格式（-tip-tim）" class="headerlink" title="Term Index格式（.tip,.tim）"></a>Term Index格式（.tip,.tim）</h4><p><a href="https://lucene.apache.org/core/7_5_0/core/org/apache/lucene/codecs/blocktree/BlockTreeTermsWriter.html" target="_blank" rel="external">格式</a>如下：</p>
<p>.tip:</p>
<p>​    Header, FSTIndex&lt; IndexStartFP&gt;…, DirOffset, Footer</p>
<p>.tim</p>
<p>​    Header, <em>PostingsHeader</em>, NodeBlock(…), FieldSummary, DirOffset, Footer</p>
<p>图例如下：</p>
<p><img src="/images/lucene-index-files/lucene-tim.png" alt="lucene Term Index &amp; Term Dictionary"></p>
<p>其中FST部分，是直接加载到内存的，详见另外一篇博文，这里为方便理解，直接写画为类TRIE一样。</p>
<h4 id="Pos列表（-doc-pos-pay）"><a href="#Pos列表（-doc-pos-pay）" class="headerlink" title="Pos列表（.doc, .pos, .pay）"></a>Pos列表（.doc, .pos, .pay）</h4><p>doc格式如下：</p>
<p><img src="/images/lucene-index-files/lucene-doc.png" alt="Lucene posting list"></p>
<p>需要注意的是，PackedBlock是对倒排列表的压缩，每128个作为一个Block，不能凑整的情况下，再按VIntBlock进行存储。无论如何存储，Block内部是存储了DocID（<code>PackedDocDeltaBlock</code>）和Term Freq(<code>PackedFreqBlock</code>)的对应关系的。</p>
<p>而Postings则是以SKIPLIST（跳表）进行存储的，这种存储格式保证了快速的查找和归并操作。最底层的SkipDatum通过DocSkip保有对实际doc的指针。PosFPSkip则指向.pos文件，PayFPSkip指向了.pay文件。</p>
<p>pos文件格式：</p>
<p><img src="/images/lucene-index-files/lucene-pos.png" alt="Lucene Position"></p>
<p>这里的PackedPosDeltaBlock与doc文件的很像，也是进行了压缩成block进行存储。最终通过PostionDelta和OffsetDelta来获取相关的位置和偏移信息。</p>
<p>pay格式：</p>
<p><img src="/images/lucene-index-files/lucene-pay.png" alt="Lucene payload"></p>
<p>同样做了Block处理，这个文件通过TermPayloads保留了Term和Payload的对应关系；通过TermOffsets保存了Term和Offset的对应关系。</p>
<h4 id="LIV文件格式-liv"><a href="#LIV文件格式-liv" class="headerlink" title="LIV文件格式(.liv)"></a>LIV文件格式(.liv)</h4><p>格式如下：</p>
<p><img src="/images/lucene-index-files/lucene-liv.png" alt="Lucene live document"></p>
<p>通过FixBitSet位图，来表示哪些是存活的，哪些是被删除的。FixBitSet的底层是通过<code>long[]</code>来模拟实现这样一个大的位图的。</p>
<p>Lucene的4.0版本之前是通过.del文件来标记哪些DocID是被删除的，而现在则改为.liv标记哪些是存活的。个人而言，没有看出来具体原因，毕竟功能实现其实是一样的。</p>
<h4 id="TermVector-tvx-tvd"><a href="#TermVector-tvx-tvd" class="headerlink" title="TermVector(.tvx, .tvd)"></a>TermVector(.tvx, .tvd)</h4><p>格式如下：</p>
<p><img src="/images/lucene-index-files/lucene-tvd.png" alt="Lucene TermVector"></p>
<p>这个格式和Field Data的很相似。区别在于最底层的Chunk直接保留了相关的信息TermFreqs、Positions、StartOffsets、TermAndPayLoads等信息。</p>
<p>从这里也可以看出Term Vector保存的信息很多都是和之前重复的，如果没有必要，完全可以关闭Term Vector功能，避免额外的性能损耗。  </p>
<h4 id="Norms-nvm-nvd"><a href="#Norms-nvm-nvd" class="headerlink" title="Norms (.nvm, .nvd)"></a>Norms (.nvm, .nvd)</h4><p>格式如下：</p>
<p><img src="/images/lucene-index-files/lucene-nvd.png" alt="Lucene Norms"></p>
<p>Norms信息通常是用来存储Field\Document的Boost加权信息，然后Lucene7之后，去除了Index时的boost加权操作。因此，目前Norms里存储的东西极少，有逐步被取消的的可能性。</p>
<h4 id="Doc-Values-dvx-dvd"><a href="#Doc-Values-dvx-dvd" class="headerlink" title="Doc Values(.dvx, .dvd)"></a>Doc Values(.dvx, .dvd)</h4><p>DocValues部分，比较复杂，以至于官方文档都没有给出详细的索引格式。以后将作为一个独立的文章还具体解释。</p>
<h4 id="Point-Values-dii，-dim"><a href="#Point-Values-dii，-dim" class="headerlink" title="Point Values(.dii，.dim)"></a>Point Values(.dii，.dim)</h4><p>Lucene7之后，彻底去除了之前关于数字类型索引和查找的逻辑。之前的TrieInt, TrieLong等完全被删除。取而代之的是IntPoint,LongPoint等类型。</p>
<p>这些类型都是由BKD-Tree来实现的，Point Value被用来实现N-Dimension多维数据的索引和快速的查询，有统一数字型查询、2D位置、3D乃至8D数据查询的趋势，这块将单独作为一个文章进行详细解读。</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>Lucene索引及其格式，是Solr以及ElasticSearch等分布式搜索引擎的根基。Lucene每一次核心功能的迭代与性能提升都是至关重要的。对Lucene索引过程以及索引文件格式的理解，有助于从更高层面来分析和看待生产环境出现的问题。</p>
<hr>
<p>参考文档：</p>
<p><a href="https://lucene.apache.org/core/7_5_0/core/org/apache/lucene/codecs/lucene70/package-summary.html" target="_blank" rel="external">Lucene Java DOC</a></p>
<p><a href="http://blog.51cto.com/sbp810050504" target="_blank" rel="external">sbp810050504的blog</a></p>
<p><a href="https://www.cnblogs.com/forfuture1978/" target="_blank" rel="external">刘超觉先的博客</a></p>
<p><a href="https://www.manning.com/books/lucene-in-action-second-edition" target="_blank" rel="external">Lucene in Action</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近2年，整个开源搜索引擎领域，发展迅速，版本迭代很快。 Lucene最近两年从4.0版本已经发布到最新的7.5.0版本，Solr和Elasticsearch也不断跟进升级。Lucene作为核心包，互联网上或者是书籍上关于它的介绍和分析都比较陈旧了，很多都是基于Lucene3.x来。是时候，从底层来分析下最新的Lucene发展情况了。&lt;/p&gt;
&lt;p&gt;本文，依Lucene 7.5.0（当时最新）版本描述。&lt;/p&gt;
&lt;h3 id=&quot;Lucene索引文件的表现&quot;&gt;&lt;a href=&quot;#Lucene索引文件的表现&quot; class=&quot;headerlink&quot; title=&quot;Lucene索引文件的表现&quot;&gt;&lt;/a&gt;Lucene索引文件的表现&lt;/h3&gt;&lt;p&gt;Lucene索引在硬盘上的&lt;strong&gt;表现&lt;/strong&gt;就是一系列的文件，后缀名不同，下面是一个样例：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/lucene-index-files/lucene-index-on-disk.jpg&quot; alt=&quot;lucene 索引文件&quot;&gt;&lt;/p&gt;
&lt;p&gt;通常，看到这些文件，我们就想打开看看，发现根本无法直接查看。这里存的到底是什么，都有什么作用。很多时候是一脸的懵。为了更好的理解这些文件，下面将一步步进行细致的分析。&lt;/p&gt;
    
    </summary>
    
      <category term="lucene" scheme="https://www.shenyanchao.cn/categories/lucene/"/>
    
    
      <category term="lucene" scheme="https://www.shenyanchao.cn/tags/lucene/"/>
    
      <category term="index" scheme="https://www.shenyanchao.cn/tags/index/"/>
    
      <category term="lucene7" scheme="https://www.shenyanchao.cn/tags/lucene7/"/>
    
  </entry>
  
  <entry>
    <title>Lucene数字类型处理</title>
    <link href="https://www.shenyanchao.cn/blog/2018/12/04/lucene-numberic/"/>
    <id>https://www.shenyanchao.cn/blog/2018/12/04/lucene-numberic/</id>
    <published>2018-12-04T04:35:48.000Z</published>
    <updated>2018-12-04T13:49:18.932Z</updated>
    
    <content type="html"><![CDATA[<p>TODO</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;TODO&lt;/p&gt;

    
    </summary>
    
    
      <category term="lucene" scheme="https://www.shenyanchao.cn/tags/lucene/"/>
    
  </entry>
  
  <entry>
    <title>关于Lucene的词典FST深入剖析</title>
    <link href="https://www.shenyanchao.cn/blog/2018/12/04/lucene-fst/"/>
    <id>https://www.shenyanchao.cn/blog/2018/12/04/lucene-fst/</id>
    <published>2018-12-04T04:35:25.000Z</published>
    <updated>2018-12-20T11:59:20.155Z</updated>
    
    <content type="html"><![CDATA[<h3 id="搜索引擎为什么能查询速度那么快？"><a href="#搜索引擎为什么能查询速度那么快？" class="headerlink" title="搜索引擎为什么能查询速度那么快？"></a>搜索引擎为什么能查询速度那么快？</h3><p>核心是在于如何快速的依据<strong>查询词</strong>快速的查找到所有的相关文档，这也是<strong>倒排索引（Inverted Index）</strong>的核心思想。那么如何设计一个快速的(常量，或者1)定位词典的数据结构就显得尤其重要。简单来说，我们可以采用HashMap， TRIE， Binary Search Tree， Tenary Search Tree等各种数据结构来实现。</p>
<p>那么开源的搜索引擎包Lucene是怎么来设计的呢？Lucene采用了一种称为FST（Finite State Transducer）的结构来构建词典，这个结构保证了时间和空间复杂度的均衡，是Lucene的核心功能之一。</p>
<h3 id="关于FST（Finite-State-Transducer）"><a href="#关于FST（Finite-State-Transducer）" class="headerlink" title="关于FST（Finite State Transducer）"></a>关于FST（Finite State Transducer）</h3><p>FST类似一种TRIE树。</p>
<h4 id="使用FSM-Finite-State-Machines-作为数据结构"><a href="#使用FSM-Finite-State-Machines-作为数据结构" class="headerlink" title="使用FSM(Finite State Machines)作为数据结构"></a>使用FSM(Finite State Machines)作为数据结构</h4><p><strong>FSM(Finite State Machines)有限状态机</strong>: 表示有限个状态（State）集合以及这些状态之间<strong>转移</strong>和动作的数学模型。其中一个状态被标记为<strong>开始状态</strong>，0个或更多的状态被标记为<strong>final状态</strong>。<br>一个FSM同一时间只处于1个状态。FSM很通用，可以用来表示多种处理过程，下面的FSM描述了《小猫咪的一天》。   </p>
<p><img src="/images/lucene-fst/fst/fst-cauchy.png" alt="fsm 小猫咪的一天"></p>
<p>其中“睡觉”或者“吃饭”代表的是<strong>状态</strong>,而“提供食物”或者“东西移动”则代表了<strong>转移</strong>。图中这个FSM是对小猫活动的一个抽象（这里并没有刻意写开始状态或者final状态），小猫咪不能同时的即处于“玩耍”又处于“睡觉”状态，并且从一个状态到下一个状态的转换只有一个输入。“睡觉”状态并不知道是从什么状态转换过来的，可能是“玩耍”，也可能是”猫砂窝”。</p>
<p>如果《小猫咪的一天》这个FSM接收以下的输入:  </p>
<ul>
<li>提供食物</li>
<li>有大声音</li>
<li>安静</li>
<li>消化食物</li>
</ul>
<p>那么我们会明确的知道，小猫咪会这样依次变化状态： 睡觉-&gt;吃饭-&gt;躲藏-&gt;吃饭-&gt;猫砂窝. </p>
<a id="more"></a>
<p>以上只是一个现实中的例子，下面我们来看如何实现一个Ordered Sets,和Map结构。</p>
<h4 id="Ordered-Sets"><a href="#Ordered-Sets" class="headerlink" title="Ordered Sets"></a>Ordered Sets</h4><p>Ordered Sets是一个有序集合。通常一个有序集合可以用二叉树、B树实现。无序的集合使用hash table来实现. 这里，我们用一个<strong>确定无环有限状态接收机（Deterministric acyclic finite state acceptor, FSA）</strong>来实现。</p>
<p>FSA是一个FSM(有限状态机)的一种，特性如下:</p>
<ul>
<li>确定：意味着指定任何一个状态，只可能最多有一个转移可以遍历到?。</li>
<li>无环： 不可能重复遍历同一个状态</li>
<li>接收机：有限状态机只“接受”特定的输入序列，并终止于final状态。</li>
</ul>
<p>下面来看，我们如何来表示只有一个key：”<strong>jul</strong>“ 的集合。FSA是这样的：   </p>
<p><img src="/images/lucene-fst/fst/fst-set1.png" alt="fsm"></p>
<p>当查询这个FSA是否包含“jul”的时候，按字符依序输入。</p>
<ul>
<li>输入j，FSA从0-&gt;1</li>
<li>输入u, FSA从1-&gt;2</li>
<li>输入l，FSA从2-&gt;3</li>
</ul>
<p>这个时候，FSA处于final状态3，所以“jul”是在这个集合的。 </p>
<p>设想一下如果输入“jun”，在状态2的时候<strong>无法移动</strong>了，就知道不在这个集合里了。<br>设想如何输入“ju”, 在状态2的时候，已经没有输入了。而状态2并不是<strong>final状态</strong>，所以也不在这个集合里。<br>值得指出的是，查找这个key是否在集合内的时间复杂度，取决于key的长度，而不是集合的大小。<br>​<br>现在往FSA里再加一个key.  FSA此时包含keys:”jul”和“mar”。    </p>
<p><img src="/images/lucene-fst/fst/fst-set2.png" alt="fsm"></p>
<p>start状态0此时有了2个转移：<strong>j</strong>和<strong>m</strong>。因此，输入key:”mar”,首先会跟随m来转移。 final状态是“jul”和“mar”<strong>共享</strong>的。这使得我们能用<strong>更少的空间</strong>来表示<strong>更多的信息</strong>。 </p>
<p>当我们在这个FSA里加入“jun”，那么它和“jul”有共同的前缀“ju”: </p>
<p><img src="/images/lucene-fst/fst/fst-set3.png" alt="fsm"></p>
<p>这里变化很小，没有增加新的状态，只是多了一个转移而已。</p>
<p>下面来看一下由“october”，“november”,”december”构成的FSA.</p>
<p><img src="/images/lucene-fst/fst/fst-set3-suffixes.png" alt="fsm"></p>
<p>它们有共同的后缀“ber”，所以在FSA只出现了1次。 其中2个有共同的后缀”ember”，也只出现了1次。    </p>
<p>那么我们如何来遍历一个FSA表示的所有key呢，我们以前面的”jul”，“jun”,”mar”为例：</p>
<p><img src="/images/lucene-fst/fst/fst-set3.png" alt="fsm"></p>
<p><strong>遍历算法</strong>是这样的：</p>
<ul>
<li>初始状态0， key=””</li>
<li>-&gt;1, key=”j”</li>
<li>-&gt;2, key=”ju”</li>
<li>-&gt;3, key=”jul”, 找到jul</li>
<li>2&lt;-, key=”ju”</li>
<li>-&gt;3, key=”jun”, 找到jun</li>
<li>2&lt;-, key=”ju”</li>
<li>1&lt;-, key=”j”</li>
<li>0&lt;-, key=””</li>
<li>-&gt;4, key=”m”</li>
<li>-&gt;5, key=”ma”,</li>
<li>-&gt;3, key=”mar”,找到mar</li>
</ul>
<p>这个算法时间复杂度O(n),n是集合里所有的key的大小, 空间复杂度O(k),k是结合内最长的key字段length。</p>
<h4 id="Ordered-maps"><a href="#Ordered-maps" class="headerlink" title="Ordered maps"></a>Ordered maps</h4><p>Ordered maps就像一个普通的map，只不过它的key是有序的。我们来看一下如何使用<strong>确定无环状态转换器（Deterministic acyclic finite state transducer， FST）</strong>来实现它。</p>
<p>FST是也一个有限状态机（FSM）,具有这样的特性：  </p>
<ul>
<li>确定：意味着指定任何一个状态，只可能最多有一个转移可以遍历到。</li>
<li>无环： 不可能重复遍历同一个状态</li>
<li>transducer：接收特定的序列，终止于final状态，同时会<strong>输出一个值</strong>。</li>
</ul>
<p>FST和FSA很像，给定一个key除了能回答是否存在，还能输出一个<strong>关联的值</strong>。  </p>
<p>下面来看这样的一个输入：“jul:7”, 7是jul关联的值，就像是一个map的entry. </p>
<p><img src="/images/lucene-fst/fst/fst-map1.png" alt="fst"></p>
<p>这和对应的有序集合基本一样，除了第一个0-&gt;1的转换j关联了一个值7. 其他的转换u和l,<strong>默认关联</strong>的值是<strong>0</strong>,这里不予展现。  </p>
<p>那么当我们查找key:”jul”的时候，大概流程如下：</p>
<ul>
<li>初始状态0 </li>
<li>输入j, FST从0-&gt;1， value=7</li>
<li>输入u， FST从1-&gt;2， value=7+0</li>
<li>输入l，FST从2-&gt;3, value=7+0+0</li>
</ul>
<p>此时，FST处于final状态3，所以存在jul，并且给出output是7.</p>
<p>我们再看一下，加入mar:3之后，FST变成什么样：</p>
<p><img src="/images/lucene-fst/fst/fst-map2.png" alt="fst"></p>
<p>同样的很简单，<strong>需要注意</strong>的是mar自带的值3放在了第1个转移上。这只是为了算法更简单而已，事实上，可以放在其他转移上。  </p>
<p>如果共享前缀，FST会发生什么呢？这里我们继续加入jun:6。</p>
<p><img src="/images/lucene-fst/fst/fst-map3.png" alt="fst"></p>
<p>和sets一样，jun和jul共享状态3， 但是有一些变化。</p>
<ul>
<li>0-&gt;1转移，输出从7变成了6</li>
<li>2-&gt;3转移，输入l，输出值变成了1。</li>
</ul>
<p>这个输出变化是很重要的，因为他改变了查找jul输出值的过程。</p>
<ul>
<li>初始状态0</li>
<li>输入j, FST从0-&gt;1， value=6</li>
<li>输入u， FST从1-&gt;2， value=6+0</li>
<li>输入l，FST从2-&gt;3, value=6+0+1</li>
</ul>
<p>最终的值仍旧是7，但是走的路径却是不一样的。<br>那查找jun是不是也是正确的呢？</p>
<ul>
<li>初始状态0</li>
<li>输入j, FST从0 -&gt; 1， value=6</li>
<li>输入u，FST从1 -&gt; 2， value=6+0</li>
<li>输入n，FST从2 -&gt; 3, value=6+0+0</li>
</ul>
<p>从上可知，jun的查询也是正确的。FST保证了不同的转移有<strong>唯一</strong>的值，但同时也复用了大部分的数据结构。    </p>
<p>实现共享状态的<strong>关键点</strong>是：每一个key,都在FST中对应一个唯一的路径。因此，对于任何一个特定的key，总会有一些value的转移组合使得路径是唯一的。我们需要做的就是如何来在转移中<strong>分配</strong>这些组合。</p>
<p>key输出的共享机制同样适用于共同前缀和共同后缀。比如我们有tuesday:3和thursday:5这样的FST:   </p>
<p><img src="/images/lucene-fst/fst/fst-map2-suffixes.png" alt="fst"></p>
<p>2个key有共同的前缀<strong>t</strong>，共同后缀<strong>sday</strong>。关联的2个value同样有共同的前缀。3可以写做<strong>3+0</strong>，而5可以写作：<strong>3+2</strong>。 这样很好的让实现了关联value的共享。   </p>
<p>上面的这个例子，其实有点简单化，并且局限。假如这些关联的value并不是int呢？ 实际上，FST对于关联value(outputs)的类型是要求必须有以下操作（method）的。</p>
<ul>
<li>加（Addition）</li>
<li>减 (Subtraction)</li>
<li>取前缀 (对于整数来说，就是min)</li>
</ul>
<h3 id="FST的构建"><a href="#FST的构建" class="headerlink" title="FST的构建"></a>FST的构建</h3><p>前面，一直没有提到如何构建FST。构建相对于遍历来说，还是有些复杂的。<br>为了简单化，我们假设set或者map里的数据是按字典序加入的。这个假设是很沉重的限制，不过我们会讲如何来缓解它。</p>
<p>为了构建FSM，我们先来看看TRIE树是如何构建的。</p>
<h4 id="TRIE树的构建"><a href="#TRIE树的构建" class="headerlink" title="TRIE树的构建"></a>TRIE树的构建</h4><p>TRIE可以看做是一个FSA,唯一的一个不同是TRIE只共享前缀，而FSA不仅共享前缀还共享后缀。</p>
<p>假设我们有一个这样的Set: mon,tues,thurs。FSA是这样的： </p>
<p><img src="/images/lucene-fst/fst/fst-days3.png" alt="fst"></p>
<p>相应的TRIE则是这样的，只共享了前缀。</p>
<p><img src="/images/lucene-fst/fst/fst-days3-trie.png" alt="fst trie"></p>
<p>TRIE有重复的3个final状态3，8，11. 而8，11都是s转移，是可以合并的。</p>
<p>构建一个TRIE树是相当简单的。插入1个key，只需要做简单的查找就可以了。如果输入先结束，那么当前状态设置为final；如果无法转移了，那么就直接创建新的转移和状态。不要忘了最后一个创建的状态设置为final就可以了。</p>
<h4 id="FST的构建-1"><a href="#FST的构建-1" class="headerlink" title="FST的构建"></a>FST的构建</h4><p>构建FST在很大程度上和构建FSA是一样的，主要的不同点是，怎么样在转移上<strong>放置和共享outputs</strong>。   </p>
<p>仍旧使用前面提到的例子，mon,tues和thurs，并给他们关联相应的星期数值2，3和5.  </p>
<p>从第1个key, mon:2开始：</p>
<p><img src="/images/lucene-fst/fst/fst-days3-fst-1.png" alt="fst mon">   </p>
<p>这里虚线代表，在后续的insert过程中，FST可能有变化。    </p>
<p>需要关注的是，这里只是把2放在了第1个转移上。技术上说，下面这样分配也是正确的。</p>
<p><img src="/images/lucene-fst/fst/fst-days3-fst-1-alt.png" alt="fst mon alt">   </p>
<p>只不过，把output放在靠近start状态的算法更容易写而已。</p>
<p>下面继续把thurs:5插入：</p>
<p><img src="/images/lucene-fst/fst/fst-days3-fst-2.png" alt="fst mon thurs">   </p>
<p>就像FSA的insert一样，插入thurs之后，我们可以知道FST的mon部分（蓝色）就不会再变了。</p>
<p>由于mon和thurs没有共同的前缀，只是简单的2个map中的key. 所以他们的output value可以直接放置在start状态的第1个转移上。</p>
<p>下面，继续插入tues:3，</p>
<p><img src="/images/lucene-fst/fst/fst-days3-fst-3.png" alt="fst">   </p>
<p>这引起了新的变化。有一部分被<strong>冻住</strong>了，并且知道以后不会再修改了。output value也出现了重新的分配。因为tues的output是3，并且tues和thurs有共同的前缀t, 所以5和3的prefix操作得出的结果就是3. 状态0-&gt;状态4的value被分配为3，状态4-&gt;状态5设置为2。</p>
<p>我们再插入更多的key, 这次插入tye:99看发生什么情况：</p>
<p><img src="/images/lucene-fst/fst/fst-days3-fst-4.png" alt="fst">   </p>
<p>插入tye，导致”es”部分被冻住，同时由于共享前缀t, 状态4-&gt;状态9的输出是99-3=96。</p>
<p>最后一步，结束了，再执行一次冻住操作。</p>
<p>最终的FST长这样：</p>
<p><img src="/images/lucene-fst/fst/fst-days3-fst-5.png" alt="fst">   </p>
<h3 id="Lucene-FST"><a href="#Lucene-FST" class="headerlink" title="Lucene FST"></a>Lucene FST</h3><p>上一部分，对于FST的概念以及构建进行了详细的介绍。本部分将对Lucene FST的实现以及具体进行详细的分析。<br>Lucene关于FST相关的代码在package:<code>org.apache.lucene.util.fst</code>。    </p>
<p>从<code>org.apache.lucene.util.fst.Builder</code>看起，这个是构建FST的Builder：</p>
<p><img src="/images/lucene-fst/fst/lucene-fst-builder.png" alt="fst builder lucene">   </p>
<p>Builder通过泛型T，从而可以构建包含不同类型的FST。我们重点关注属性。</p>
<p>从其中插入数据<code>add()</code>方法看起： </p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/** Add the next input/output pair.  The provided input</span></div><div class="line">   *  must be sorted after the previous one according to</div><div class="line">   *  &#123;<span class="doctag">@link</span> IntsRef#compareTo&#125;.  It's also OK to add the same</div><div class="line">   *  input twice in a row with different outputs, as long</div><div class="line">   *  as &#123;<span class="doctag">@link</span> Outputs&#125; implements the &#123;<span class="doctag">@link</span> Outputs#merge&#125;</div><div class="line">   *  method. Note that input is fully consumed after this</div><div class="line">   *  method is returned (so caller is free to reuse), but</div><div class="line">   *  output is not.  So if your outputs are changeable (eg</div><div class="line">   *  &#123;<span class="doctag">@link</span> ByteSequenceOutputs&#125; or &#123;<span class="doctag">@link</span></div><div class="line">   *  IntSequenceOutputs&#125;) then you cannot reuse across</div><div class="line">   *  calls. */</div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">add</span><span class="params">(IntsRef input, T output)</span> <span class="keyword">throws</span> IOException </span>&#123;</div><div class="line"></div><div class="line">    ...</div><div class="line">    <span class="comment">// prefixLenPlus1是计算出input和lastInput具有公共前缀的位置</span></div><div class="line">    <span class="keyword">final</span> <span class="keyword">int</span> prefixLenPlus1 = pos1+<span class="number">1</span>;</div><div class="line"></div><div class="line">     <span class="comment">// 1.新插入的节点放到frontier数组，UnCompileNode表明是新插入的，以后还可能会变化，还未放入FST内。</span></div><div class="line">    <span class="keyword">if</span> (frontier.length &lt; input.length+<span class="number">1</span>) &#123;</div><div class="line">      <span class="keyword">final</span> UnCompiledNode&lt;T&gt;[] next = ArrayUtil.grow(frontier, input.length+<span class="number">1</span>);</div><div class="line">      <span class="keyword">for</span>(<span class="keyword">int</span> idx=frontier.length;idx&lt;next.length;idx++) &#123;</div><div class="line">        next[idx] = <span class="keyword">new</span> UnCompiledNode&lt;&gt;(<span class="keyword">this</span>, idx);</div><div class="line">      &#125;</div><div class="line">      frontier = next;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// minimize/compile states from previous input's</span></div><div class="line">    <span class="comment">// orphan'd suffix</span></div><div class="line"></div><div class="line">    <span class="comment">// 2.从prefixLenPlus1, 进行freeze冰冻操作, 添加并构建最小FST</span></div><div class="line">    freezeTail(prefixLenPlus1);</div><div class="line"></div><div class="line">    <span class="comment">// init tail states for current input</span></div><div class="line">    <span class="comment">// 3.将当前input剩下的部分插入，构建arc转移（前缀是共用的，不用添加新的状态）。</span></div><div class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> idx=prefixLenPlus1;idx&lt;=input.length;idx++) &#123;</div><div class="line">      frontier[idx-<span class="number">1</span>].addArc(input.ints[input.offset + idx - <span class="number">1</span>],</div><div class="line">                             frontier[idx]);</div><div class="line">      frontier[idx].inputCount++;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">final</span> UnCompiledNode&lt;T&gt; lastNode = frontier[input.length];</div><div class="line">    <span class="keyword">if</span> (lastInput.length() != input.length || prefixLenPlus1 != input.length + <span class="number">1</span>) &#123;</div><div class="line">      lastNode.isFinal = <span class="keyword">true</span>;</div><div class="line">      lastNode.output = NO_OUTPUT;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// push conflicting outputs forward, only as far as</span></div><div class="line">    <span class="comment">// needed</span></div><div class="line">    <span class="comment">// 4.如果有冲突的话，重新分配output值</span></div><div class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> idx=<span class="number">1</span>;idx&lt;prefixLenPlus1;idx++) &#123;</div><div class="line">      <span class="keyword">final</span> UnCompiledNode&lt;T&gt; node = frontier[idx];</div><div class="line">      <span class="keyword">final</span> UnCompiledNode&lt;T&gt; parentNode = frontier[idx-<span class="number">1</span>];</div><div class="line"></div><div class="line">      <span class="keyword">final</span> T lastOutput = parentNode.getLastOutput(input.ints[input.offset + idx - <span class="number">1</span>]);</div><div class="line">      <span class="function"><span class="keyword">assert</span> <span class="title">validOutput</span><span class="params">(lastOutput)</span></span>;</div><div class="line"></div><div class="line">      <span class="keyword">final</span> T commonOutputPrefix;</div><div class="line">      <span class="keyword">final</span> T wordSuffix;</div><div class="line"></div><div class="line">      <span class="keyword">if</span> (lastOutput != NO_OUTPUT) &#123;</div><div class="line">        <span class="comment">// 使用common方法，计算output的共同前缀</span></div><div class="line">        commonOutputPrefix = fst.outputs.common(output, lastOutput);</div><div class="line">        <span class="function"><span class="keyword">assert</span> <span class="title">validOutput</span><span class="params">(commonOutputPrefix)</span></span>;</div><div class="line">        <span class="comment">// 使用subtract方法，计算重新分配的output</span></div><div class="line">        wordSuffix = fst.outputs.subtract(lastOutput, commonOutputPrefix);</div><div class="line">        <span class="function"><span class="keyword">assert</span> <span class="title">validOutput</span><span class="params">(wordSuffix)</span></span>;</div><div class="line">        parentNode.setLastOutput(input.ints[input.offset + idx - <span class="number">1</span>], commonOutputPrefix);</div><div class="line">        node.prependOutput(wordSuffix);</div><div class="line">      &#125; <span class="keyword">else</span> &#123;</div><div class="line">        commonOutputPrefix = wordSuffix = NO_OUTPUT;</div><div class="line">      &#125;</div><div class="line">      output = fst.outputs.subtract(output, commonOutputPrefix);</div><div class="line">      <span class="function"><span class="keyword">assert</span> <span class="title">validOutput</span><span class="params">(output)</span></span>;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    ...</div><div class="line">  &#125;</div></pre></td></tr></table></figure>
<p>通过注释，我们看到input是经过排序的，也就是ordered。否则生成的就不是最小的FST。另外如果NO_OUTPUT就退化为FSA了，不用执行第4步重新分配output了。</p>
<p>其中<code>freezeTail</code> 方法就是将不再变化的部分进行冰冻，又叫compile，把UnCompileNode，给构建进FST里。进入到FST是先进行compileNode, 然后addNode进去的。</p>
<p>总结以下，加入节点过程：</p>
<ul>
<li><ol>
<li>新插入input放入frontier，这里还没有加入FST</li>
</ol>
</li>
<li><ol>
<li>依据当前input, 对上次插入数据进行freezeTail操作, 放入FST内</li>
</ol>
</li>
<li><ol>
<li>构建input的转移（Arc）关系</li>
</ol>
</li>
<li><ol>
<li>解决Output冲突，重新分配output，保证路径统一(NO_OUTPUT,不执行)</li>
</ol>
</li>
</ul>
<p>最后在<code>finish</code>方法里，执行<code>freezeTail(0)</code>, 把所有的input构建进FST内。</p>
<p>另外，值得注意的是Lucene里定义的<strong>Outputs</strong>类型：</p>
<p><img src="/images/lucene-fst/fst/lucene-fst-outputs.png" alt="fst">  </p>
<p>其中3个method是Outputs接口定义的，有11个不同类型的实现:</p>
<ul>
<li><code>T add(T prefix, T output);</code> 加</li>
<li><code>T subtract(T output, T inc);</code> 减</li>
<li><code>T common(T output1, T output2)</code> 前缀</li>
</ul>
<p>完全满足我们上个部分的限制，可见就是基于之前算法的一个完整的实现。    </p>
<p>除了在Term词典这块有应用，FST在整个lucene内部使用的也是很广泛的，基本把hashmap记性了替换。<br>场景大概有以下：  </p>
<ul>
<li>自动联想：suggester</li>
<li>charFilter: mappingcharFilter</li>
<li>同义词过滤器</li>
<li>hunspell拼写检查词典</li>
</ul>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>FST，不但能<strong>共享前缀</strong>还能<strong>共享后缀</strong>。不但能判断查找的key是否存在，还能给出响应的输入output。 它在时间复杂度和空间复杂度上都做了最大程度的优化，使得Lucene能够将Term Dictionary完全加载到内存，快速的定位Term找到响应的output（posting倒排列表）。</p>
<hr>
<p>参考文档：   </p>
<p><a href="http://www.cs.uvm.edu/~xwu/wie/CourseSlides/Schips-BurstTries.pdf" target="_blank" rel="external">Burst Tries</a><br><a href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.24.3698" target="_blank" rel="external">Direct Construction of Minimal Acyclic Subsequential Transducers</a><br><a href="https://blog.burntsushi.net/transducers/" target="_blank" rel="external">Index 1,600,000,000 Keys with Automata and Rust</a><br><a href="https://en.wikipedia.org/wiki/DFA_minimization" target="_blank" rel="external">DFA minimization WikiPedia</a><br><a href="http://www.cs.put.poznan.pl/dweiss/site/publications/download/fsacomp.pdf" target="_blank" rel="external">Smaller Representation of Finite State Automata</a><br><a href="http://blog.mikemccandless.com/2010/12/using-finite-state-transducers-in.html" target="_blank" rel="external">Using Finite State Transducers in Lucene</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;搜索引擎为什么能查询速度那么快？&quot;&gt;&lt;a href=&quot;#搜索引擎为什么能查询速度那么快？&quot; class=&quot;headerlink&quot; title=&quot;搜索引擎为什么能查询速度那么快？&quot;&gt;&lt;/a&gt;搜索引擎为什么能查询速度那么快？&lt;/h3&gt;&lt;p&gt;核心是在于如何快速的依据&lt;strong&gt;查询词&lt;/strong&gt;快速的查找到所有的相关文档，这也是&lt;strong&gt;倒排索引（Inverted Index）&lt;/strong&gt;的核心思想。那么如何设计一个快速的(常量，或者1)定位词典的数据结构就显得尤其重要。简单来说，我们可以采用HashMap， TRIE， Binary Search Tree， Tenary Search Tree等各种数据结构来实现。&lt;/p&gt;
&lt;p&gt;那么开源的搜索引擎包Lucene是怎么来设计的呢？Lucene采用了一种称为FST（Finite State Transducer）的结构来构建词典，这个结构保证了时间和空间复杂度的均衡，是Lucene的核心功能之一。&lt;/p&gt;
&lt;h3 id=&quot;关于FST（Finite-State-Transducer）&quot;&gt;&lt;a href=&quot;#关于FST（Finite-State-Transducer）&quot; class=&quot;headerlink&quot; title=&quot;关于FST（Finite State Transducer）&quot;&gt;&lt;/a&gt;关于FST（Finite State Transducer）&lt;/h3&gt;&lt;p&gt;FST类似一种TRIE树。&lt;/p&gt;
&lt;h4 id=&quot;使用FSM-Finite-State-Machines-作为数据结构&quot;&gt;&lt;a href=&quot;#使用FSM-Finite-State-Machines-作为数据结构&quot; class=&quot;headerlink&quot; title=&quot;使用FSM(Finite State Machines)作为数据结构&quot;&gt;&lt;/a&gt;使用FSM(Finite State Machines)作为数据结构&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;FSM(Finite State Machines)有限状态机&lt;/strong&gt;: 表示有限个状态（State）集合以及这些状态之间&lt;strong&gt;转移&lt;/strong&gt;和动作的数学模型。其中一个状态被标记为&lt;strong&gt;开始状态&lt;/strong&gt;，0个或更多的状态被标记为&lt;strong&gt;final状态&lt;/strong&gt;。&lt;br&gt;一个FSM同一时间只处于1个状态。FSM很通用，可以用来表示多种处理过程，下面的FSM描述了《小猫咪的一天》。   &lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/lucene-fst/fst/fst-cauchy.png&quot; alt=&quot;fsm 小猫咪的一天&quot;&gt;&lt;/p&gt;
&lt;p&gt;其中“睡觉”或者“吃饭”代表的是&lt;strong&gt;状态&lt;/strong&gt;,而“提供食物”或者“东西移动”则代表了&lt;strong&gt;转移&lt;/strong&gt;。图中这个FSM是对小猫活动的一个抽象（这里并没有刻意写开始状态或者final状态），小猫咪不能同时的即处于“玩耍”又处于“睡觉”状态，并且从一个状态到下一个状态的转换只有一个输入。“睡觉”状态并不知道是从什么状态转换过来的，可能是“玩耍”，也可能是”猫砂窝”。&lt;/p&gt;
&lt;p&gt;如果《小猫咪的一天》这个FSM接收以下的输入:  &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;提供食物&lt;/li&gt;
&lt;li&gt;有大声音&lt;/li&gt;
&lt;li&gt;安静&lt;/li&gt;
&lt;li&gt;消化食物&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;那么我们会明确的知道，小猫咪会这样依次变化状态： 睡觉-&amp;gt;吃饭-&amp;gt;躲藏-&amp;gt;吃饭-&amp;gt;猫砂窝. &lt;/p&gt;
    
    </summary>
    
      <category term="lucene" scheme="https://www.shenyanchao.cn/categories/lucene/"/>
    
    
      <category term="lucene" scheme="https://www.shenyanchao.cn/tags/lucene/"/>
    
      <category term="FST" scheme="https://www.shenyanchao.cn/tags/FST/"/>
    
      <category term="FSM" scheme="https://www.shenyanchao.cn/tags/FSM/"/>
    
      <category term="FSA" scheme="https://www.shenyanchao.cn/tags/FSA/"/>
    
  </entry>
  
  <entry>
    <title>利用MAT来分析JAVA内存泄露</title>
    <link href="https://www.shenyanchao.cn/blog/2018/10/29/mat-for-java/"/>
    <id>https://www.shenyanchao.cn/blog/2018/10/29/mat-for-java/</id>
    <published>2018-10-29T06:53:46.000Z</published>
    <updated>2018-12-20T11:59:51.866Z</updated>
    
    <content type="html"><![CDATA[<h3 id="如何DUMP出堆栈"><a href="#如何DUMP出堆栈" class="headerlink" title="如何DUMP出堆栈"></a>如何DUMP出堆栈</h3><h4 id="手动dump"><a href="#手动dump" class="headerlink" title="手动dump"></a>手动dump</h4><pre><code>jmap -dump:format=b,file=&lt;dumpfile.hprof&gt; &lt;pid&gt;
</code></pre><h4 id="JVM参数自动dump"><a href="#JVM参数自动dump" class="headerlink" title="JVM参数自动dump"></a>JVM参数自动dump</h4><pre><code>-XX:+HeapDumpOnOutOfMemoryError
-XX:HeapDumpPath=${heap.dump.path}
</code></pre><h3 id="下载并调整MAT-Eclipse-Memory-Analyze-Tool"><a href="#下载并调整MAT-Eclipse-Memory-Analyze-Tool" class="headerlink" title="下载并调整MAT(Eclipse Memory Analyze Tool)"></a>下载并调整MAT(Eclipse Memory Analyze Tool)</h3><p>下载地址： <a href="https://www.eclipse.org/mat/downloads.php" target="_blank" rel="external">https://www.eclipse.org/mat/downloads.php</a></p>
<p><img src="/images/blog/mat/mat-for-java.jpg" alt="mat"></p>
<p>依据不同的操作系统下载响应版本。</p>
<a id="more"></a>
<h3 id="解析dump出的文件"><a href="#解析dump出的文件" class="headerlink" title="解析dump出的文件"></a>解析dump出的文件</h3><p>通常情况下，dump出的文件是很大的。需要修改一下MemoryAnalyzer.ini，调大<code>-Xmx</code>参数,至少要比要分析的文件相等。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">-startup</div><div class="line">../Eclipse/plugins/org.eclipse.equinox.launcher_1.5.0.v20180512-1130.jar</div><div class="line">--launcher.library</div><div class="line">../Eclipse/plugins/org.eclipse.equinox.launcher.cocoa.macosx.x86_64_1.1.700.v20180518-1200</div><div class="line">-vmargs</div><div class="line">-Xmx10G</div><div class="line">-Dorg.eclipse.swt.internal.carbon.smallFonts</div><div class="line">-XstartOnFirstThread</div></pre></td></tr></table></figure>
<h3 id="无界面执行（LINUX）"><a href="#无界面执行（LINUX）" class="headerlink" title="无界面执行（LINUX）"></a>无界面执行（LINUX）</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">./ParseHeapDump.sh $&#123;dump.prof&#125; org.eclipse.mat.api:suspects</div></pre></td></tr></table></figure>
<p>还支持另外两个：</p>
<p>org.eclipse.mat.api:overview<br>org.eclipse.mat.api:top_components</p>
<p>执行之后，产生多个zip版html。不过这个版本，没有直接分析出来的好用，有些功能有缺失。</p>
<hr>
<p>其他线上问题常见分析工具：</p>
<p><a href="https://github.com/blueshen/useful-scripts" target="_blank" rel="external">https://github.com/blueshen/useful-scripts</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;如何DUMP出堆栈&quot;&gt;&lt;a href=&quot;#如何DUMP出堆栈&quot; class=&quot;headerlink&quot; title=&quot;如何DUMP出堆栈&quot;&gt;&lt;/a&gt;如何DUMP出堆栈&lt;/h3&gt;&lt;h4 id=&quot;手动dump&quot;&gt;&lt;a href=&quot;#手动dump&quot; class=&quot;headerlink&quot; title=&quot;手动dump&quot;&gt;&lt;/a&gt;手动dump&lt;/h4&gt;&lt;pre&gt;&lt;code&gt;jmap -dump:format=b,file=&amp;lt;dumpfile.hprof&amp;gt; &amp;lt;pid&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;JVM参数自动dump&quot;&gt;&lt;a href=&quot;#JVM参数自动dump&quot; class=&quot;headerlink&quot; title=&quot;JVM参数自动dump&quot;&gt;&lt;/a&gt;JVM参数自动dump&lt;/h4&gt;&lt;pre&gt;&lt;code&gt;-XX:+HeapDumpOnOutOfMemoryError
-XX:HeapDumpPath=${heap.dump.path}
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;下载并调整MAT-Eclipse-Memory-Analyze-Tool&quot;&gt;&lt;a href=&quot;#下载并调整MAT-Eclipse-Memory-Analyze-Tool&quot; class=&quot;headerlink&quot; title=&quot;下载并调整MAT(Eclipse Memory Analyze Tool)&quot;&gt;&lt;/a&gt;下载并调整MAT(Eclipse Memory Analyze Tool)&lt;/h3&gt;&lt;p&gt;下载地址： &lt;a href=&quot;https://www.eclipse.org/mat/downloads.php&quot;&gt;https://www.eclipse.org/mat/downloads.php&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/blog/mat/mat-for-java.jpg&quot; alt=&quot;mat&quot;&gt;&lt;/p&gt;
&lt;p&gt;依据不同的操作系统下载响应版本。&lt;/p&gt;
    
    </summary>
    
      <category term="JVM" scheme="https://www.shenyanchao.cn/categories/JVM/"/>
    
    
      <category term="java" scheme="https://www.shenyanchao.cn/tags/java/"/>
    
      <category term="mat" scheme="https://www.shenyanchao.cn/tags/mat/"/>
    
      <category term="OOM" scheme="https://www.shenyanchao.cn/tags/OOM/"/>
    
  </entry>
  
  <entry>
    <title>微服务下的API设计原则</title>
    <link href="https://www.shenyanchao.cn/blog/2018/08/23/the-principle-of-api-design-in-mircoservice/"/>
    <id>https://www.shenyanchao.cn/blog/2018/08/23/the-principle-of-api-design-in-mircoservice/</id>
    <published>2018-08-23T09:05:00.000Z</published>
    <updated>2018-10-23T08:57:54.889Z</updated>
    
    <content type="html"><![CDATA[<h1 id="微服务下的API设计原则"><a href="#微服务下的API设计原则" class="headerlink" title="微服务下的API设计原则"></a>微服务下的API设计原则</h1><p>目的：<br>规范团队乃至公司的API设计。<br>主要参考： <a href="https://developer.github.com/v3/" target="_blank" rel="external">Github API</a></p>
<h2 id="1-为了安全，请使用HTTPS"><a href="#1-为了安全，请使用HTTPS" class="headerlink" title="1. 为了安全，请使用HTTPS"></a>1. 为了安全，请使用HTTPS</h2><p>与API设计无关、为了安全请使用HTTPS。公网API,强制使用HTTPS。内网API可酌情选择。</p>
<h2 id="2-API-地址和版本"><a href="#2-API-地址和版本" class="headerlink" title="2. API 地址和版本"></a>2. API 地址和版本</h2><p>在 <code>url</code> 中指定 API 的版本是个很好地做法。<br>如果 API 变化比较大，可以把API设计为子域名，比如 <code>https://api.ke.com/v3</code>；<br>也可以简单地把版本放在路径中，比如 <code>https://ke.com/api/v1</code>。<br><strong>不建议放入Header</strong>，不直观。</p>
<h2 id="3-schema请使用JSON"><a href="#3-schema请使用JSON" class="headerlink" title="3. schema请使用JSON"></a>3. schema请使用JSON</h2><p>对于响应返回的格式，JSON 因为它的可读性、紧凑性以及多种语言支持等优点，成为了 HTTP API 最常用的返回格式。因此，最好采用<strong>JSON</strong>作为返回内容的格式。</p>
<p><strong>不推荐其他格式</strong>，如果必须使用，比如 <code>xml</code>，应该在请求头部 <code>Accept</code> 中指定。<br>对于不支持的格式，服务端需要返回正确的 <code>status code</code>，并给出详细的说明。</p>
<a id="more"></a>
<h2 id="4-以资源为中心的URL设计"><a href="#4-以资源为中心的URL设计" class="headerlink" title="4. 以资源为中心的URL设计"></a>4. 以资源为中心的URL设计</h2><p>资源是 <code>Restful API</code> 的核心元素，所有的操作都是针对特定资源进行的。而资源就是 <code>URL</code>（Uniform Resoure Locator）表示的，所以简洁、清晰、结构化的 URL 设计是至关重要的。Github 可以说是这方面的典范，下面我们就拿 <code>repository</code> 来说明。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">/users/:username/repos</div><div class="line">/users/:org/repos</div><div class="line">/repos/:owner/:repo</div><div class="line">/repos/:owner/:repo/tags</div><div class="line">/repos/:owner/:repo/branches/:branch</div></pre></td></tr></table></figure>
<p>我们可以看到几个特性：</p>
<ul>
<li>资源分为单个文档和集合，尽量使用复数来表示资源，单个资源通过添加 id 或者 name 等来表示</li>
<li>一个资源可以有多个不同的 URL</li>
<li>资源可以嵌套，通过类似目录路径的方式来表示，以体现它们之间的关系</li>
</ul>
<p><strong>NOTE</strong>: 根据RFC3986定义，URL是大小写敏感的。<strong>建议全部使用小写字母</strong>。</p>
<h2 id="5-使用正确的HTTP-Method"><a href="#5-使用正确的HTTP-Method" class="headerlink" title="5. 使用正确的HTTP Method"></a>5. 使用正确的HTTP Method</h2><p>有了资源的 URL 设计，所有针对资源的操作都是使用 HTTP 方法指定的。比较常用的方法有：</p>
<table>
<thead>
<tr>
<th>METHOD</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>HEAD</td>
<td>只获取某个资源的头部信息。比如只想了解某个文件的大小，某个资源的修改日期等</td>
</tr>
<tr>
<td>GET</td>
<td>获取资源</td>
</tr>
<tr>
<td>POST</td>
<td>创建资源</td>
</tr>
<tr>
<td>PATCH</td>
<td>更新资源的部分属性。因为 PATCH 比较新，而且规范比较复杂，所以真正实现的比较少，一般都是用 POST 替代</td>
</tr>
<tr>
<td>PUT</td>
<td>替换资源，客户端需要提供新建资源的所有属性。如果新内容为空，要设置 <code>Content-Length</code> 为 0，以区别错误信息</td>
</tr>
<tr>
<td>DELETE</td>
<td>删除资源</td>
</tr>
</tbody>
</table>
<p>比如：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">GET /repos/:owner/:repo/issues</div><div class="line">GET /repos/:owner/:repo/issues/:number</div><div class="line">POST /repos/:owner/:repo/issues</div><div class="line">PATCH /repos/:owner/:repo/issues/:number</div><div class="line">DELETE /repos/:owner/:repo</div></pre></td></tr></table></figure>
<p>建议：依据公司的实际情况，不可能所有的服务都能符合RESTFUL标准。请重点学习使用<code>GET,POST,DELETE</code></p>
<h3 id="不符合-CRUD-的情况"><a href="#不符合-CRUD-的情况" class="headerlink" title="不符合 CRUD 的情况"></a>不符合 CRUD 的情况</h3><p>在实际资源操作中，总会有一些不符合 <code>CRUD</code>（Create-Read-Update-Delete） 的情况，一般有几种处理方法。</p>
<h4 id="使用-POST"><a href="#使用-POST" class="headerlink" title="使用 POST"></a>使用 POST</h4><p>为需要的动作增加一个 endpoint，使用 POST 来执行动作，比如 <code>POST /resend</code> 重新发送邮件。</p>
<h4 id="增加控制参数"><a href="#增加控制参数" class="headerlink" title="增加控制参数"></a>增加控制参数</h4><p>添加动作相关的参数，通过修改参数来控制动作。比如一个博客网站，会有把写好的文章“发布”的功能，可以用上面的 <code>POST /articles/{:id}/publish</code> 方法，也可以在文章中增加 <code>published:boolean</code> 字段，发布的时候就是更新该字段 <code>PUT /articles/{:id}?published=true</code></p>
<h4 id="把动作转换成资源"><a href="#把动作转换成资源" class="headerlink" title="把动作转换成资源"></a>把动作转换成资源</h4><p>把动作转换成可以执行 <code>CRUD</code> 操作的资源， github 就是用了这种方法。</p>
<p>比如“喜欢”一个 gist，就增加一个 <code>/gists/:id/star</code> 子资源，然后对其进行操作：“喜欢”使用 <code>PUT /gists/:id/star</code>，“取消喜欢”使用 <code>DELETE /gists/:id/star</code>。</p>
<p>另外一个例子是 <code>Fork</code>，这也是一个动作，但是在 gist 下面增加 <code>forks</code>资源，就能把动作变成 <code>CRUD</code> 兼容的：<code>POST /gists/:id/forks</code> 可以执行用户 fork 的动作。</p>
<h2 id="6-Query-让查询更自由"><a href="#6-Query-让查询更自由" class="headerlink" title="6. Query 让查询更自由"></a>6. Query 让查询更自由</h2><p>比如查询某个 repo 下面 issues 的时候，可以通过以下参数来控制返回哪些结果：</p>
<ul>
<li>state：issue 的状态，可以是 <code>open</code>，<code>closed</code>，<code>all</code></li>
<li>since：在指定时间点之后更新过的才会返回</li>
<li>assignee：被 assign 给某个 user 的 issues</li>
<li>sort：选择排序的值，可以是 <code>created</code>、<code>updated</code>、<code>comments</code></li>
<li>direction：排序的方向，升序（asc）还是降序（desc）</li>
<li>……</li>
</ul>
<h2 id="7-分页-Pagination"><a href="#7-分页-Pagination" class="headerlink" title="7. 分页 Pagination"></a>7. 分页 Pagination</h2><p>当返回某个资源的列表时，如果要返回的数目特别多，比如 github 的 <code>/users</code>，就需要使用分页分批次按照需要来返回特定数量的结果。</p>
<p>分页的实现会用到上面提到的 url query，通过两个参数来控制要返回的资源结果：</p>
<ul>
<li>size：每页返回多少资源，如果没提供会使用预设的默认值；这个数量也是有一个最大值，不然用户把它设置成一个非常大的值（比如 <code>99999999</code>）也失去了设计的初衷</li>
<li>page：要获取哪一页的资源，默认是第一页</li>
</ul>
<p>返回的资源列表为 <code>[(page-1)*size, page*size)</code>。</p>
<h2 id="8-选择合适的HTTP状态码"><a href="#8-选择合适的HTTP状态码" class="headerlink" title="8. 选择合适的HTTP状态码"></a>8. 选择合适的HTTP状态码</h2><p>HTTP 应答中，需要带一个很重要的字段：<code>status code</code>。它说明了请求的大致情况，是否正常完成、需要进一步处理、出现了什么错误，对于客户端非常重要。状态码都是三位的整数，大概分成了几个区间：</p>
<ul>
<li><code>2XX</code>：请求正常处理并返回</li>
<li><code>3XX</code>：重定向，请求的资源位置发生变化</li>
<li><code>4XX</code>：客户端发送的请求有错误</li>
<li><code>5XX</code>：服务器端错误</li>
</ul>
<p>在 HTTP API 设计中，经常用到的状态码以及它们的意义如下表：</p>
<table>
<thead>
<tr>
<th>状态码</th>
<th>Label</th>
<th>重点关注</th>
<th>解释</th>
</tr>
</thead>
<tbody>
<tr>
<td>200</td>
<td>OK</td>
<td>Y</td>
<td>请求成功接收并处理，一般响应中都会有 body</td>
</tr>
<tr>
<td>201</td>
<td>Created</td>
<td></td>
<td>请求已完成，并导致了一个或者多个资源被创建，最常用在 POST 创建资源的时候</td>
</tr>
<tr>
<td>202</td>
<td>Accepted</td>
<td></td>
<td>请求已经接收并开始处理，但是处理还没有完成。一般用在异步处理的情况，响应 body 中应该告诉客户端去哪里查看任务的状态</td>
</tr>
<tr>
<td>204</td>
<td>No Content</td>
<td></td>
<td>请求已经处理完成，但是没有信息要返回，经常用在 PUT 更新资源的时候（客户端提供资源的所有属性，因此不需要服务端返回）。如果有重要的 metadata，可以放到头部返回</td>
</tr>
<tr>
<td>301</td>
<td>Moved Permanently</td>
<td>Y</td>
<td>请求的资源已经永久性地移动到另外一个地方，后续所有的请求都应该直接访问新地址。服务端会把新地址写在 <code>Location</code> 头部字段，方便客户端使用。允许客户端把 POST 请求修改为 GET。</td>
</tr>
<tr>
<td>304</td>
<td>Not Modified</td>
<td>Y</td>
<td>请求的资源和之前的版本一样，没有发生改变。用来缓存资源，和条件性请求（conditional request）一起出现</td>
</tr>
<tr>
<td>307</td>
<td>Temporary Redirect</td>
<td></td>
<td>目标资源暂时性地移动到新的地址，客户端需要去新地址进行操作，但是<strong>不能</strong>修改请求的方法。</td>
</tr>
<tr>
<td>308</td>
<td>Permanent Redirect</td>
<td></td>
<td>和 301 类似，除了客户端<strong>不能</strong>修改原请求的方法</td>
</tr>
<tr>
<td>400</td>
<td>Bad Request</td>
<td>Y</td>
<td>客户端发送的请求有错误（请求语法错误，body 数据格式有误，body 缺少必须的字段等），导致服务端无法处理</td>
</tr>
<tr>
<td>401</td>
<td>Unauthorized</td>
<td>Y</td>
<td>请求的资源需要认证，客户端没有提供认证信息或者认证信息不正确</td>
</tr>
<tr>
<td>403</td>
<td>Forbidden</td>
<td>Y</td>
<td>服务器端接收到并理解客户端的请求，但是客户端的权限不足。比如，普通用户想操作只有管理员才有权限的资源。为了安全考虑，避免攻击，对外服务，可将这个状态码改写为<strong>404</strong>返回给客户端</td>
</tr>
<tr>
<td>404</td>
<td>Not Found</td>
<td>Y</td>
<td>客户端要访问的资源不存在，链接失效或者客户端伪造 URL 的时候回遇到这个情况</td>
</tr>
<tr>
<td>405</td>
<td>Method Not Allowed</td>
<td></td>
<td>服务端接收到了请求，而且要访问的资源也存在，但是不支持对应的方法。服务端<strong>必须</strong>返回 <code>Allow</code> 头部，告诉客户端哪些方法是允许的</td>
</tr>
<tr>
<td>415</td>
<td>Unsupported Media Type</td>
<td></td>
<td>服务端不支持客户端请求的资源格式，一般是因为客户端在 <code>Content-Type</code> 或者 <code>Content-Encoding</code> 中申明了希望的返回格式，但是服务端没有实现。比如，客户端希望收到 <code>xml</code>返回，但是服务端支持 <code>Json</code></td>
</tr>
<tr>
<td>429</td>
<td>Too Many Requests</td>
<td>Y</td>
<td>客户端在规定的时间里发送了太多请求，在进行限流的时候会用到</td>
</tr>
<tr>
<td>500</td>
<td>Internal Server Error</td>
<td>Y</td>
<td>服务器内部错误，导致无法完成请求的内容</td>
</tr>
<tr>
<td>503</td>
<td>Service Unavailable</td>
<td>Y</td>
<td>服务器因为负载过高或者维护，暂时无法提供服务。服务器端应该返回 <code>Retry-After</code> 头部，告诉客户端过一段时间再来重试</td>
</tr>
</tbody>
</table>
<p>上面这些状态码覆盖了 API 设计中大部分的情况，如果对某个状态码不清楚或者希望查看更完整的列表，可以参考 <a href="https://httpstatuses.com/" target="_blank" rel="external">HTTP Status Code</a> 这个网站，或者 <a href="https://tools.ietf.org/html/rfc7231#section-6" target="_blank" rel="external">RFC7231 Response Status Codes</a> 的内容。<br>在实际应用中，<strong>不建议再使用更多的状态码</strong>。</p>
<h2 id="9-错误处理码设计"><a href="#9-错误处理码设计" class="headerlink" title="9. 错误处理码设计"></a>9. 错误处理码设计</h2><p>除了使用好HTTP状态码，必须有良好的错误码设计。一个良好的状态码设计应同事给出<code>状态码</code>和对应<code>错误消息</code>。<br>HTTP请求返回格式(建议)：</p>
<pre><code>{
    &quot;code&quot;:XXX,
    &quot;message&quot;:&quot;ABCDE...&quot;,
    &quot;data&quot;:{
        ...
    }
}
</code></pre><p>在正常请求时，约定<code>code=0,message=&quot;ok&quot;</code>。</p>
<p>错误时，错误码规则为<code>ABBBBCCCC</code>，共9位。</p>
<p>A:错误级别。如1代表系统级错误，2代表服务级错误；<br>B:项目或模块名称代码；9999个项目或模块，够用了；<br>C:具体错误编号。单个项目/模块有999种错误应该够用；</p>
<p>A错误级别码：</p>
<table>
<thead>
<tr>
<th>级别码</th>
<th>错误说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>依赖组件级错误</td>
</tr>
<tr>
<td>2</td>
<td>服务级错误</td>
</tr>
<tr>
<td>3</td>
<td></td>
</tr>
<tr>
<td>4</td>
<td>请求错误</td>
</tr>
<tr>
<td>5</td>
<td>系统级错误</td>
</tr>
<tr>
<td>…</td>
<td>-</td>
</tr>
</tbody>
</table>
<p>BBBB项目代码：</p>
<table>
<thead>
<tr>
<th>级别码</th>
<th>错误说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>0001</td>
<td>search-ershou</td>
</tr>
<tr>
<td>0002</td>
<td>basic-search</td>
</tr>
<tr>
<td>…</td>
<td>-</td>
</tr>
</tbody>
</table>
<p>CCCC错误编号：</p>
<table>
<thead>
<tr>
<th>错误编号</th>
<th>错误说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>1000</td>
<td>权限认证相关错误</td>
</tr>
<tr>
<td>2000</td>
<td>连接类错误</td>
</tr>
<tr>
<td>3000</td>
<td>超时类错误</td>
</tr>
<tr>
<td>4000</td>
<td>参数错误</td>
</tr>
<tr>
<td>…</td>
</tr>
</tbody>
</table>
<h2 id="10-验证和授权"><a href="#10-验证和授权" class="headerlink" title="10. 验证和授权"></a>10. 验证和授权</h2><p>一般来说，让任何人随意访问公开的 API 是不好的做法。验证和授权是两件事情：</p>
<ul>
<li>验证（Authentication）是为了确定用户是其申明的身份，比如提供账户的密码。不然的话，任何人伪造成其他身份（比如其他用户或者管理员）是非常危险的</li>
<li>授权（Authorization）是为了保证用户有对请求资源特定操作的权限。比如用户的私人信息只能自己能访问，其他人无法看到；有些特殊的操作只能管理员可以操作，其他用户有只读的权限等等</li>
</ul>
<p>如果没有通过验证（提供的用户名和密码不匹配，token 不正确等），需要返回 <a href="https://httpstatuses.com/401" target="_blank" rel="external"><strong>401 Unauthorized</strong></a>状态码，并在 body 中说明具体的错误信息；而没有被授权访问的资源操作，需要返回 <a href="https://httpstatuses.com/403" target="_blank" rel="external"><strong>403 Forbidden</strong></a> 状态码，还有详细的错误信息。</p>
<p><strong>NOTE</strong>：Github API 对某些用户未被授权访问的资源操作返回 <a href="https://httpstatuses.com/404" target="_blank" rel="external"><strong>404 Not Found</strong></a>，目的是为了防止私有资源的泄露（比如黑客可以自动化试探用户的私有资源，返回 403 的话，就等于告诉黑客用户有这些私有的资源）。</p>
<h2 id="11-限流rate-limit"><a href="#11-限流rate-limit" class="headerlink" title="11. 限流rate limit"></a>11. 限流rate limit</h2><p>如果对访问的次数不加控制，很可能会造成 API 被滥用，甚至被 <a href="https://en.wikipedia.org/wiki/Denial-of-service_attack" target="_blank" rel="external">DDos 攻击</a>。根据使用者不同的身份对其进行限流，可以防止这些情况，减少服务器的压力。</p>
<p>对用户的请求限流之后，要有方法告诉用户它的请求使用情况，<code>Github API</code> 使用的三个相关的头部可以借鉴：</p>
<ul>
<li><code>X-RateLimit-Limit</code>: 用户每个小时允许发送请求的最大值</li>
<li><code>X-RateLimit-Remaining</code>：当前时间窗口剩下的可用请求数目</li>
<li><code>X-RateLimit-Rest</code>: 时间窗口重置的时候，到这个时间点可用的请求数量就会变成 X-RateLimit-Limit的值</li>
</ul>
<p>如果允许没有登录的用户使用 API（可以让用户试用），可以把 <code>X-RateLimit-Limit</code> 的值设置得很小，比如 Github 使用的 <code>60</code>。没有登录的用户是按照请求的 IP 来确定的，而登录的用户按照认证后的信息来确定身份。<br>对于超过流量的请求，可以返回 <a href="https://httpstatuses.com/429" target="_blank" rel="external"><strong>429 Too many requests</strong></a> 状态码，并附带错误信息。而 <code>Github API</code> 返回的是 <a href="https://httpstatuses.com/403" target="_blank" rel="external"><strong>403 Forbidden</strong></a>，虽然没有 <code>429</code> 更准确，也是可以理解的。</p>
<h2 id="12-Hypermedia-API"><a href="#12-Hypermedia-API" class="headerlink" title="12. Hypermedia API"></a>12. Hypermedia API</h2><p>Restful API 的设计最好做到 Hypermedia：在返回结果中提供相关资源的链接。这种设计也被称为 <a href="http://en.wikipedia.org/wiki/HATEOAS" target="_blank" rel="external">HATEOAS</a>。这样做的好处是，用户可以根据返回结果就能得到后续操作需要访问的地址。<br>比如访问 <a href="https://api.github.com/" target="_blank" rel="external">api.github.com</a>，就可以看到 Github API 支持的资源操作。<br>Spring技术栈，可以使用<a href="https://spring.io/projects/spring-hateoas" target="_blank" rel="external">Spring Hateoas</a>；由于需要在返回body内增加内容，内部服务使用起来颇有难度，不建议。外部服务强烈推荐。</p>
<h2 id="13-编写优秀的文档"><a href="#13-编写优秀的文档" class="headerlink" title="13. 编写优秀的文档"></a>13. 编写优秀的文档</h2><p>API 最终是给人使用的，不管是公司内部，还是公开的 API 都是一样。即使我们遵循了上面提到的所有规范，设计的 API 非常优雅，用户还是不知道怎么使用我们的 API。最后一步，但非常重要的一步是：为你的 API 编写优秀的文档。</p>
<p>对每个请求以及返回的参数给出说明，最好给出一个详细而完整地示例，提醒用户需要注意的地方……反正目标就是用户可以根据你的文档就能直接使用API，而不是要发邮件给你，或者跑到你的座位上问你一堆问题。<br>文档生成：<strong>建议使用<a href="https://swagger.io/" target="_blank" rel="external">SWAGGER</a></strong><br>与Spring集成：使用<a href="http://springfox.github.io/springfox/" target="_blank" rel="external">SpringFox</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;微服务下的API设计原则&quot;&gt;&lt;a href=&quot;#微服务下的API设计原则&quot; class=&quot;headerlink&quot; title=&quot;微服务下的API设计原则&quot;&gt;&lt;/a&gt;微服务下的API设计原则&lt;/h1&gt;&lt;p&gt;目的：&lt;br&gt;规范团队乃至公司的API设计。&lt;br&gt;主要参考： &lt;a href=&quot;https://developer.github.com/v3/&quot;&gt;Github API&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;1-为了安全，请使用HTTPS&quot;&gt;&lt;a href=&quot;#1-为了安全，请使用HTTPS&quot; class=&quot;headerlink&quot; title=&quot;1. 为了安全，请使用HTTPS&quot;&gt;&lt;/a&gt;1. 为了安全，请使用HTTPS&lt;/h2&gt;&lt;p&gt;与API设计无关、为了安全请使用HTTPS。公网API,强制使用HTTPS。内网API可酌情选择。&lt;/p&gt;
&lt;h2 id=&quot;2-API-地址和版本&quot;&gt;&lt;a href=&quot;#2-API-地址和版本&quot; class=&quot;headerlink&quot; title=&quot;2. API 地址和版本&quot;&gt;&lt;/a&gt;2. API 地址和版本&lt;/h2&gt;&lt;p&gt;在 &lt;code&gt;url&lt;/code&gt; 中指定 API 的版本是个很好地做法。&lt;br&gt;如果 API 变化比较大，可以把API设计为子域名，比如 &lt;code&gt;https://api.ke.com/v3&lt;/code&gt;；&lt;br&gt;也可以简单地把版本放在路径中，比如 &lt;code&gt;https://ke.com/api/v1&lt;/code&gt;。&lt;br&gt;&lt;strong&gt;不建议放入Header&lt;/strong&gt;，不直观。&lt;/p&gt;
&lt;h2 id=&quot;3-schema请使用JSON&quot;&gt;&lt;a href=&quot;#3-schema请使用JSON&quot; class=&quot;headerlink&quot; title=&quot;3. schema请使用JSON&quot;&gt;&lt;/a&gt;3. schema请使用JSON&lt;/h2&gt;&lt;p&gt;对于响应返回的格式，JSON 因为它的可读性、紧凑性以及多种语言支持等优点，成为了 HTTP API 最常用的返回格式。因此，最好采用&lt;strong&gt;JSON&lt;/strong&gt;作为返回内容的格式。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;不推荐其他格式&lt;/strong&gt;，如果必须使用，比如 &lt;code&gt;xml&lt;/code&gt;，应该在请求头部 &lt;code&gt;Accept&lt;/code&gt; 中指定。&lt;br&gt;对于不支持的格式，服务端需要返回正确的 &lt;code&gt;status code&lt;/code&gt;，并给出详细的说明。&lt;/p&gt;
    
    </summary>
    
      <category term="微服务" scheme="https://www.shenyanchao.cn/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
    
      <category term="微服务" scheme="https://www.shenyanchao.cn/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
      <category term="API" scheme="https://www.shenyanchao.cn/tags/API/"/>
    
      <category term="设计" scheme="https://www.shenyanchao.cn/tags/%E8%AE%BE%E8%AE%A1/"/>
    
  </entry>
  
  <entry>
    <title>Spring Redis 注解式Cache那些事</title>
    <link href="https://www.shenyanchao.cn/blog/2018/07/23/spring-cache-redis-annotation/"/>
    <id>https://www.shenyanchao.cn/blog/2018/07/23/spring-cache-redis-annotation/</id>
    <published>2018-07-23T09:05:00.000Z</published>
    <updated>2018-12-20T11:58:02.490Z</updated>
    
    <content type="html"><![CDATA[<h3 id="前言："><a href="#前言：" class="headerlink" title="前言："></a>前言：</h3><blockquote>
<p>spring-data-redis使得Spring项目可以快速简单的通过RedisTemplate来操作Redis。而spring-boot-starter-data-redis更是让redis集成更加的方便。</p>
</blockquote>
<h3 id="SpringBoot如何与Redis集成，作为cache"><a href="#SpringBoot如何与Redis集成，作为cache" class="headerlink" title="SpringBoot如何与Redis集成，作为cache"></a>SpringBoot如何与Redis集成，作为cache</h3><p>application.yml里如下配置：</p>
<figure class="highlight yml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="attr">spring:</span></div><div class="line"><span class="attr">  redis:</span></div><div class="line"><span class="attr">    host:</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span></div><div class="line">    	port: <span class="number">6379</span></div><div class="line">    	database: <span class="number">0</span></div><div class="line">    	timeout: <span class="number">1000</span></div><div class="line">    	pool:</div><div class="line">      		max-idle: <span class="number">200</span></div><div class="line">      		min-idle: <span class="number">0</span></div><div class="line">      		max-active: <span class="number">200</span></div><div class="line">      		max-wait: <span class="number">1000</span></div></pre></td></tr></table></figure>
<p>spring boot可以自动组装相关配置，注意其中使用到了jedis pool，用于提升性能，非必须。<br>通过以下的annotation加入方法名上，可以无侵入的使用cache。</p>
<ul>
<li>@Cacheable   缓存</li>
<li>@CachePut    设置缓存</li>
<li>@CacheEvict  失效或更新缓存</li>
<li><p>@Caching   组合操作</p>
<p>以上annotation不做详细展开。</p>
<a id="more"></a>
<p>做到上面似乎已经可以了，但有一些问题需要我们来解决。</p>
</li>
</ul>
<ul>
<li>a.redis连接报错\超时怎么办？此时应该是可降级的。</li>
<li>b.使用连接池，连接不可用如何破？</li>
</ul>
<p>下面贴一个比较成熟的做法，继承<code>CachingConfigurerSupport</code>：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div></pre></td><td class="code"><pre><div class="line"><span class="meta">@Configuration</span></div><div class="line"><span class="meta">@EnableCaching</span> <span class="comment">//启用</span></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">RedisConfig</span> <span class="keyword">extends</span> <span class="title">CachingConfigurerSupport</span> </span>&#123;</div><div class="line"></div><div class="line">    <span class="comment">// 过期时间</span></div><div class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> expire = <span class="number">600</span>;</div><div class="line"></div><div class="line">    <span class="comment">// application.yml配置参数有限，注入并扩展用。</span></div><div class="line">    <span class="meta">@Autowired</span></div><div class="line">    <span class="keyword">private</span> RedisProperties redisProperties;</div><div class="line"></div><div class="line">    <span class="comment">//此处自定义jedis pool配置，设置TestOnBrrow等等</span></div><div class="line">    <span class="meta">@Bean</span></div><div class="line">    <span class="function"><span class="keyword">public</span> JedisPoolConfig <span class="title">jedisPoolConfig</span><span class="params">()</span> </span>&#123;</div><div class="line">        JedisPoolConfig jedisPoolConfig = <span class="keyword">new</span> JedisPoolConfig();</div><div class="line">        RedisProperties.Pool pool = redisProperties.getPool();</div><div class="line">        jedisPoolConfig.setMaxIdle(pool.getMaxIdle());</div><div class="line">        jedisPoolConfig.setMaxTotal(pool.getMaxActive());</div><div class="line">        jedisPoolConfig.setMinIdle(pool.getMinIdle());</div><div class="line">        jedisPoolConfig.setMaxWaitMillis(pool.getMaxWait());</div><div class="line">        jedisPoolConfig.setTestOnBorrow(<span class="keyword">true</span>);</div><div class="line">        jedisPoolConfig.setTestWhileIdle(<span class="keyword">true</span>);</div><div class="line">        <span class="keyword">return</span> jedisPoolConfig;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">   <span class="comment">//生成redisConnectionFactory，使用自定义的jedis pool</span></div><div class="line">    <span class="meta">@Bean</span></div><div class="line">    <span class="function"><span class="keyword">public</span> RedisConnectionFactory <span class="title">redisConnectionFactory</span><span class="params">(JedisPoolConfig jedisPoolConfig)</span> </span>&#123;</div><div class="line">        JedisConnectionFactory jedisConnectionFactory = <span class="keyword">new</span> JedisConnectionFactory();</div><div class="line">        jedisConnectionFactory.setHostName(redisProperties.getHost());</div><div class="line">        jedisConnectionFactory.setPort(redisProperties.getPort());</div><div class="line">        jedisConnectionFactory.setDatabase(redisProperties.getDatabase());</div><div class="line">        jedisConnectionFactory.setTimeout(redisProperties.getTimeout());</div><div class="line">        <span class="keyword">if</span> (<span class="keyword">null</span> != redisProperties.getPassword()) &#123;</div><div class="line">            jedisConnectionFactory.setPassword(redisProperties.getPassword());</div><div class="line">        &#125;</div><div class="line">        jedisConnectionFactory.setPoolConfig(jedisPoolConfig);</div><div class="line">        <span class="keyword">return</span> jedisConnectionFactory;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// 设置cacheManager相关，主要涉及默认过期时间。</span></div><div class="line">    <span class="meta">@Bean</span></div><div class="line">    <span class="function"><span class="keyword">public</span> CacheManager <span class="title">cacheManager</span><span class="params">(RedisTemplate redisTemplate)</span> </span>&#123;</div><div class="line">        RedisCacheManager cacheManager = <span class="keyword">new</span> RedisCacheManager(redisTemplate);</div><div class="line">        <span class="comment">//设置缓存过期时间，可单独对某个cache制定过期时间</span></div><div class="line">        cacheManager.setDefaultExpiration(expire);</div><div class="line">        <span class="comment">//设置redis key是否使用前缀，默认前缀是cacheName</span></div><div class="line">        cacheManager.setUsePrefix(<span class="keyword">true</span>);</div><div class="line">        <span class="keyword">return</span> cacheManager;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">//定义redisTemplate，主要是定义key\value的序列化器</span></div><div class="line">    <span class="meta">@Bean</span></div><div class="line">    <span class="function"><span class="keyword">public</span> RedisTemplate&lt;String, String&gt; <span class="title">redisTemplate</span><span class="params">(RedisConnectionFactory redisConnectionFactory)</span> </span>&#123;</div><div class="line">        StringRedisTemplate template = <span class="keyword">new</span> StringRedisTemplate(redisConnectionFactory);</div><div class="line">        template.setValueSerializer(getValueSerializer());</div><div class="line">        template.afterPropertiesSet();</div><div class="line">        <span class="keyword">return</span> template;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">private</span> RedisSerializer <span class="title">getValueSerializer</span><span class="params">()</span> </span>&#123;</div><div class="line">        Jackson2JsonRedisSerializer jackson2JsonRedisSerializer = <span class="keyword">new</span> Jackson2JsonRedisSerializer(Object.class);</div><div class="line">        ObjectMapper om = <span class="keyword">new</span> ObjectMapper();</div><div class="line">        om.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY);</div><div class="line">        om.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL);</div><div class="line">        jackson2JsonRedisSerializer.setObjectMapper(om);</div><div class="line">        <span class="keyword">return</span> jackson2JsonRedisSerializer;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// 设置redis key生成策略</span></div><div class="line">    <span class="meta">@Bean</span></div><div class="line">    <span class="meta">@Override</span></div><div class="line">    <span class="function"><span class="keyword">public</span> KeyGenerator <span class="title">keyGenerator</span><span class="params">()</span> </span>&#123;</div><div class="line">        <span class="keyword">return</span> <span class="keyword">new</span> RequestKeyGenerator();</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// 重点：设置和redis交互报错时的错误处理器。</span></div><div class="line">    <span class="meta">@Bean</span></div><div class="line">    <span class="meta">@Override</span></div><div class="line">    <span class="function"><span class="keyword">public</span> CacheErrorHandler <span class="title">errorHandler</span><span class="params">()</span> </span>&#123;</div><div class="line">        <span class="keyword">return</span> <span class="keyword">new</span> CallbackCacheErrorHandler();</div><div class="line">    &#125;</div></pre></td></tr></table></figure>
<p>下面看一下<code>CallbackCacheErrorHandler</code>    :</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CallbackCacheErrorHandler</span> <span class="keyword">implements</span> <span class="title">CacheErrorHandler</span> </span>&#123;</div><div class="line"></div><div class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger LOGGER = LoggerFactory.getLogger(CallbackCacheErrorHandler.class);</div><div class="line"></div><div class="line">    <span class="meta">@Override</span></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">handleCacheGetError</span><span class="params">(RuntimeException exception, Cache cache, Object key)</span> </span>&#123;</div><div class="line">        LOGGER.error(<span class="string">"cache get error, cacheName:&#123;&#125;, key:&#123;&#125;, msg:"</span>, cache.getName(), key, exception);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="meta">@Override</span></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">handleCachePutError</span><span class="params">(RuntimeException exception, Cache cache, Object key, Object value)</span> </span>&#123;</div><div class="line">        LOGGER.error(<span class="string">"cache put error, cacheName:&#123;&#125;, key:&#123;&#125;, msg:"</span>, cache.getName(), key, exception);</div><div class="line"></div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="meta">@Override</span></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">handleCacheEvictError</span><span class="params">(RuntimeException exception, Cache cache, Object key)</span> </span>&#123;</div><div class="line">        LOGGER.error(<span class="string">"cache evict error, cacheName:&#123;&#125;, key:&#123;&#125;, msg:"</span>, cache.getName(), key, exception);</div><div class="line"></div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="meta">@Override</span></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">handleCacheClearError</span><span class="params">(RuntimeException exception, Cache cache)</span> </span>&#123;</div><div class="line">        LOGGER.error(<span class="string">"cache clear error, cacheName:&#123;&#125;, msg:"</span>, cache.getName(), exception);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>此处当报错的时候只进行了日志记录，当然如果有其他需求，都可以在这里扩展。自此，spring boot与redis集成大功告成，一切都是那么的完美。</p>
<h3 id="关于RedisCacheManager是否setUsePrefix的坑"><a href="#关于RedisCacheManager是否setUsePrefix的坑" class="headerlink" title="关于RedisCacheManager是否setUsePrefix的坑"></a>关于RedisCacheManager是否<code>setUsePrefix</code>的坑</h3><p>首先，我们要知道是否使用<code>prefix</code>的区别是什么？<br>区别如下：</p>
<ul>
<li><ol>
<li>使用<code>prefix</code>的时候，redis cache的key都会默认添加上cacheName，用于区分不同的cache。</li>
</ol>
</li>
<li><ol>
<li>使用<code>prefix</code>的时候，当清除或者失效所有的key的时候，使用的是key prefix*获取所有的key,然后依次清楚。而不使用<code>prefix</code>的时候，需要清除或者失效所有key的时候，则是从一个维护了所有key的zset中获取的，这个zset通常叫做<code>${cacheName}~keys</code>。</li>
</ol>
</li>
</ul>
<p>下面通过源代码来证实一下：<br>RedisCache.java内<code>RedisWriteThroughCallback</code>负责往redis设置缓存：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div></pre></td><td class="code"><pre><div class="line">	static class RedisWriteThroughCallback extends AbstractRedisCacheCallback&lt;byte[]&gt; &#123;</div><div class="line"></div><div class="line">	public RedisWriteThroughCallback(BinaryRedisCacheElement element, RedisCacheMetadata metadata) &#123;</div><div class="line">		super(element, metadata);</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	@Override</div><div class="line">	public byte[] doInRedis(BinaryRedisCacheElement element, RedisConnection connection) throws DataAccessException &#123;</div><div class="line"></div><div class="line">		try &#123;</div><div class="line">          //加锁</div><div class="line">			lock(connection);</div><div class="line"></div><div class="line">			try &#123;</div><div class="line"></div><div class="line">				byte[] value = connection.get(element.getKeyBytes());</div><div class="line"></div><div class="line">				if (value != null) &#123;</div><div class="line">					return value;</div><div class="line">				&#125;</div><div class="line"></div><div class="line">				if (!isClusterConnection(connection)) &#123;</div><div class="line"></div><div class="line">					connection.watch(element.getKeyBytes());</div><div class="line">					// 开始事务</div><div class="line">					connection.multi();</div><div class="line">				&#125;</div><div class="line"></div><div class="line">				value = element.get();</div><div class="line"></div><div class="line">				if (value.length == 0) &#123;</div><div class="line">					connection.del(element.getKeyBytes());</div><div class="line">				&#125; else &#123;</div><div class="line">				   // 设置缓存key-value</div><div class="line">					connection.set(element.getKeyBytes(), value);</div><div class="line">					// 设置失效日期</div><div class="line">					processKeyExpiration(element, connection);</div><div class="line">					// 维护key到已知zset内</div><div class="line">					maintainKnownKeys(element, connection);</div><div class="line">				&#125;</div><div class="line"></div><div class="line">				if (!isClusterConnection(connection)) &#123;</div><div class="line">					connection.exec();</div><div class="line">				&#125;</div><div class="line"></div><div class="line">				return value;</div><div class="line">			&#125; catch (RuntimeException e) &#123;</div><div class="line">				if (!isClusterConnection(connection)) &#123;</div><div class="line">					connection.discard();</div><div class="line">				&#125;</div><div class="line">				throw e;</div><div class="line">			&#125;</div><div class="line">		&#125; finally &#123;</div><div class="line">		   // 释放锁</div><div class="line">			unlock(connection);</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line">&#125;;</div><div class="line"></div><div class="line"> protected void maintainKnownKeys(RedisCacheElement element, RedisConnection connection) &#123;</div><div class="line"></div><div class="line">		if (!element.hasKeyPrefix()) &#123; //不使用prefix</div><div class="line">          // 则zadd到已知的key集合内</div><div class="line">			connection.zAdd(cacheMetadata.getSetOfKnownKeysKey(), 0, element.getKeyBytes());</div><div class="line"></div><div class="line">			if (!element.isEternal()) &#123;</div><div class="line">				connection.expire(cacheMetadata.getSetOfKnownKeysKey(), element.getTimeToLive());</div><div class="line">			&#125;</div><div class="line">		&#125;</div><div class="line">	&#125;</div></pre></td></tr></table></figure>
<p>从上面分析得知，设置缓存的时候有以下几步：</p>
<ul>
<li>1.设置key-value</li>
<li>2.设置key的过期时间</li>
<li>3.维护key到已知key的zset列表</li>
</ul>
<p>清理所有key的时候，是怎么操作的呢？</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">clear</span><span class="params">()</span> </span>&#123;</div><div class="line">	redisOperations.execute(cacheMetadata.usesKeyPrefix() ? <span class="keyword">new</span> RedisCacheCleanByPrefixCallback(cacheMetadata)</div><div class="line">			: <span class="keyword">new</span> RedisCacheCleanByKeysCallback(cacheMetadata));</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>可以看出依据是否使用前缀，使用不同的回调方法。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line"> * <span class="doctag">@author</span> Christoph Strobl</div><div class="line"> * <span class="doctag">@since</span> 1.5</div><div class="line"> */</div><div class="line"><span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">RedisCacheCleanByKeysCallback</span> <span class="keyword">extends</span> <span class="title">LockingRedisCacheCallback</span>&lt;<span class="title">Void</span>&gt; </span>&#123;</div><div class="line"></div><div class="line">	<span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> PAGE_SIZE = <span class="number">128</span>;</div><div class="line">	<span class="keyword">private</span> <span class="keyword">final</span> RedisCacheMetadata metadata;</div><div class="line"></div><div class="line">	RedisCacheCleanByKeysCallback(RedisCacheMetadata metadata) &#123;</div><div class="line">		<span class="keyword">super</span>(metadata);</div><div class="line">		<span class="keyword">this</span>.metadata = metadata;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	<span class="comment">/*</span></div><div class="line">	 * (non-Javadoc)</div><div class="line">	 * @see org.springframework.data.redis.cache.RedisCache.LockingRedisCacheCallback#doInLock(org.springframework.data.redis.connection.RedisConnection)</div><div class="line">	 */</div><div class="line">	<span class="meta">@Override</span></div><div class="line">	<span class="function"><span class="keyword">public</span> Void <span class="title">doInLock</span><span class="params">(RedisConnection connection)</span> </span>&#123;</div><div class="line"></div><div class="line">		<span class="keyword">int</span> offset = <span class="number">0</span>;</div><div class="line">		<span class="keyword">boolean</span> finished = <span class="keyword">false</span>;</div><div class="line"></div><div class="line">		do &#123;</div><div class="line">			<span class="comment">// need to paginate the keys</span></div><div class="line">			Set&lt;<span class="keyword">byte</span>[]&gt; keys = connection.zRange(metadata.getSetOfKnownKeysKey(), (offset) * PAGE_SIZE,</div><div class="line">					(offset + <span class="number">1</span>) * PAGE_SIZE - <span class="number">1</span>);  <span class="comment">//使用zrange遍历，删除</span></div><div class="line">			finished = keys.size() &lt; PAGE_SIZE;</div><div class="line">			offset++;</div><div class="line">			<span class="keyword">if</span> (!keys.isEmpty()) &#123;</div><div class="line">				connection.del(keys.toArray(<span class="keyword">new</span> <span class="keyword">byte</span>[keys.size()][]));</div><div class="line">			&#125;</div><div class="line">		&#125; <span class="keyword">while</span> (!finished);</div><div class="line"></div><div class="line">		connection.del(metadata.getSetOfKnownKeysKey());</div><div class="line">		<span class="keyword">return</span> <span class="keyword">null</span>;</div><div class="line">	&#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line"> * <span class="doctag">@author</span> Christoph Strobl</div><div class="line"> * <span class="doctag">@since</span> 1.5</div><div class="line"> */</div><div class="line"><span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">RedisCacheCleanByPrefixCallback</span> <span class="keyword">extends</span> <span class="title">LockingRedisCacheCallback</span>&lt;<span class="title">Void</span>&gt; </span>&#123;</div><div class="line"></div><div class="line">	<span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">byte</span>[] REMOVE_KEYS_BY_PATTERN_LUA = <span class="keyword">new</span> StringRedisSerializer().serialize(</div><div class="line">			<span class="string">"local keys = redis.call('KEYS', ARGV[1]); local keysCount = table.getn(keys); if(keysCount &gt; 0) then for _, key in ipairs(keys) do redis.call('del', key); end; end; return keysCount;"</span>);</div><div class="line">	<span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">byte</span>[] WILD_CARD = <span class="keyword">new</span> StringRedisSerializer().serialize(<span class="string">"*"</span>);</div><div class="line">	<span class="keyword">private</span> <span class="keyword">final</span> RedisCacheMetadata metadata;</div><div class="line"></div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="title">RedisCacheCleanByPrefixCallback</span><span class="params">(RedisCacheMetadata metadata)</span> </span>&#123;</div><div class="line">		<span class="keyword">super</span>(metadata);</div><div class="line">		<span class="keyword">this</span>.metadata = metadata;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	<span class="comment">/*</span></div><div class="line">	 * (non-Javadoc)</div><div class="line">	 * @see org.springframework.data.redis.cache.RedisCache.LockingRedisCacheCallback#doInLock(org.springframework.data.redis.connection.RedisConnection)</div><div class="line">	 */</div><div class="line">	<span class="meta">@Override</span></div><div class="line">	<span class="function"><span class="keyword">public</span> Void <span class="title">doInLock</span><span class="params">(RedisConnection connection)</span> <span class="keyword">throws</span> DataAccessException </span>&#123;</div><div class="line"></div><div class="line">		<span class="keyword">byte</span>[] prefixToUse = Arrays.copyOf(metadata.getKeyPrefix(), metadata.getKeyPrefix().length + WILD_CARD.length);</div><div class="line">		System.arraycopy(WILD_CARD, <span class="number">0</span>, prefixToUse, metadata.getKeyPrefix().length, WILD_CARD.length);</div><div class="line"></div><div class="line">		<span class="keyword">if</span> (isClusterConnection(connection)) &#123;</div><div class="line"></div><div class="line">			<span class="comment">// load keys to the client because currently Redis Cluster connections do not allow eval of lua scripts.</span></div><div class="line">			Set&lt;<span class="keyword">byte</span>[]&gt; keys = connection.keys(prefixToUse);  <span class="comment">//集群模式下，使用keys获取所有的key</span></div><div class="line">			<span class="keyword">if</span> (!keys.isEmpty()) &#123;</div><div class="line">				connection.del(keys.toArray(<span class="keyword">new</span> <span class="keyword">byte</span>[keys.size()][]));</div><div class="line">			&#125;</div><div class="line">		&#125; <span class="keyword">else</span> &#123;</div><div class="line">		   <span class="comment">// 非集群模式下，使用LUA脚本，keys删除。</span></div><div class="line">			connection.eval(REMOVE_KEYS_BY_PATTERN_LUA, ReturnType.INTEGER, <span class="number">0</span>, prefixToUse);</div><div class="line">		&#125;</div><div class="line"></div><div class="line">		<span class="keyword">return</span> <span class="keyword">null</span>;</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>从以上源码可以看出使用prefix的区别。总结下，坑在哪儿，应该如何根据业务来选择。</p>
<ul>
<li>坑1：不使用<code>prefix</code>,需要额外的zset来保存已知key集合，风险点是zset有可能很大，占用空间，如果被置换出去，功能则不一致</li>
<li>坑2：使用<code>prefix</code>, 没有额外的zset。但是失效或者清理所有key的时候，使用<code>keys *</code>可能导致redis被拖死，清理时间内无响应。</li>
<li>坑3：设置缓存，使用了multi，对redis压力不小，高并发下尤其明显，需要注意。</li>
</ul>
<h3 id="关于Redis-Cache默认使用lock的问题"><a href="#关于Redis-Cache默认使用lock的问题" class="headerlink" title="关于Redis Cache默认使用lock的问题"></a>关于Redis Cache默认使用lock的问题</h3><p>在高并发下，发现spring redis cache的put效率并不高，经过排查发现put操作有lock机制，切lock时间无法更改。</p>
<p>如上<code>RedisWriteThroughCallback</code>所示，有lock和unlock操作，其实就是往redis写一个key作为lock, 删除这个key作为unlock。这个操作在分布式系统中，可以保证其一致性，但是也损失了性能。尤其在仅作为缓存使用的场景，key对应的value具备幂等性，完全可以忽略。</p>
<p>源码重点在这个<code>waitForLock</code>方法里：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">boolean</span> <span class="title">waitForLock</span><span class="params">(RedisConnection connection)</span> </span>&#123;</div><div class="line"></div><div class="line">	<span class="keyword">boolean</span> retry;</div><div class="line">	<span class="keyword">boolean</span> foundLock = <span class="keyword">false</span>;</div><div class="line">	do &#123;</div><div class="line">		retry = <span class="keyword">false</span>;</div><div class="line">		<span class="keyword">if</span> (connection.exists(cacheMetadata.getCacheLockKey())) &#123;</div><div class="line">			foundLock = <span class="keyword">true</span>;</div><div class="line">			<span class="keyword">try</span> &#123;</div><div class="line">				Thread.sleep(WAIT_FOR_LOCK_TIMEOUT); <span class="comment">//此处WAIT_FOR_LOCK_TIMEOUT=300ms</span></div><div class="line">			&#125; <span class="keyword">catch</span> (InterruptedException ex) &#123;</div><div class="line">				Thread.currentThread().interrupt();</div><div class="line">			&#125;</div><div class="line">			retry = <span class="keyword">true</span>;</div><div class="line">		&#125;</div><div class="line">	&#125; <span class="keyword">while</span> (retry);</div><div class="line"></div><div class="line">	<span class="keyword">return</span> foundLock;</div><div class="line">&#125;</div><div class="line"></div><div class="line">  <span class="comment">// 加锁</span></div><div class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">lock</span><span class="params">(RedisConnection connection)</span> </span>&#123;</div><div class="line">	waitForLock(connection);</div><div class="line">	connection.set(cacheMetadata.getCacheLockKey(), <span class="string">"locked"</span>.getBytes());</div><div class="line">&#125;</div><div class="line"> <span class="comment">// 解锁</span></div><div class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">unlock</span><span class="params">(RedisConnection connection)</span> </span>&#123;</div><div class="line">	connection.del(cacheMetadata.getCacheLockKey());</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>可以看出每次加锁，如果lock已经存在的情况下，会额外sleep 300ms,这在高并发、高性能的缓存场景是<strong>极其低效</strong>的。并且在极端情况下，unlock删除key没成功，将会导致所有key都无法设置或更新,并陷入死循环。spring内部也没有提供相关的行为覆盖机制，这是一个较大的坑。</p>
<h3 id="Spring-Data-Redis-2-0-RC1的优化"><a href="#Spring-Data-Redis-2-0-RC1的优化" class="headerlink" title="Spring-Data-Redis 2.0 RC1的优化"></a>Spring-Data-Redis 2.0 RC1的优化</h3><p><a href="https://jira.spring.io/browse/DATAREDIS-481" target="_blank" rel="external">官方DATAREDIS-481</a>注意到了Lock的优化，并对cache manager做了颠覆性的升级。<br>下面跟着我来看看，spring-data-redis 2.0之后如何使用注解式cache.<br>由于底层依赖的<a href="https://github.com/xetorthio/jedis" target="_blank" rel="external">Jedis</a>,自从发布2.9.0版本之后，升级缓慢，目前也仅支持到2.8.x和3.x.x版本，所以Spring推荐使用<a href="https://github.com/lettuce-io/lettuce-core" target="_blank" rel="external">lettuce</a>.</p>
<p>先看application.yml里如何写：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="attr">spring:</span></div><div class="line"><span class="attr">    redis:</span></div><div class="line"><span class="attr">      host:</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span></div><div class="line"><span class="attr">      database:</span> <span class="number">0</span></div><div class="line"><span class="attr">      port:</span> <span class="number">6379</span></div><div class="line"><span class="attr">      timeout:</span> <span class="number">1000</span></div><div class="line"><span class="attr">      lettuce:</span></div><div class="line"><span class="attr">        pool:</span></div><div class="line"><span class="attr">          max-active:</span> <span class="number">500</span></div><div class="line"><span class="attr">          min-idle:</span> <span class="number">0</span></div><div class="line"><span class="attr">          max-idle:</span> <span class="number">500</span></div><div class="line"><span class="attr">          max-wait:</span> <span class="number">1000</span></div></pre></td></tr></table></figure>
<p>开始使用lettuce了，jedis提示deprecated了。<br>pool提供的参数有限，如果想自己定制，参见如下设置：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div></pre></td><td class="code"><pre><div class="line">  	<span class="comment">//继承CachingConfigurerSupport</span></div><div class="line"><span class="meta">@Configuration</span></div><div class="line"><span class="meta">@EnableCaching</span></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">RedisConfig</span> <span class="keyword">extends</span> <span class="title">CachingConfigurerSupport</span> </span>&#123;</div><div class="line"></div><div class="line">    <span class="comment">//注入默认参数</span></div><div class="line">    <span class="meta">@Autowired</span></div><div class="line">    <span class="keyword">private</span> RedisProperties redisProperties;</div><div class="line">    <span class="comment">//默认超时</span></div><div class="line">    <span class="keyword">private</span> <span class="keyword">long</span> expire = <span class="number">600L</span>;</div><div class="line"></div><div class="line">    <span class="meta">@Bean</span></div><div class="line">    <span class="function"><span class="keyword">public</span> RedisConnectionFactory <span class="title">redisConnectionFactory</span><span class="params">()</span> </span>&#123;</div><div class="line">        <span class="comment">//commons-pool2包</span></div><div class="line">        GenericObjectPoolConfig poolConfig = <span class="keyword">new</span> GenericObjectPoolConfig();</div><div class="line">        poolConfig.setMaxIdle(<span class="number">500</span>);</div><div class="line">        poolConfig.setMinIdle(<span class="number">0</span>);</div><div class="line">        poolConfig.setMaxTotal(<span class="number">500</span>);</div><div class="line">        poolConfig.setMaxWaitMillis(<span class="number">1000</span>);</div><div class="line">        poolConfig.setTestOnBorrow(<span class="keyword">true</span>);   <span class="comment">//额外设置</span></div><div class="line"></div><div class="line">        <span class="comment">// 基本连接信息：host port database password</span></div><div class="line">        RedisStandaloneConfiguration redisStandaloneConfiguration = <span class="keyword">new</span> RedisStandaloneConfiguration();</div><div class="line">        redisStandaloneConfiguration.setHostName(redisProperties.getHost());</div><div class="line">        redisStandaloneConfiguration.setPort(redisProperties.getPort());</div><div class="line">        redisStandaloneConfiguration.setDatabase(redisProperties.getDatabase());</div><div class="line">        <span class="keyword">if</span> (<span class="keyword">null</span> != redisProperties.getPassword())&#123;</div><div class="line">            redisStandaloneConfiguration.setPassword(RedisPassword.of(redisProperties.getPassword()));</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="comment">//这里单独配置超时时间，连接池管理</span></div><div class="line">        LettuceClientConfiguration lettuceClientConfiguration = LettucePoolingClientConfiguration.builder()</div><div class="line">                .commandTimeout(Duration.ofMillis(<span class="number">200</span>)).shutdownTimeout(Duration.ofMillis(<span class="number">200</span>)).poolConfig</div><div class="line">                        (poolConfig)</div><div class="line">                .build();</div><div class="line">        LettuceConnectionFactory lettuceConnectionFactory = <span class="keyword">new</span> LettuceConnectionFactory</div><div class="line">                (redisStandaloneConfiguration, lettuceClientConfiguration);</div><div class="line">        lettuceConnectionFactory.setValidateConnection(<span class="keyword">true</span>);</div><div class="line">        <span class="keyword">return</span> lettuceConnectionFactory;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="meta">@Bean</span></div><div class="line">    <span class="function"><span class="keyword">public</span> CacheManager <span class="title">cacheManager</span><span class="params">(RedisConnectionFactory redisConnectionFactory)</span> </span>&#123;</div><div class="line">        <span class="comment">// 默认配置使用prefix、单独设置valueSerializer、过期时间</span></div><div class="line">        RedisCacheConfiguration redisCacheConfiguration =</div><div class="line">                RedisCacheConfiguration.defaultCacheConfig().serializeValuesWith(</div><div class="line">                        RedisSerializationContext.SerializationPair.fromSerializer(getValueSerializer()))</div><div class="line">                        .entryTtl(Duration.ofSeconds</div><div class="line">                                (expire)).disableCachingNullValues();</div><div class="line">        <span class="comment">// 使用redisConnectionFactory直接创建无锁的cm</span></div><div class="line">        RedisCacheManager cm = RedisCacheManager.builder(RedisCacheWriter.nonLockingRedisCacheWriter(redisConnectionFactory)).cacheDefaults(redisCacheConfiguration).transactionAware().build();</div><div class="line">        <span class="keyword">return</span> cm;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">private</span> RedisSerializer <span class="title">getValueSerializer</span><span class="params">()</span> </span>&#123;</div><div class="line">        Jackson2JsonRedisSerializer jackson2JsonRedisSerializer = <span class="keyword">new</span> Jackson2JsonRedisSerializer(Object.class);</div><div class="line">        ObjectMapper om = <span class="keyword">new</span> ObjectMapper();</div><div class="line">        om.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY);</div><div class="line">        om.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL);</div><div class="line">        jackson2JsonRedisSerializer.setObjectMapper(om);</div><div class="line">        <span class="keyword">return</span> jackson2JsonRedisSerializer;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="meta">@Bean</span></div><div class="line">    <span class="meta">@Override</span></div><div class="line">    <span class="function"><span class="keyword">public</span> CacheErrorHandler <span class="title">errorHandler</span><span class="params">()</span> </span>&#123;</div><div class="line">        <span class="keyword">return</span> <span class="keyword">new</span> RedisCacheErrorHandler();</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="meta">@Override</span></div><div class="line">    <span class="function"><span class="keyword">public</span> KeyGenerator <span class="title">keyGenerator</span><span class="params">()</span> </span>&#123;</div><div class="line">        <span class="keyword">return</span> <span class="keyword">new</span> MyKeyGenerator()</div><div class="line">    &#125;</div></pre></td></tr></table></figure>
<p>从上面可以看出，基本操作是一致的，但是RedisCacheManager创建更加优雅，不在直接依赖redisTemplate。<br>关于是否使用prefix问题，<code>RedisCacheConfiguration.defaultCacheConfig()</code>中代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">private</span> <span class="title">RedisCacheConfiguration</span><span class="params">(Duration ttl, Boolean cacheNullValues, Boolean usePrefix,</span></span></div><div class="line">		CacheKeyPrefix keyPrefix, SerializationPair&lt;String&gt; keySerializationPair,</div><div class="line">		SerializationPair&lt;?&gt; valueSerializationPair, ConversionService conversionService) &#123;</div><div class="line"></div><div class="line">	<span class="keyword">this</span>.ttl = ttl;</div><div class="line">	<span class="keyword">this</span>.cacheNullValues = cacheNullValues;</div><div class="line">	<span class="keyword">this</span>.usePrefix = usePrefix;</div><div class="line">	<span class="keyword">this</span>.keyPrefix = keyPrefix;</div><div class="line">	<span class="keyword">this</span>.keySerializationPair = keySerializationPair;</div><div class="line">	<span class="keyword">this</span>.valueSerializationPair = (SerializationPair&lt;Object&gt;) valueSerializationPair;</div><div class="line">	<span class="keyword">this</span>.conversionService = conversionService;</div><div class="line">&#125;</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> RedisCacheConfiguration <span class="title">defaultCacheConfig</span><span class="params">()</span> </span>&#123;</div><div class="line"></div><div class="line">	DefaultFormattingConversionService conversionService = <span class="keyword">new</span> DefaultFormattingConversionService();</div><div class="line"></div><div class="line">	registerDefaultConverters(conversionService);</div><div class="line">   <span class="comment">// 默认usePrefix为true,是推荐的</span></div><div class="line">	<span class="keyword">return</span> <span class="keyword">new</span> RedisCacheConfiguration(Duration.ZERO, <span class="keyword">true</span>, <span class="keyword">true</span>, CacheKeyPrefix.simple(),</div><div class="line">			SerializationPair.fromSerializer(<span class="keyword">new</span> StringRedisSerializer()),</div><div class="line">			SerializationPair.fromSerializer(<span class="keyword">new</span> JdkSerializationRedisSerializer()), conversionService);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>当然也是可以覆盖禁用的，使用<code>disableKeyPrefix</code>, 但明确提出，你需要特别注意，不建议使用。</p>
<p>关于是否使用lock的问题，新版本也提供了可选方案。通过<code>RedisCacheWriter</code>来实现：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">static</span> RedisCacheWriter <span class="title">nonLockingRedisCacheWriter</span><span class="params">(RedisConnectionFactory connectionFactory)</span> </span>&#123;</div><div class="line"></div><div class="line">	Assert.notNull(connectionFactory, <span class="string">"ConnectionFactory must not be null!"</span>);</div><div class="line"></div><div class="line">	<span class="keyword">return</span> <span class="keyword">new</span> DefaultRedisCacheWriter(connectionFactory);</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">static</span> RedisCacheWriter <span class="title">lockingRedisCacheWriter</span><span class="params">(RedisConnectionFactory connectionFactory)</span> </span>&#123;</div><div class="line"></div><div class="line">	Assert.notNull(connectionFactory, <span class="string">"ConnectionFactory must not be null!"</span>);</div><div class="line"></div><div class="line">	<span class="keyword">return</span> <span class="keyword">new</span> DefaultRedisCacheWriter(connectionFactory, Duration.ofMillis(<span class="number">50</span>));</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>可以看出lockingRedisCacheWriter将会有sleep 50ms来处理锁,nonlocking则没有加锁等待，给用户提供了更好的处理方案。</p>
<p>关于全部失效或者清理key的问题，2.0版本处理方案如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div></pre></td><td class="code"><pre><div class="line"><span class="meta">@Override</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">clean</span><span class="params">(String name, <span class="keyword">byte</span>[] pattern)</span> </span>&#123;</div><div class="line"></div><div class="line">	Assert.notNull(name, <span class="string">"Name must not be null!"</span>);</div><div class="line">	Assert.notNull(pattern, <span class="string">"Pattern must not be null!"</span>);</div><div class="line"></div><div class="line">	execute(name, connection -&gt; &#123;</div><div class="line"></div><div class="line">		<span class="keyword">boolean</span> wasLocked = <span class="keyword">false</span>;</div><div class="line"></div><div class="line">		<span class="keyword">try</span> &#123;</div><div class="line"></div><div class="line">			<span class="keyword">if</span> (isLockingCacheWriter()) &#123;</div><div class="line">				doLock(name, connection);</div><div class="line">				wasLocked = <span class="keyword">true</span>;</div><div class="line">			&#125;</div><div class="line">         <span class="comment">// 这里仍旧是使用的keys操作</span></div><div class="line">			<span class="keyword">byte</span>[][] keys = Optional.ofNullable(connection.keys(pattern)).orElse(Collections.emptySet())</div><div class="line">					.toArray(<span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">0</span>][]);</div><div class="line"></div><div class="line">			<span class="keyword">if</span> (keys.length &gt; <span class="number">0</span>) &#123;</div><div class="line">				connection.del(keys);</div><div class="line">			&#125;</div><div class="line">		&#125; <span class="keyword">finally</span> &#123;</div><div class="line"></div><div class="line">			<span class="keyword">if</span> (wasLocked &amp;&amp; isLockingCacheWriter()) &#123;</div><div class="line">				doUnlock(name, connection);</div><div class="line">			&#125;</div><div class="line">		&#125;</div><div class="line"></div><div class="line">		<span class="keyword">return</span> <span class="string">"OK"</span>;</div><div class="line">	&#125;);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>这里仍旧使用的是<code>keys</code>命令，坑仍在。后续使用<code>scan</code>操作也许是更好的选择，但最终还是要依据自己的业务需求来定制。</p>
<p>总结：</p>
<blockquote>
<p><strong>开源项目的坑无处不在，即使是spring</strong>。<br>无论是什么版本，使用<code>prefix</code>是更好的选择，也是趋势所在。<br>keys操作对性能的影响始终未能彻底消除，建议使用key expire机制来规避。（生产环境keys操作也是尽可能要避免的）。<br>redis缓存key的大小，无论是性能还是存储的影响都很大，强烈建议在业务允许范围内尽可能减小key的大小(比如使用MD5,有一定碰撞率)。</p>
</blockquote>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;前言：&quot;&gt;&lt;a href=&quot;#前言：&quot; class=&quot;headerlink&quot; title=&quot;前言：&quot;&gt;&lt;/a&gt;前言：&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;spring-data-redis使得Spring项目可以快速简单的通过RedisTemplate来操作Redis。而spring-boot-starter-data-redis更是让redis集成更加的方便。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;SpringBoot如何与Redis集成，作为cache&quot;&gt;&lt;a href=&quot;#SpringBoot如何与Redis集成，作为cache&quot; class=&quot;headerlink&quot; title=&quot;SpringBoot如何与Redis集成，作为cache&quot;&gt;&lt;/a&gt;SpringBoot如何与Redis集成，作为cache&lt;/h3&gt;&lt;p&gt;application.yml里如下配置：&lt;/p&gt;
&lt;figure class=&quot;highlight yml&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;5&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;6&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;7&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;8&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;9&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;10&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;11&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;&lt;span class=&quot;attr&quot;&gt;spring:&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;span class=&quot;attr&quot;&gt;  redis:&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;span class=&quot;attr&quot;&gt;    host:&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;127.0&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;.0&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;.1&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    	port: &lt;span class=&quot;number&quot;&gt;6379&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    	database: &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    	timeout: &lt;span class=&quot;number&quot;&gt;1000&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    	pool:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;      		max-idle: &lt;span class=&quot;number&quot;&gt;200&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;      		min-idle: &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;      		max-active: &lt;span class=&quot;number&quot;&gt;200&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;      		max-wait: &lt;span class=&quot;number&quot;&gt;1000&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;spring boot可以自动组装相关配置，注意其中使用到了jedis pool，用于提升性能，非必须。&lt;br&gt;通过以下的annotation加入方法名上，可以无侵入的使用cache。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;@Cacheable   缓存&lt;/li&gt;
&lt;li&gt;@CachePut    设置缓存&lt;/li&gt;
&lt;li&gt;@CacheEvict  失效或更新缓存&lt;/li&gt;
&lt;li&gt;&lt;p&gt;@Caching   组合操作&lt;/p&gt;
&lt;p&gt;以上annotation不做详细展开。&lt;/p&gt;
    
    </summary>
    
      <category term="spring" scheme="https://www.shenyanchao.cn/categories/spring/"/>
    
    
      <category term="spring" scheme="https://www.shenyanchao.cn/tags/spring/"/>
    
      <category term="redis" scheme="https://www.shenyanchao.cn/tags/redis/"/>
    
      <category term="cache" scheme="https://www.shenyanchao.cn/tags/cache/"/>
    
  </entry>
  
  <entry>
    <title>关于接口定义的一些想法</title>
    <link href="https://www.shenyanchao.cn/blog/2016/03/20/about-interface-define/"/>
    <id>https://www.shenyanchao.cn/blog/2016/03/20/about-interface-define/</id>
    <published>2016-03-20T02:43:00.000Z</published>
    <updated>2018-12-26T08:46:24.863Z</updated>
    
    <content type="html"><![CDATA[<p>最近公司内项目，需要开发接口给ios,android客户端去调用。因此，做了一些思考，主要是关于如何更好的定义接口以及联调。</p>
<h3 id="使用RESTFul接口"><a href="#使用RESTFul接口" class="headerlink" title="使用RESTFul接口"></a>使用RESTFul接口</h3><p>RESTFul接口作为一个通行的标准，当然是优先使用的。项目都是基于Spring的，因此采用的是Spring MVC.</p>
<h3 id="解决接口联调的苦难"><a href="#解决接口联调的苦难" class="headerlink" title="解决接口联调的苦难"></a>解决接口联调的苦难</h3><p>作为一个技术人员，写文档是一大令人头疼的事情。况且即使把文档写好了，也可能导致在以后的修修补补中，导致不一致的情况。<br>因此，考虑采用文档自动生成的方式。最终选用了<a href="www.swagger.io">Swagger</a>来自动为Spring MVC生成文档。</p>
<ul>
<li>swagger-maven-plugin</li>
<li>swagger-ui</li>
</ul>
<h3 id="项目中遇到的一些教训"><a href="#项目中遇到的一些教训" class="headerlink" title="项目中遇到的一些教训"></a>项目中遇到的一些教训</h3><p>作为技术负责人</p>
<ul>
<li>提前制定接口，方便联调</li>
<li>提前规划返回接口类型，统一字段名称。</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近公司内项目，需要开发接口给ios,android客户端去调用。因此，做了一些思考，主要是关于如何更好的定义接口以及联调。&lt;/p&gt;
&lt;h3 id=&quot;使用RESTFul接口&quot;&gt;&lt;a href=&quot;#使用RESTFul接口&quot; class=&quot;headerlink&quot; title=&quot;
    
    </summary>
    
      <category term="java" scheme="https://www.shenyanchao.cn/categories/java/"/>
    
    
      <category term="spring" scheme="https://www.shenyanchao.cn/tags/spring/"/>
    
      <category term="restful" scheme="https://www.shenyanchao.cn/tags/restful/"/>
    
      <category term="interface" scheme="https://www.shenyanchao.cn/tags/interface/"/>
    
  </entry>
  
  <entry>
    <title>Restful Spring MVC</title>
    <link href="https://www.shenyanchao.cn/blog/2015/11/03/restful-springmvc/"/>
    <id>https://www.shenyanchao.cn/blog/2015/11/03/restful-springmvc/</id>
    <published>2015-11-03T05:53:00.000Z</published>
    <updated>2018-10-23T08:57:11.266Z</updated>
    
    <content type="html"><![CDATA[<p>Spring MVC本身对Restful支持非常好。它的<code>@RequestMapping</code>、<code>@RequestParam</code>、<code>@PathVariable</code>、<code>@ResponseBody</code>注解很好的支持了REST。<a href="http://static.springsource.org/spring/docs/3.0.0.M3/reference/html/ch18s02.html" target="_blank" rel="external">18.2 Creating RESTful services</a></p>
<h3 id="1-RequestMapping"><a href="#1-RequestMapping" class="headerlink" title="1. @RequestMapping"></a>1. <code>@RequestMapping</code></h3><p>Spring uses the @RequestMapping method annotation to define the URI Template for the request. 类似于struts的action-mapping。 可以指定POST或者GET。</p>
<h3 id="2-PathVariable"><a href="#2-PathVariable" class="headerlink" title="2. @PathVariable"></a>2. <code>@PathVariable</code></h3><p>The @PathVariable method parameter annotation is used to indicate that a method parameter should be bound to the value of a URI template variable. 用于抽取URL中的信息作为参数。（注意，不包括请求字符串，那是<code>@RequestParam</code>做的事情。）</p>
<pre><code>@RequestMapping(&quot;/owners/{ownerId}&quot;, method=RequestMethod.GET)
public String findOwner(@PathVariable String ownerId, Model model) {
        // ...
}
</code></pre><p>如果变量名与pathVariable名不一致，那么需要指定：</p>
<pre><code>@RequestMapping(&quot;/owners/{ownerId}&quot;, method=RequestMethod.GET)
public String findOwner(@PathVariable(&quot;ownerId&quot;) String theOwner, Model model) {
    // implementation omitted
}
</code></pre><blockquote>
<p><strong>Tip</strong></p>
<p>method parameters that are decorated with the @PathVariable annotation can be of any simple type such as int, long, Date… Spring automatically converts to the appropriate type and throws a TypeMismatchException if the type is not correct.</p>
</blockquote>
<a id="more"></a>
<h3 id="3-RequestParam"><a href="#3-RequestParam" class="headerlink" title="3. @RequestParam"></a>3. <code>@RequestParam</code></h3><p>官方文档居然没有对这个注解进行说明，估计是遗漏了（真不应该啊）。这个注解跟<code>@PathVariable</code>功能差不多，只是参数值的来源不一样而已。它的取值来源是请求参数（querystring或者post表单字段）。</p>
<p>对了，因为它的来源可以是POST字段，所以它支持更丰富和复杂的类型信息。比如文件对象:</p>
<pre><code>@RequestMapping(&quot;/imageUpload&quot;)
public String processImageUpload(@RequestParam(&quot;name&quot;) String name,
                @RequestParam(&quot;description&quot;) String description,
                @RequestParam(&quot;image&quot;) MultipartFile image) throws IOException {
    this.imageDatabase.storeImage(name, image.getInputStream(),
                                    (int) image.getSize(), description);
    return &quot;redirect:imageList&quot;;
}
</code></pre><p>还可以设置defaultValue：</p>
<pre><code>@RequestMapping(&quot;/imageUpload&quot;)
public String processImageUpload(@RequestParam(value=&quot;name&quot;, defaultValue=&quot;arganzheng&quot;) String name,
                @RequestParam(&quot;description&quot;) String description,
                @RequestParam(&quot;image&quot;) MultipartFile image) throws IOException {
    this.imageDatabase.storeImage(name, image.getInputStream(),
                                    (int) image.getSize(), description);
    return &quot;redirect:imageList&quot;;
}
</code></pre><h3 id="4-RequestBody和-ResponseBody"><a href="#4-RequestBody和-ResponseBody" class="headerlink" title="4. @RequestBody和@ResponseBody"></a>4. <code>@RequestBody</code>和<code>@ResponseBody</code></h3><p>这两个注解其实用到了Spring的一个非常灵活的设计——<code>HttpMessageConverter</code> <a href="http://static.springsource.org/spring/docs/3.0.0.M3/reference/html/ch18s03.html#rest-message-conversion" target="_blank" rel="external">18.3.2 HTTP Message Conversion</a></p>
<p>与<code>@RequestParam</code>不同，<code>@RequestBody</code>和<code>@ResponseBody</code>是针对整个HTTP请求或者返回消息的。前者只是针对HTTP请求消息中的一个 name=value 键值对(名称很贴切)。</p>
<p><code>HtppMessageConverter</code>负责将HTTP请求消息(HTTP request message)转化为对象，或者将对象转化为HTTP响应体(HTTP response body)。</p>
<pre><code>public interface HttpMessageConverter&lt;T&gt; {

    // Indicate whether the given class is supported by this converter.
    boolean supports(Class&lt;? extends T&gt; clazz);

    // Return the list of MediaType objects supported by this converter.
    List&lt;MediaType&gt; getSupportedMediaTypes();

    // Read an object of the given type form the given input message, and returns it.
    T read(Class&lt;T&gt; clazz, HttpInputMessage inputMessage) throws IOException,
                                                                    HttpMessageNotReadableException;

    // Write an given object to the given output message.
    void write(T t, HttpOutputMessage outputMessage) throws IOException,
                                                            HttpMessageNotWritableException;

}
</code></pre><p>Spring MVC对<code>HttpMessageConverter</code>有多种默认实现，基本上不需要自己再自定义<code>HttpMessageConverter</code><br>&gt;</p>
<ul>
<li>StringHttpMessageConverter - converts strings</li>
<li>FormHttpMessageConverter - converts form data to/from a MultiValueMap<string, string=""></string,></li>
<li>ByteArrayMessageConverter - converts byte arrays</li>
<li>SourceHttpMessageConverter - convert to/from a javax.xml.transform.Source</li>
<li>RssChannelHttpMessageConverter - convert to/from RSS feeds</li>
<li>MappingJacksonHttpMessageConverter - convert to/from JSON using Jackson’s ObjectMapper</li>
<li>etc…</li>
</ul>
<p>然而对于RESTful应用，用的最多的当然是<code>MappingJacksonHttpMessageConverter</code>。</p>
<p>但是<code>MappingJacksonHttpMessageConverter</code>不是默认的<code>HttpMessageConverter</code>：</p>
<pre><code>public class AnnotationMethodHandlerAdapter extends WebContentGenerator
implements HandlerAdapter, Ordered, BeanFactoryAware {

    ...

    public AnnotationMethodHandlerAdapter() {
        // no restriction of HTTP methods by default
        super(false);

        // See SPR-7316
        StringHttpMessageConverter stringHttpMessageConverter = new StringHttpMessageConverter();
        stringHttpMessageConverter.setWriteAcceptCharset(false);
        this.messageConverters = new HttpMessageConverter[]{new ByteArrayHttpMessageConverter(), stringHttpMessageConverter,
        new SourceHttpMessageConverter(), new XmlAwareFormHttpMessageConverter()};
    }
}
</code></pre><p>如上：默认的<code>HttpMessageConverter</code>是<code>ByteArrayHttpMessageConverter</code>、<code>stringHttpMessageConverter</code>、<code>SourceHttpMessageConverter</code>和<code>XmlAwareFormHttpMessageConverter</code>转换器。所以需要配置一下：</p>
<pre><code>&lt;bean class=&quot;org.springframework.web.servlet.mvc.annotation.AnnotationMethodHandlerAdapter&quot;&gt;
    &lt;property name=&quot;messageConverters&quot;&gt;
    &lt;list&gt;
        &lt;bean class=&quot;org.springframework.http.converter.StringHttpMessageConverter&quot;&gt;
        &lt;property name=&quot;supportedMediaTypes&quot;&gt;
            &lt;list&gt;
            &lt;value&gt;text/plain;charset=GBK&lt;/value&gt;
            &lt;/list&gt;
        &lt;/property&gt;
        &lt;/bean&gt;
        &lt;bean class=&quot;org.springframework.http.converter.json.MappingJacksonHttpMessageConverter&quot; /&gt;
    &lt;/list&gt;
    &lt;/property&gt;
&lt;/bean&gt;
</code></pre><p>配置好了之后，就可以享受<code>@Requestbody</code>和<code>@ResponseBody</code>对JONS转换的便利之处了：</p>
<pre><code>@RequestMapping(value = &quot;api&quot;, method = RequestMethod.POST)
@ResponseBody
public boolean addApi(@RequestBody
    Api api, @RequestParam(value = &quot;afterApiId&quot;, required = false)
    Integer afterApiId) {
        Integer id = apiMetadataService.addApi(api);
        return id &gt; 0;
}

@RequestMapping(value = &quot;api/{apiId}&quot;, method = RequestMethod.GET)
@ResponseBody
public Api getApi(@PathVariable(&quot;apiId&quot;)
    int apiId) {
        return apiMetadataService.getApi(apiId, Version.primary);
}
</code></pre><p>一般情况下我们是不需要自定义<code>HttpMessageConverter</code>，不过对于Restful应用，有时候我们需要返回jsonp数据：</p>
<pre><code>package me.arganzheng.study.springmvc.util;

import java.io.IOException;
import java.io.PrintStream;

import org.codehaus.jackson.map.ObjectMapper;
import org.codehaus.jackson.map.annotate.JsonSerialize.Inclusion;
import org.springframework.http.HttpOutputMessage;
import org.springframework.http.converter.HttpMessageNotWritableException;
import org.springframework.http.converter.json.MappingJacksonHttpMessageConverter;
import org.springframework.web.context.request.RequestAttributes;
import org.springframework.web.context.request.RequestContextHolder;
import org.springframework.web.context.request.ServletRequestAttributes;

public class MappingJsonpHttpMessageConverter extends MappingJacksonHttpMessageConverter {

    public MappingJsonpHttpMessageConverter() {
    ObjectMapper objectMapper = new ObjectMapper();
    objectMapper.setSerializationConfig(objectMapper.getSerializationConfig().withSerializationInclusion(Inclusion.NON_NULL));
    setObjectMapper(objectMapper);
    }

    @Override
    protected void writeInternal(Object o, HttpOutputMessage outputMessage) throws IOException, HttpMessageNotWritableException {
    String jsonpCallback = null;

    RequestAttributes reqAttrs = RequestContextHolder.currentRequestAttributes();
    if(reqAttrs instanceof ServletRequestAttributes){
        jsonpCallback = ((ServletRequestAttributes)reqAttrs).getRequest().getParameter(&quot;jsonpCallback&quot;);
    }

    if(jsonpCallback != null){
        new PrintStream(outputMessage.getBody()).print(jsonpCallback + &quot;(&quot;);
    }

    super.writeInternal(o, outputMessage);

    if(jsonpCallback != null){
        new PrintStream(outputMessage.getBody()).println(&quot;);&quot;);
    }
    }
}
</code></pre><p>如果请求的参数中带有<code>jsonpCallback</code>，那么会返回jsonp格式数据。比如：<br><a href="http://open.buy.qq.com/meta/api/1.xhtml?jsonpCallback=clientFunction。" target="_blank" rel="external">http://open.buy.qq.com/meta/api/1.xhtml?jsonpCallback=clientFunction。</a><br>会返回<code>clientFunction(…);</code></p>
<h3 id="5-CookieValue"><a href="#5-CookieValue" class="headerlink" title="5. @CookieValue"></a>5. <code>@CookieValue</code></h3><p><code>@CookieValue</code>用于将请求的Cookie数据映射到功能处理方法的参数上。</p>
<pre><code>public String test(@CookieValue(value=&quot;JSESSIONID&quot;, defaultValue=&quot;&quot;) String sessionId){
    ...
}
</code></pre><p>如上配置将自动将JSESSIONID值入参到sessionId参数上，defaultValue表示Cookie中没有JSESSIONID时默认为空。</p>
<pre><code>public String test2(@CookieValue(value=&quot;JSESSIONID&quot;, defaultValue=&quot;&quot;) Cookie sessionId){
    ...
}
</code></pre><p>传入参数类型也可以是javax.servlet.http.Cookie类型。</p>
<p><strong>TIPS</strong> 如果是使用cookies值来保持回话状态的话，推荐使用Spring的<a href="http://docs.spring.io/spring/docs/3.0.0.M3/reference/html/ch04s04.html" target="_blank" rel="external">Bean Scopes</a>机制，具体参见笔者的另一篇文章：<a href="http://blog.arganzheng.me/posts/spring-bean-scopes.html" target="_blank" rel="external">Spring的Bean Scopes</a>。非常方便。</p>
<h3 id="6-RequestHeader"><a href="#6-RequestHeader" class="headerlink" title="6. @RequestHeader"></a>6. <code>@RequestHeader</code></h3><p><code>@RequestHeader</code>用于将请求的头信息区数据映射到功能处理方法的参数上。</p>
<pre><code>@RequestMapping(value=&quot;/header&quot;)
public String test(
   @RequestHeader(&quot;User-Agent&quot;) String userAgent,
   @RequestHeader(value=&quot;Accept&quot;) String[] accepts)
</code></pre><p>如上配置将自动将请求头“User-Agent”值入参到userAgent参数上，并将“Accept”请求头值入参到accepts参数上。</p>
<h3 id="7-返回多种表现形式-Returning-multiple-representations"><a href="#7-返回多种表现形式-Returning-multiple-representations" class="headerlink" title="7. 返回多种表现形式(Returning multiple representations)"></a>7. 返回多种表现形式(Returning multiple representations)</h3><p>对于Restful服务，一个资源往往有多种表现形式，比如最常见的就是返回xml和json格式数据，还有就是RSS和ATOM。怎样让客户端告诉Restful服务，我希望得到什么样表现形式的资源呢？</p>
<p>一般来说client可以通过以下三者方式来通知Server它希望拿到的资源格式：</p>
<ol>
<li>使用不同URI来表示同个资源的不同表现形式。一般使用不同的文件拓展名。如<a href="http://blog.arganzheng.me/users/argan.xml表示返回xml格式数据，而http://blog.arganzheng.me/users/aganzheng.json表示返回json格式" target="_blank" rel="external">http://blog.arganzheng.me/users/argan.xml表示返回xml格式数据，而http://blog.arganzheng.me/users/aganzheng.json表示返回json格式</a>.</li>
<li>使用一个请求参数告诉服务器希望得到的资源格式。如format=json。</li>
<li>使用同个URI，但是通过Accept HTTP request header来告诉server它理解的media types。例如同样请求<a href="http://blog.arganzheng.me/users/argan，如果带上`text/xml`" target="_blank" rel="external">http://blog.arganzheng.me/users/argan，如果带上`text/xml`</a> accept header表示请求一个XML资源，带上<code>application/pdf</code>则表示期望收到pdf格式资源。</li>
</ol>
<p>这其实就是Spring MVC默认的三个<code>ContentNegotiationStrategy</code>，即所谓的PPA Strategy（path extension, then parameter, then Accept header) ，顺序也是先path extension，然后parameter(默认是format参数)，然后才是accept头。</p>
<p>Spring提供了<a href="http://static.springsource.org/spring/docs/3.0.x/javadoc-api/org/springframework/web/servlet/view/ContentNegotiatingViewResolver.html" target="_blank" rel="external"><code>ContentNegotiatingViewResolver</code></a>来解决这个问题：</p>
<pre><code>public class ContentNegotiatingViewResolver extends WebApplicationObjectSupport implements ViewResolver, Ordered {

    private static final Log logger = LogFactory.getLog(ContentNegotiatingViewResolver.class);

    private static final String ACCEPT_HEADER = &quot;Accept&quot;;

    private static final boolean jafPresent =
        ClassUtils.isPresent(&quot;javax.activation.FileTypeMap&quot;, ContentNegotiatingViewResolver.class.getClassLoader());

    private static final UrlPathHelper urlPathHelper = new UrlPathHelper();


    private int order = Ordered.HIGHEST_PRECEDENCE;

    private boolean favorPathExtension = true;

    private boolean favorParameter = false;

    private String parameterName = &quot;format&quot;;

    private boolean useNotAcceptableStatusCode = false;

    private boolean ignoreAcceptHeader = false;

    private boolean useJaf = true;

    private ConcurrentMap&lt;String, MediaType&gt; mediaTypes = new ConcurrentHashMap&lt;String, MediaType&gt;();

    private List&lt;View&gt; defaultViews;

    private MediaType defaultContentType;

    private List&lt;ViewResolver&gt; viewResolvers;


    // ignore some setter and getter...

    public void setMediaTypes(Map&lt;String, String&gt; mediaTypes) {
      Assert.notNull(mediaTypes, &quot;&apos;mediaTypes&apos; must not be null&quot;);
      for (Map.Entry&lt;String, String&gt; entry : mediaTypes.entrySet()) {
        String extension = entry.getKey().toLowerCase(Locale.ENGLISH);
        MediaType mediaType = MediaType.parseMediaType(entry.getValue());
        this.mediaTypes.put(extension, mediaType);
      }
    }

    public void setDefaultViews(List&lt;View&gt; defaultViews) {
      this.defaultViews = defaultViews;
    }

    public void setDefaultContentType(MediaType defaultContentType) {
      this.defaultContentType = defaultContentType;
    }

    public void setViewResolvers(List&lt;ViewResolver&gt; viewResolvers) {
      this.viewResolvers = viewResolvers;
    }


    @Override
    protected void initServletContext(ServletContext servletContext) {
      if (this.viewResolvers == null) {
        Map&lt;String, ViewResolver&gt; matchingBeans =
            BeanFactoryUtils.beansOfTypeIncludingAncestors(getApplicationContext(), ViewResolver.class);
        this.viewResolvers = new ArrayList&lt;ViewResolver&gt;(matchingBeans.size());
        for (ViewResolver viewResolver : matchingBeans.values()) {
          if (this != viewResolver) {
            this.viewResolvers.add(viewResolver);
          }
        }
      }
      if (this.viewResolvers.isEmpty()) {
        logger.warn(&quot;Did not find any ViewResolvers to delegate to; please configure them using the &quot; +
            &quot;&apos;viewResolvers&apos; property on the ContentNegotiatingViewResolver&quot;);
      }
      OrderComparator.sort(this.viewResolvers);
    }

    public View resolveViewName(String viewName, Locale locale) throws Exception {
      RequestAttributes attrs = RequestContextHolder.getRequestAttributes();
      Assert.isInstanceOf(ServletRequestAttributes.class, attrs);
      List&lt;MediaType&gt; requestedMediaTypes = getMediaTypes(((ServletRequestAttributes) attrs).getRequest());
      if (requestedMediaTypes != null) {
        List&lt;View&gt; candidateViews = getCandidateViews(viewName, locale, requestedMediaTypes);
        View bestView = getBestView(candidateViews, requestedMediaTypes);
        if (bestView != null) {
          return bestView;
        }
      }
      if (this.useNotAcceptableStatusCode) {
        if (logger.isDebugEnabled()) {
          logger.debug(&quot;No acceptable view found; returning 406 (Not Acceptable) status code&quot;);
        }
        return NOT_ACCEPTABLE_VIEW;
      }
      else {
        logger.debug(&quot;No acceptable view found; returning null&quot;);
        return null;
      }
    }


    protected List&lt;MediaType&gt; getMediaTypes(HttpServletRequest request) {
      if (this.favorPathExtension) {
        String requestUri = urlPathHelper.getRequestUri(request);
        String filename = WebUtils.extractFullFilenameFromUrlPath(requestUri);
        MediaType mediaType = getMediaTypeFromFilename(filename);
        if (mediaType != null) {
          if (logger.isDebugEnabled()) {
            logger.debug(&quot;Requested media type is &apos;&quot; + mediaType + &quot;&apos; (based on filename &apos;&quot; + filename + &quot;&apos;)&quot;);
          }
          return Collections.singletonList(mediaType);
        }
      }
      if (this.favorParameter) {
        if (request.getParameter(this.parameterName) != null) {
          String parameterValue = request.getParameter(this.parameterName);
          MediaType mediaType = getMediaTypeFromParameter(parameterValue);
          if (mediaType != null) {
            if (logger.isDebugEnabled()) {
              logger.debug(&quot;Requested media type is &apos;&quot; + mediaType + &quot;&apos; (based on parameter &apos;&quot; +
                  this.parameterName + &quot;&apos;=&apos;&quot; + parameterValue + &quot;&apos;)&quot;);
            }
            return Collections.singletonList(mediaType);
          }
        }
      }
      if (!this.ignoreAcceptHeader) {
        String acceptHeader = request.getHeader(ACCEPT_HEADER);
        if (StringUtils.hasText(acceptHeader)) {
          try {
                      List&lt;MediaType&gt; mediaTypes = MediaType.parseMediaTypes(acceptHeader);
                      MediaType.sortByQualityValue(mediaTypes);
                      if (logger.isDebugEnabled()) {
                          logger.debug(&quot;Requested media types are &quot; + mediaTypes + &quot; (based on Accept header)&quot;);
                      }
                      return mediaTypes;
          }
          catch (IllegalArgumentException ex) {
            if (logger.isDebugEnabled()) {
              logger.debug(&quot;Could not parse accept header [&quot; + acceptHeader + &quot;]: &quot; + ex.getMessage());
            }
            return null;
          }
        }
      }
      if (this.defaultContentType != null) {
        if (logger.isDebugEnabled()) {
          logger.debug(&quot;Requested media types is &quot; + this.defaultContentType +
              &quot; (based on defaultContentType property)&quot;);
        }
        return Collections.singletonList(this.defaultContentType);
      }
      else {
        return Collections.emptyList();
      }
    }


    protected MediaType getMediaTypeFromFilename(String filename) {
      String extension = StringUtils.getFilenameExtension(filename);
      if (!StringUtils.hasText(extension)) {
        return null;
      }
      extension = extension.toLowerCase(Locale.ENGLISH);
      MediaType mediaType = this.mediaTypes.get(extension);
      if (mediaType == null &amp;&amp; this.useJaf &amp;&amp; jafPresent) {
        mediaType = ActivationMediaTypeFactory.getMediaType(filename);
        if (mediaType != null) {
          this.mediaTypes.putIfAbsent(extension, mediaType);
        }
      }
      return mediaType;
    }


    protected MediaType getMediaTypeFromParameter(String parameterValue) {
      return this.mediaTypes.get(parameterValue.toLowerCase(Locale.ENGLISH));
    }

    private List&lt;View&gt; getCandidateViews(String viewName, Locale locale, List&lt;MediaType&gt; requestedMediaTypes)
        throws Exception {

      List&lt;View&gt; candidateViews = new ArrayList&lt;View&gt;();
      for (ViewResolver viewResolver : this.viewResolvers) {
        View view = viewResolver.resolveViewName(viewName, locale);
        if (view != null) {
          candidateViews.add(view);
        }
        for (MediaType requestedMediaType : requestedMediaTypes) {
          List&lt;String&gt; extensions = getExtensionsForMediaType(requestedMediaType);
          for (String extension : extensions) {
            String viewNameWithExtension = viewName + &quot;.&quot; + extension;
            view = viewResolver.resolveViewName(viewNameWithExtension, locale);
            if (view != null) {
              candidateViews.add(view);
            }
          }

        }
      }
      if (!CollectionUtils.isEmpty(this.defaultViews)) {
        candidateViews.addAll(this.defaultViews);
      }
      return candidateViews;
    }

    private List&lt;String&gt; getExtensionsForMediaType(MediaType requestedMediaType) {
      List&lt;String&gt; result = new ArrayList&lt;String&gt;();
      for (Entry&lt;String, MediaType&gt; entry : this.mediaTypes.entrySet()) {
        if (requestedMediaType.includes(entry.getValue())) {
          result.add(entry.getKey());
        }
      }
      return result;
    }

    private View getBestView(List&lt;View&gt; candidateViews, List&lt;MediaType&gt; requestedMediaTypes) {
      MediaType bestRequestedMediaType = null;
      View bestView = null;
      for (MediaType requestedMediaType : requestedMediaTypes) {
        for (View candidateView : candidateViews) {
          if (StringUtils.hasText(candidateView.getContentType())) {
            MediaType candidateContentType = MediaType.parseMediaType(candidateView.getContentType());
            if (requestedMediaType.includes(candidateContentType)) {
              bestRequestedMediaType = requestedMediaType;
              bestView = candidateView;
              break;
            }
          }
        }
        if (bestView != null) {
          if (logger.isDebugEnabled()) {
            logger.debug(&quot;Returning [&quot; + bestView + &quot;] based on requested media type &apos;&quot; +
                bestRequestedMediaType + &quot;&apos;&quot;);
          }
          break;
        }
      }
      return bestView;

    }

    ...

}
</code></pre><p>可以看到<code>ContentNegotiationViewResolver</code>有点类似于ComposeCommand（参见Command模式 by GoF），它本身实现了ViewResolver接口，所以它是一个ViewResolver，但是它组合了一堆的ViewResolver，根据一定的规则（前面讨论的content negotiation）将视图请求转发给最match的ViewResolver。</p>
<p>所以关键在两点：</p>
<h4 id="1-content-negotiation策略-ContentNegotiationStrategy"><a href="#1-content-negotiation策略-ContentNegotiationStrategy" class="headerlink" title="1. content negotiation策略 (ContentNegotiationStrategy)"></a>1. content negotiation策略 (<code>ContentNegotiationStrategy</code>)</h4><blockquote>
<p>This view resolver uses the requested media type to select a suitable View for a request. This media type is determined by using the following criteria:</p>
<ol>
<li>If the requested path has a file extension and if the setFavorPathExtension(boolean) property is true, the mediaTypes property is inspected for a matching media type.</li>
<li>If the request contains a parameter defining the extension and if the setFavorParameter(boolean) property is true, the mediaTypes property is inspected for a matching media type. The default name of the parameter is format and it can be configured using the parameterName property.</li>
<li>If there is no match in the mediaTypes property and if the Java Activation Framework (JAF) is both enabled and present on the classpath, FileTypeMap.getContentType(String) is used instead.</li>
<li>If the previous steps did not result in a media type, and ignoreAcceptHeader is false, the request Accept header is used.</li>
</ol>
<p>Once the requested media type has been determined, this resolver queries each delegate view resolver for a View and determines if the requested media type is compatible with the view’s content type). The most compatible view is returned.</p>
</blockquote>
<p>这个就是上面提到的Spring MVC默认的三个<code>ContentNegotiationStrategy</code>，即所谓的PPA Strategy（path extension, then parameter, then Accept header) ，顺序也是先path extension，然后parameter(默认是format参数)，然后才是accept头。</p>
<p>关于<code>ContentNegotiationStrategy</code>，可以参考笔者的另一篇文章：<a href="http://blog.arganzheng.me/posts/content-negotiation-using-spring-mvc.html" target="_blank" rel="external">content negotiation using spring mvc</a>。有具体的实际案例。</p>
<h5 id="2-供选择的SingleViewResolver"><a href="#2-供选择的SingleViewResolver" class="headerlink" title="2. 供选择的SingleViewResolver"></a>2. 供选择的SingleViewResolver</h5><p>&gt;</p>
<ol>
<li>The ContentNegotiatingViewResolver does not resolve views itself, but delegates to other ViewResolvers. By default, these other view resolvers are picked up automatically from the application context, though they can also be set explicitly by using the viewResolvers property. Note that in order for this view resolver to work properly, the order property needs to be set to a higher precedence than the others (the default is Ordered.HIGHEST_PRECEDENCE.)<br>&gt;<br> 说明：即<code>private List&lt;ViewResolver&gt; viewResolvers;</code>属性。需要注意的是Spring会自动加载和注册所有其他的ViewResolver到<code>ContentNegotiationViewResolover</code>的<code>viewResolvers</code>属性。但是你需要告诉Spring MVC，你希望controller返回的view都是由<code>ContentNegotiationViewResolover</code>来解析，而不是其他定义的ViewResolver。这是通过order配置项来决定。你应该给<code>ContentNegotiationViewResolover</code>配置最高的order(其实默认就是最高了)。<br>&gt;</li>
<li>Additionally, this view resolver exposes the defaultViews property, allowing you to override the views provided by the view resolvers. Note that these default views are offered as candicates, and still need have the content type requested (via file extension, parameter, or Accept header, described above). You can also set the default content type directly, which will be returned when the other mechanisms (Accept header, file extension or parameter) do not result in a match.<br>&gt;<br> 说明：即<code>private List&lt;View&gt; defaultViews;</code>和<code>private MediaType defaultContentType;</code>属性。</li>
</ol>
<p>关于<code>ContentNegotiatingViewResolver</code>，下面两篇文章都不错，值得一看：</p>
<ol>
<li><a href="http://blog.eyallupu.com/2009/07/content-negotiation-using-spring-mvcs.html" target="_blank" rel="external">Content Negotiation using Spring MVC’s ContentNegotiatingViewResolver</a>:使用了<code>viewResolvers</code>配置。</li>
<li><a href="http://blog.springsource.com/2009/03/16/adding-an-atom-view-to-an-application-using-springs-rest-support/" target="_blank" rel="external">ADDING AN ATOM VIEW TO AN APPLICATION USING SPRING’S REST SUPPORT</a>:使用了<code>ViewResolvers</code>配置。</li>
<li><a href="http://www.mkyong.com/spring-mvc/spring-3-mvc-contentnegotiatingviewresolver-example/" target="_blank" rel="external">Spring 3 MVC ContentNegotiatingViewResolver Example</a>:使用了<code>defaultViews</code>配置。</li>
</ol>
<p>注意：<code>@ResponseBody</code>是为了单个View准备的，即它只能转换成一种格式，对于<code>ContentNegotiatingViewResolver</code>，需要多个<strong>Single</strong>ViewResolver来接收。</p>
<h3 id="8-客户端调用-Accessing-RESTful-services-on-the-Client"><a href="#8-客户端调用-Accessing-RESTful-services-on-the-Client" class="headerlink" title="8. 客户端调用 Accessing RESTful services on the Client"></a>8. 客户端调用 <a href="http://static.springsource.org/spring/docs/3.0.0.M3/reference/html/ch18s03.html#rest-resttemplate" target="_blank" rel="external">Accessing RESTful services on the Client</a></h3><p>Spring MVC不仅大大的简化了服务端RESTful服务的开发和开放，还提供了一些辅助类来方便客户端调用REST服务。</p>
<p>以前Client如果要调用REST服务，一般是使用HttpClient来发送HTTP请求：</p>
<pre><code>String uri = &quot;http://example.com/hotels/1/bookings&quot;;

PostMethod post = new PostMethod(uri);
String request = // create booking request content
post.setRequestEntity(new StringRequestEntity(request));

httpClient.executeMethod(post);

if (HttpStatus.SC_CREATED == post.getStatusCode()) {
  Header location = post.getRequestHeader(&quot;Location&quot;);
  if (location != null) {
    System.out.println(&quot;Created new booking at :&quot; + location.getValue());
  }
}
</code></pre><p>太过底层，而且代码比较冗长，一般都要手动封装一下（即类似于SDK，封装了签名和HTTP发送和接受细节）。我们看一下Spring MVC是怎么解决这个问题的。</p>
<h4 id="RestTemplate"><a href="#RestTemplate" class="headerlink" title="RestTemplate"></a><a href="http://blog.springsource.org/2009/03/27/rest-in-spring-3-resttemplate/" target="_blank" rel="external">RestTemplate</a></h4><p>RestTemplate是client-site HTTP access的核心类。正如它的名称所示，<code>RestTemplate</code>非常类似于<code>JdbcTemplate</code>, <code>JmsTemplate</code>等XXXTemplate。这意味着<code>RestTemplate</code>是线程安全的并且可以通过callback来定制它的行为。</p>
<p><strong>TIPS</strong> Spring提供的Template类非常灵活和好用，种类也很丰富。当你需要做一些事情的时候可以先考虑一下有没有相应的template可以用。</p>
<p>RestTemplate默认使用<code>java.net</code>包下的基础类来创建HTTP请求。你可以实现<code>ClientHttpRequestFactory</code>接口，提供你自己的Http请求工厂类。Spring提供了<code>CommonsClientHttpRequestFactory</code>，这个工厂类使用Jakarta Commons HttpClient来创建HTTP请求。这样就可以使用HttpClient提供的认证和链接池功能了。</p>
<p><a href="http://static.springsource.org/spring/docs/3.0.x/javadoc-api/org/springframework/web/client/RestTemplate.html" target="_blank" rel="external">RestTemplate提供的方法如下</a>：</p>
<blockquote>
<p><strong>HTTP Method</strong>    <strong>RestTemplate Method</strong></p>
<ul>
<li>DELETE    delete(String url, String… urlVariables)</li>
<li>GET    getForObject(String url, Class<t> responseType, String… urlVariables)</t></li>
<li>HEAD    headForHeaders(String url, String… urlVariables)</li>
<li>OPTIONS    optionsForAllow(String url, String… urlVariables)</li>
<li>POST    postForLocation(String url, Object request, String… urlVariables)</li>
<li>PUT    put(String url, Object request, String…urlVariables)</li>
<li>ANY    exchange(String, HttpMethod, HttpEntity, Class, Object…)<pre><code>execute(String, HttpMethod, RequestCallback, ResponseExtractor, Object...)
</code></pre></li>
</ul>
</blockquote>
<p>方法名称很有规律，都是这个pattern——<code>${HTTP Method}${WhatIsReturne}</code>。例如getForObject() will perform a GET, convert the HTTP response into an object type of your choice, and returns that object. postForLocation will do a POST, converting the given object into a HTTP request, and returns the response HTTP Location header where the newly created object can be found. As you can see, these methods try to enforce REST best practices.</p>
<p>其中getForObject()、postForLocation()和put()方法接收或者返回的参数通过<code>HttpMessageConverter</code>来转换为Http Request或者Http Response。这点与前面介绍服务端RESTful的<code>@RequestBody</code>和<code>@ResponseBody</code>是一样的，Spring MVC默认会注册常用的Converter，你也可以自定义。</p>
<p>另外，每个方法的第一个参数都是一个url string，但是这个URI可以带有变量(还记得<code>@PathVariable</code>吗:)哦。参数有两种方式绑定值：</p>
<ol>
<li><p>作为字符串变量数组(String variable arguments array)</p>
<pre><code>String result = restTemplate.getForObject(&quot;http://example.com/hotels/{hotel}/bookings/{booking}&quot;, String.class, &quot;42&quot;, &quot;21&quot;);
</code></pre><p> 会转换为一个对<code>http://example.com/hotels/42/bookings/21</code>的GET请求。</p>
</li>
<li><p>或者Map对象(Map)</p>
<p>The map variant expands the template based on variable name, and is therefore more useful when using many variables, or when a single variable is used multiple times.</p>
<pre><code>Map&lt;String, String&gt; vars = new HashMap&lt;String, String&gt;();
vars.put(&quot;hotel&quot;, &quot;42&quot;);
vars.put(&quot;booking&quot;, &quot;21&quot;);
String result = restTemplate.getForObject(&quot;http://example.com/hotels/{hotel}/bookings/{booking}&quot;, String.class, vars);
会转换为一个对`http://example.com/hotels/42/rooms/42`的GET请求。
</code></pre></li>
</ol>
<p>关于RestTemplate使用的具体例子可以参考这篇文章<a href="http://blog.springsource.org/2009/03/27/rest-in-spring-3-resttemplate/" target="_blank" rel="external"><br>REST IN SPRING 3: RESTTEMPLATE</a>。写的非常好，强烈推荐！</p>
<h3 id="9-支持RESTful的URL"><a href="#9-支持RESTful的URL" class="headerlink" title="9. 支持RESTful的URL"></a>9. 支持RESTful的URL</h3><p>在开发功能模块之前，应该先把URL设计好。比查对 <strong>消息</strong> 这个资源的操作URL可以这么设计：</p>
<pre><code>http://arganzheng.me/messages/show/123456
http://arganzheng.me/messages/preview/123456
http://arganzheng.me/messages/delete/123456
http://arganzheng.me/messages/new
http://arganzheng.me/message/update
</code></pre><p>说明：可以看到我们的URL中有动作在里面，事实上纯粹的RESTful URL是把动作隐含在HTTP头中：GET、PUT、DELETE、POST。。不过这样对用户编码有要求，这个相对简单点。</p>
<p>要支持这种URL，web.xml需要这么配置：</p>
<pre><code>&lt;!-- REST servlet-mapping --&gt;
&lt;servlet-mapping&gt;
    &lt;servlet-name&gt;DispatcherServlet&lt;srvlet-name&gt;
    &lt;url-pattern&gt;/&lt;/url-pattern&gt;
&lt;srvlet-mapping&gt;
</code></pre><p>但是这样的话有个问题，就是静态文件也被mapping了，会导致找不到资源。Spring提供了一个resources配置项支持静态文件的处理<a href="http://static.springsource.org/spring/docs/3.1.x/spring-framework-reference/html/mvc.html#mvc-config-static-resources" target="_blank" rel="external">16.14.5 Configuring Serving of Resources</a>：</p>
<pre><code>&lt;!-- Forwards requests to the &quot;/&quot; resource to the &quot;welcome&quot; view --&gt;
  &lt;mvc:view-controller path=&quot;/&quot; view-name=&quot;index&quot;/&gt;

  &lt;!-- Handles HTTP GET requests for /resources/** by efficiently serving up static resources in the ${webappRoot}/resources/ directory --&gt;
  &lt;mvc:resources mapping=&quot;/resources/**&quot; location=&quot;/resources/&quot; /&gt;
  &lt;!-- 注意：配置了mvc:resources就必须配置这个选项，否则handler mapping都失效了
      @see  http://stackoverflow.com/questions/7910845/the-handler-mapping-from-the-mvcresource-override-other-mappings-which-defined
  --&gt;
  &lt;mvc:annotation-driven /&gt;
</code></pre><p>这样所有请求：<code>http://arganzheng.me/resources/**</code>会映射到webapp下的resources目录，而不是找我们的controller处理。</p>
<p>但是有个奇怪的问题，就是配置这个之后，原来动态东西就不能访问到了，提示找不到对应的handler，解决方案是增加一个<code>&lt;mvc:annotation-driven /&gt;</code>配置。具体参见<a href="http://stackoverflow.com/questions/7910845/the-handler-mapping-from-the-mvcresource-override-other-mappings-which-defined" target="_blank" rel="external">The handler mapping from the mvc:resource override other mappings which defined with annotation</a>。</p>
<p>另外，静态的html页面一般不放在resources路面下，而是直接在根目录下，比如：<a href="http://arganzheng.me/index.html或者http://arganzheng.me/404.html。所以应该在web.xml中在配置一个url-mapping规则：" target="_blank" rel="external">http://arganzheng.me/index.html或者http://arganzheng.me/404.html。所以应该在web.xml中在配置一个url-mapping规则：</a></p>
<pre><code>&lt;!-- 避免被Spring DispatcherServlet接管 --&gt;
  &lt;servlet-mapping&gt;
      &lt;servlet-name&gt;default&lt;srvlet-name&gt;
      &lt;url-pattern&gt;*.html&lt;/url-pattern&gt;
  &lt;srvlet-mapping&gt;
</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Spring MVC本身对Restful支持非常好。它的&lt;code&gt;@RequestMapping&lt;/code&gt;、&lt;code&gt;@RequestParam&lt;/code&gt;、&lt;code&gt;@PathVariable&lt;/code&gt;、&lt;code&gt;@ResponseBody&lt;/code&gt;注解很好的支持了REST。&lt;a href=&quot;http://static.springsource.org/spring/docs/3.0.0.M3/reference/html/ch18s02.html&quot;&gt;18.2 Creating RESTful services&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;1-RequestMapping&quot;&gt;&lt;a href=&quot;#1-RequestMapping&quot; class=&quot;headerlink&quot; title=&quot;1. @RequestMapping&quot;&gt;&lt;/a&gt;1. &lt;code&gt;@RequestMapping&lt;/code&gt;&lt;/h3&gt;&lt;p&gt;Spring uses the @RequestMapping method annotation to define the URI Template for the request. 类似于struts的action-mapping。 可以指定POST或者GET。&lt;/p&gt;
&lt;h3 id=&quot;2-PathVariable&quot;&gt;&lt;a href=&quot;#2-PathVariable&quot; class=&quot;headerlink&quot; title=&quot;2. @PathVariable&quot;&gt;&lt;/a&gt;2. &lt;code&gt;@PathVariable&lt;/code&gt;&lt;/h3&gt;&lt;p&gt;The @PathVariable method parameter annotation is used to indicate that a method parameter should be bound to the value of a URI template variable. 用于抽取URL中的信息作为参数。（注意，不包括请求字符串，那是&lt;code&gt;@RequestParam&lt;/code&gt;做的事情。）&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@RequestMapping(&amp;quot;/owners/{ownerId}&amp;quot;, method=RequestMethod.GET)
public String findOwner(@PathVariable String ownerId, Model model) {
        // ...
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;如果变量名与pathVariable名不一致，那么需要指定：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@RequestMapping(&amp;quot;/owners/{ownerId}&amp;quot;, method=RequestMethod.GET)
public String findOwner(@PathVariable(&amp;quot;ownerId&amp;quot;) String theOwner, Model model) {
    // implementation omitted
}
&lt;/code&gt;&lt;/pre&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Tip&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;method parameters that are decorated with the @PathVariable annotation can be of any simple type such as int, long, Date… Spring automatically converts to the appropriate type and throws a TypeMismatchException if the type is not correct.&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="spring" scheme="https://www.shenyanchao.cn/categories/spring/"/>
    
    
      <category term="spring" scheme="https://www.shenyanchao.cn/tags/spring/"/>
    
      <category term="restful" scheme="https://www.shenyanchao.cn/tags/restful/"/>
    
      <category term="mvc" scheme="https://www.shenyanchao.cn/tags/mvc/"/>
    
  </entry>
  
  <entry>
    <title>关于C3P0容错和自动重连特性的研究</title>
    <link href="https://www.shenyanchao.cn/blog/2015/03/26/c3p0-config/"/>
    <id>https://www.shenyanchao.cn/blog/2015/03/26/c3p0-config/</id>
    <published>2015-03-26T05:07:00.000Z</published>
    <updated>2018-12-20T11:58:21.621Z</updated>
    
    <content type="html"><![CDATA[<p>最近常有数据库和网络设备升级和搬迁等事情，而各个应用都是基于数据库连接池做的，大部分都是基于C3P0，数据库或网络状况的变动都会导致客户端连接池中的connection失效，如何剔除这些blocked connection就和C3P0的各个配置息息相关。</p>
<h4 id="1）C3P0容错和自动重连与以下配置参数有关："><a href="#1）C3P0容错和自动重连与以下配置参数有关：" class="headerlink" title="1）C3P0容错和自动重连与以下配置参数有关："></a>1）C3P0容错和自动重连与以下配置参数有关：</h4><p><code>breakAfterAcquireFailure</code> ：true表示pool向数据库请求连接失败后标记整个pool为block并close，就算后端数据库恢复正常也不进行重连，客户端对pool的请求都拒绝掉。false表示不会标记 pool为block，新的请求都会尝试去数据库请求connection。默认为false。因此，如果想让数据库和网络故障恢复之后，pool能继续请求正常资源必须把此项配置设为false<br><a id="more"></a><br><code>idleConnectionTestPeriod</code> ：C3P0会有一个Task检测pool内的连接是否正常，此参数就是Task运行的频率。默认值为0，表示不进行检测。</p>
<p><code>testConnectionOnCheckout</code> ：true表示在每次从pool内checkout连接的时候测试其有效性，这是个同步操作，因此应用端的每次数据库调用，都会先通过测试sql测试其有效性，如果连接无效，会关闭此连接并剔除出pool，并尝试从pool内取其他连接，默认为false，此特性要慎用，会造成至少多一倍的数据库调用。</p>
<p><code>testConnectionOnCheckin</code> ：true表示每次把连接checkin到pool里的时候测试其有效性，因为是个事后操作，所以是异步的，应用端不需要等待测试结果，但同样会造成至少多一倍的数据库调用。</p>
<p><code>acquireRetryAttempts 和acquireRetryDelay</code> ：pool请求取连接失败后重试的次数和重试的频率。请求连接会发生在pool内连接少于min值或则等待请求数&gt;池内能提供的连接数</p>
<p><code>automaticTestTable 、connectionTesterClassName 、preferredTestQuery</code> ：表示测试方式，默认是采用DatabaseMetaData.getTables()来测试connection的有效性，但可以通过以上配置来定制化测试语句，通过其名字就很好理解其含义，无需过多解释</p>
<p><code>maxIdleTime 和 maxConnectionAge</code> ：表示connection的时效性，maxIdleTime和maxConnectionAge不同之处在于， maxIdleTime表示idle状态的connection能存活的最大时间，而 maxConnectionAge表示connection能存活的绝对时间</p>
<h4 id="2）应用端getConnection抛出exception时，-C3P0会测试其connection的有效性，并根据状态处理此connection，但应用端不会重调。"><a href="#2）应用端getConnection抛出exception时，-C3P0会测试其connection的有效性，并根据状态处理此connection，但应用端不会重调。" class="headerlink" title="2）应用端getConnection抛出exception时， C3P0会测试其connection的有效性，并根据状态处理此connection，但应用端不会重调。"></a>2）应用端getConnection抛出exception时， C3P0会测试其connection的有效性，并根据状态处理此connection，但应用端不会重调。</h4><h4 id="3）无论是网络问题还是远端数据库服务器，就算恢复正常后，客户端pool内其已存在的connection都会失效，要保证应用端调用无误，必须在checkout到应用端之前刷新这些无效connection"><a href="#3）无论是网络问题还是远端数据库服务器，就算恢复正常后，客户端pool内其已存在的connection都会失效，要保证应用端调用无误，必须在checkout到应用端之前刷新这些无效connection" class="headerlink" title="3）无论是网络问题还是远端数据库服务器，就算恢复正常后，客户端pool内其已存在的connection都会失效，要保证应用端调用无误，必须在checkout到应用端之前刷新这些无效connection"></a>3）无论是网络问题还是远端数据库服务器，就算恢复正常后，客户端pool内其已存在的connection都会失效，要保证应用端调用无误，必须在checkout到应用端之前刷新这些无效connection</h4><h4 id="4）breakAfterAcquireFailure-false是关键。"><a href="#4）breakAfterAcquireFailure-false是关键。" class="headerlink" title="4）breakAfterAcquireFailure=false是关键。"></a>4）breakAfterAcquireFailure=false是关键。</h4><p>如果 breakAfterAcquireFailure=true ，一旦pool向数据库请求连接失败，就会标记pool block并关闭pool，这样无论数据库是否恢复正常，应用端都无法从pool拿到连接</p>
<h4 id="5）要想保证网络和数据库瞬间的失效100-不会造成应用端getConnection失败必须开启testConnectionOnCheckout。但此特性的代价巨大，建议在应用端做容错。"><a href="#5）要想保证网络和数据库瞬间的失效100-不会造成应用端getConnection失败必须开启testConnectionOnCheckout。但此特性的代价巨大，建议在应用端做容错。" class="headerlink" title="5）要想保证网络和数据库瞬间的失效100%不会造成应用端getConnection失败必须开启testConnectionOnCheckout。但此特性的代价巨大，建议在应用端做容错。"></a>5）要想保证网络和数据库瞬间的失效100%不会造成应用端getConnection失败必须开启testConnectionOnCheckout。但此特性的代价巨大，建议在应用端做容错。</h4><h4 id="6）推荐使用-idleConnectionTestPeriod。可以根据应用调用频率权衡一个检查pool的频率，这样可以在保证性能损耗不大情况下，尽可能的保证pool内connection的有效性"><a href="#6）推荐使用-idleConnectionTestPeriod。可以根据应用调用频率权衡一个检查pool的频率，这样可以在保证性能损耗不大情况下，尽可能的保证pool内connection的有效性" class="headerlink" title="6）推荐使用 idleConnectionTestPeriod。可以根据应用调用频率权衡一个检查pool的频率，这样可以在保证性能损耗不大情况下，尽可能的保证pool内connection的有效性"></a>6）推荐使用 idleConnectionTestPeriod。可以根据应用调用频率权衡一个检查pool的频率，这样可以在保证性能损耗不大情况下，尽可能的保证pool内connection的有效性</h4><h4 id="7）若嫌DatabaseMetaData-getTables-性能不好，可以尝试通过配置automaticTestTable、connectionTesterClassName、preferredTestQuery来找到一个性能最好的测试语句，只要能验证connection有效就行"><a href="#7）若嫌DatabaseMetaData-getTables-性能不好，可以尝试通过配置automaticTestTable、connectionTesterClassName、preferredTestQuery来找到一个性能最好的测试语句，只要能验证connection有效就行" class="headerlink" title="7）若嫌DatabaseMetaData.getTables()性能不好，可以尝试通过配置automaticTestTable、connectionTesterClassName、preferredTestQuery来找到一个性能最好的测试语句，只要能验证connection有效就行"></a>7）若嫌DatabaseMetaData.getTables()性能不好，可以尝试通过配置automaticTestTable、connectionTesterClassName、preferredTestQuery来找到一个性能最好的测试语句，只要能验证connection有效就行</h4><p>综上所述，要想保证性能的前提下，本人推荐的配置组合如下：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">break</span>AfterAcquireFailure: <span class="literal">false</span></div><div class="line"><span class="built_in">test</span>ConnectionOnCheckout: <span class="literal">false</span></div><div class="line"><span class="built_in">test</span>ConnectionOnCheckin: <span class="literal">false</span></div><div class="line">idleConnectionTestPeriod: 60</div><div class="line">acquireRetryAttempts: 10</div><div class="line">acquireRetryDelay: 1000</div></pre></td></tr></table></figure>
<p>但需要注意的是以上的配置不能保证100%应用端getConnection无误，如果应用端不能发生getConnection错误，需要自行考虑容错和重试机制。</p>
<p>在以上配置下，当网络或数据库发生瞬间变动的情况下，会有如下事情发生：</p>
<ul>
<li><p>1）自动测试idleConnection的 task轮训检测pool，对每个connction通过DatabaseMetaData.getTables()来测试有效性，并剔除无效连接。</p>
</li>
<li><p>2）根据请求情况和配置，pool向数据库请求新连接并加入池内</p>
</li>
<li><p>3）应用端getConnection-&gt;是否发生异常-&gt;如果发生异常，检验其有效性，并剔除出pool-&gt;如果没有发生异常（自动检查task之前已检测），调用成功</p>
</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近常有数据库和网络设备升级和搬迁等事情，而各个应用都是基于数据库连接池做的，大部分都是基于C3P0，数据库或网络状况的变动都会导致客户端连接池中的connection失效，如何剔除这些blocked connection就和C3P0的各个配置息息相关。&lt;/p&gt;
&lt;h4 id=&quot;1）C3P0容错和自动重连与以下配置参数有关：&quot;&gt;&lt;a href=&quot;#1）C3P0容错和自动重连与以下配置参数有关：&quot; class=&quot;headerlink&quot; title=&quot;1）C3P0容错和自动重连与以下配置参数有关：&quot;&gt;&lt;/a&gt;1）C3P0容错和自动重连与以下配置参数有关：&lt;/h4&gt;&lt;p&gt;&lt;code&gt;breakAfterAcquireFailure&lt;/code&gt; ：true表示pool向数据库请求连接失败后标记整个pool为block并close，就算后端数据库恢复正常也不进行重连，客户端对pool的请求都拒绝掉。false表示不会标记 pool为block，新的请求都会尝试去数据库请求connection。默认为false。因此，如果想让数据库和网络故障恢复之后，pool能继续请求正常资源必须把此项配置设为false&lt;br&gt;
    
    </summary>
    
      <category term="c3p0" scheme="https://www.shenyanchao.cn/categories/c3p0/"/>
    
    
      <category term="c3p0" scheme="https://www.shenyanchao.cn/tags/c3p0/"/>
    
      <category term="dhcp" scheme="https://www.shenyanchao.cn/tags/dhcp/"/>
    
  </entry>
  
  <entry>
    <title>如何在Solr中更好的处理同义词</title>
    <link href="https://www.shenyanchao.cn/blog/2014/11/25/better-synonym-handling-in-solr/"/>
    <id>https://www.shenyanchao.cn/blog/2014/11/25/better-synonym-handling-in-solr/</id>
    <published>2014-11-25T05:53:00.000Z</published>
    <updated>2018-12-24T06:36:28.255Z</updated>
    
    <content type="html"><![CDATA[<p>当使用Solr来构建搜索引擎的时候，你可能经常会遇到这样的场景：你有一个同义词列表，并且你想用户查询也能够命中到同义词。听起来很简单不是吗？为什么搜索“dog”的时候，不能命中包含“hound(猎犬)”或者“pooch(狗)”的文档呢？甚至包含“Rover(流浪者)”和“canis familiaris(犬)”?</p>
<p><img src="/images/blog/2014/File-Licking_the_staffy_pup.JPG" alt="solr plugin 小狗"></p>
<p>叫Rover或者其他名字，可能只是为了让小狗听起来很可爱。</p>
<p>事实证明，Solr的同义词扩展没有你想象的那么简单。但是我们有很多好的方法来搬石头砸自己的脚。</p>
<a id="more"></a>
<h3 id="The-SynonymFilterFactory"><a href="#The-SynonymFilterFactory" class="headerlink" title="The SynonymFilterFactory"></a>The SynonymFilterFactory</h3><p>Solr提供了一个听起来很酷的SynonymFilterFactory,它可以接收一个逗号分割的同义词文本。你甚至可以选择同义词是相互扩展还是特定方向的替换。</p>
<p>举例来说，你可以让“dog”，“hound”和“pooch”都扩展为“dog|hound|pooch”，或者你可以指定“dog”映射到“hound”，反过来却不可以，或者你可以把所有的词都转化为”dog“,Solr处理这部分是非常灵活的并且做的很棒。</p>
<p>当你考虑是把SynonymFilterFactory放在查询分析器还是索引分析器时，这个问题就变得很复杂啦。</p>
<h3 id="Index-time-vs-query-time"><a href="#Index-time-vs-query-time" class="headerlink" title="Index-time vs. query-time"></a>Index-time vs. query-time</h3><p>下图总结了查询时（query-time）和索引时（index-time）同义词扩展的基本差异。当然我们是为了解决solr中使用的问题，但是这2种方法适用于任何信息检索系统。</p>
<p><img src="/images/blog/2014/index_vs_query_expansion2.png" alt="Index-time vs. query-time expansion."></p>
<p>你的直观选择可能是将SynonymFilterFactory放在查询分析器内。理论上，这样做有以下优点：</p>
<ul>
<li>索引大小不会变化</li>
<li>同义词可以随时更换，不用更新索引</li>
<li>同义词实时生效，不需要重新索引</li>
</ul>
<p>然而，按<a href="http://wiki.apache.org/solr/AnalyzersTokenizersTokenFilters#solr.SynonymFilterFactory" target="_blank" rel="external">Solr Docs</a>所说，这是一个Very Bad Thing to Do(™)，显然的你应该把SynonymFilterFactory放在索引分析器里，而不是简单的依靠你的直觉来判断。文档里说，查询时的同义词扩展有以下的缺点：</p>
<ul>
<li>多字同义词并不能识别为短语查询</li>
<li>罕见同义词的IDF会被加权，导致不可想象的搜索结果</li>
<li>多字同义词不会匹配查询</li>
</ul>
<p>这有点复杂，因此也值得我们一一解决这些问题。</p>
<h3 id="多字同义词并不能识别为短语查询"><a href="#多字同义词并不能识别为短语查询" class="headerlink" title="多字同义词并不能识别为短语查询"></a>多字同义词并不能识别为短语查询</h3><p>在Health On the Net,我们的搜索引擎使用MeSH来做查询扩展，MeSH是一个为健康领域提供优质同义词的医疗本体。例如”breast cancer“的同义词：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">breast neoplasm</div><div class="line">breast neoplasms</div><div class="line">breast tumor</div><div class="line">breast tumors</div><div class="line">cancer of breast</div><div class="line">cancer of the breast</div></pre></td></tr></table></figure>
<p>因此在正常情况下，如果SynonymFilterFactory配置了<code>expand=&quot;true&quot;</code>,查询”breast cancer“就变成了：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">+((breast breast breast breast breast cancer cancer) (cancer neoplasm neoplasms tumor tumors) breast breast)</div></pre></td></tr></table></figure>
<p>这将命中包含”breast neoplasms“,”cancer of the breast”等等的文档。</p>
<p>然而，这也意味着，如果你正在做一个短语查询（比如”breast cancer“）,如果想生效，你的文档必须字面上匹配类似”breast cancer breast breast“这样的字符。</p>
<p>啊？这里到底发生了什么？事实证明SynonymFilterFactory并没有按你所想来扩展多字同义词。直觉上，可能认为它表现为一个有限自动机，Solr构建出的结果可能类似这样(忽略复数)：</p>
<p><img src="/images/blog/2014/graph11.png" alt="Lucene FSA"></p>
<p>但是，它真正构建的是下面这样的：</p>
<p><img src="/images/blog/2014/graph22.png" alt="Lucene FSA"></p>
<p>简直是一碗意大利面。</p>
<p>你可怜的文档必须依序包含所有的4个部分。让人惊讶。</p>
<p>同样，DisMax和EDisMax查询分析器的mm(最小匹配)参数，并不能像你所想的那样工作。在上面的例子中，设置<code>mm=100%</code>将需要所有4个部分都匹配。</p>
<pre><code>+((breast breast breast breast breast cancer cancer) (cancer neoplasm neoplasms tumor tumors) breast breast)~4
</code></pre><h3 id="罕见同义词的IDF会被加权"><a href="#罕见同义词的IDF会被加权" class="headerlink" title="罕见同义词的IDF会被加权"></a>罕见同义词的IDF会被加权</h3><p>即使你没有多字同义词，Solr Docs也提到了第二个避免查询时扩展的原因：不正常的IDF加权。考虑我们的”dog”,”hound”,”pooch”例子，查询3个里面的任意一个都会被扩展为：</p>
<pre><code>+(dog hound pooch)
</code></pre><p>由于“hound”和”pooch“是比较少见的字，因此无论查询什么，包含这些字的文档会在查询结果中排名特别高。这对可怜的用户来说，简直是一个浩劫，为什么搜索”dog“的时候，会有那么多包含”hound“和”pooch“的怪异文档排名那么高。</p>
<p>索引时扩展通过给”dog”,”hound”,”pooch”赋予相同的IDF值，而不管原始文档是什么。</p>
<h3 id="多字同义词不会匹配查询"><a href="#多字同义词不会匹配查询" class="headerlink" title="多字同义词不会匹配查询"></a>多字同义词不会匹配查询</h3><p>最后，也是最严重的是，如果你对用户查询做任意类型的分词，SynonymFilterFactory并不会匹配多字同义词。这是因为分词器会将用户输入分开，然后才交给SynonymFilterFactory来转换。</p>
<p>比如，查询“cancer of the breast”会被StandardTokenizationFactory分词为[“cancer”,”of”,”the”,”breast]，并且只有独立的词才会传给SynonymFilterFactory。因此，在这种情况下，如果分词后的单个词，比如‘cancer“和”breast“都没有同义词的情况下，同义词扩展就压根不会发生。</p>
<h3 id="其他问题"><a href="#其他问题" class="headerlink" title="其他问题"></a>其他问题</h3><p>最初，我按照Solr的建议，使用索引时扩展，但是我发现索引时同义词扩展有它自己的问题。显然，除了有索引爆炸的问题，我还发现一个关于高亮的有趣的bug。</p>
<p>当我搜索”breast cancer“的时候，我发现高亮器会很神奇的把”breast cancer X Y“给高亮了，其中”X“和”Y“是文档中任何跟在”breast cancer“后面的2个字符。例如，它可能会高亮”breast cancer frauds are“或者”breast cancer is to“。</p>
<p><img src="/images/blog/2014/breast_cancer_highlighting2.png" alt="solr highlight bug"></p>
<p>看完这个<a href="https://issues.apache.org/jira/browse/SOLR-3390" target="_blank" rel="external">solr bug</a>,这和前面提到的Solr多字同义词扩展是一个原因。</p>
<p>使用查询时扩展，你的查询被转换为像意大利面般的图已经足够的怪异了。但是在索引时扩展，假如你的文档包含”breast cancer treatment options“,会变成什么样子呢。</p>
<p><img src="/images/blog/2014/graph33.png" alt=""></p>
<p>这就是Lucene认为的你文档的样子。同义词扩展给你带来了比你要求更多的东西，类似”Dada-esque“的结果！”Breast tumor the options“确实是这样的。</p>
<p>从根本上来说，Lucene认为一个查询”cancer of the breast“(4个Token)和你原始文档里的”breast cancer treatment options“(4个Token)是一样的。这是因为Tokens只是一个叠加另一个上面而已，丢失任何信息的部分都可以由它后面的部门来替代。</p>
<p>查询时扩展不会引起这个问题，因为Solr只扩展了查询，而不是文档。因此Lucene仍然认为查询的”cancer of the breast“只会匹配文档里的”breast cancer“。</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>所有这些古怪的问题，让我得出这样的结论：Solr内建的同义词扩展机制是及其糟糕的。我必须找出一个更好的方法来让Solr按我想的来运行。</p>
<p>总之，无论是索引时扩展还是查询时扩展使用标准的SynonymFilterFactory都是不可行的，因为它们都有各自不同的问题。</p>
<p><strong>Index-time</strong></p>
<ul>
<li>索引爆炸</li>
<li>同义词不能立即生效，所有文档需重新索引</li>
<li>同义词不能立即删除</li>
<li>多字同义词导致多余的文字被高亮</li>
</ul>
<p><strong>Query-time</strong></p>
<ul>
<li>短语查询不支持</li>
<li>罕见同义词被认为加权了</li>
<li>多字同义词不匹配查询</li>
</ul>
<p>我开始假设理想的同义词扩展系统应该是基于查询时的，由于基于索引的扩展有那么多固有的缺点。同时，我也意识到在Solr实现同义词扩展之前，有一个更加根本的问题需要解决。</p>
<p>回到”dog“/“hound”/“pooch”的例子，对待3个词对等的是不明智的。在特定的查询中，”dog“可能并不与”hound“和”pooch“是一样的，比如 (e.g. “The Hound of the Baskervilles,” “The Itchy &amp; Scratchy &amp; Poochy Show”). 一视同仁感觉是错误的。</p>
<p>同样的，即使使用官方推荐的索引时扩展，IDF权重也被抛弃了。每个包含”dog“的文章现在也都包含”pooch“，这意味着我们将永久的丢失关于”pooch“的真实IDF值。</p>
<p>在一个理想的系统里，搜索”dog“，返回的结果应该包含所有存在”hound“和”pooch“的文档，但是应该将所有包含真实查询的文档排的更靠前面，包含”dog“的应该得到更高的分。同样的，搜索“hound”应该把包含“hound”的排的更靠前面，搜索“pooch”就应该将包含“pooch”的更靠前。所有的3个搜索都返回相同的文档集，但是结果排序不一样。</p>
<h3 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h3><p>我的解决方法是，把同义词扩展从分析器的Tokenizer链移动到QueryParser。不是把查询变成如上面的纵横交错的图，而是把它分为2个部分：主查询和同义词查询。然后我为每个部分独立配置权重，指定每个部分内部为“should occur”。最后将二者使用“must occur”的布尔查询包装起来。</p>
<p>因此，搜索“dog”为被解析为类似这样：</p>
<pre><code>+((dog)^1.2 (hound pooch)^1.1)
</code></pre><p>1.2和1.1是独立的权重，可以配置。文档必须包含“dog”,”hound”或者“pooch”，但是“dog”更优先显示。</p>
<p>这样来处理同义词，带来了另一个有趣的副作用：它消除了短语查询不支持的问题。如果是“breast cancer”(带引号)，将会被解析为这样：</p>
<pre><code>+((&quot;breast cancer&quot;)^1.2 ((&quot;breast neoplasm&quot;) (&quot;breast tumor&quot;) (&quot;cancer ? breast&quot;) (&quot;cancer ? ? breast&quot;))^1.1)
</code></pre><p>(问号?的出现是由于停用词“of”和“the”)</p>
<p>这意味着查询带引号的“breast cancer”会匹配所有包含“breast neoplasm,” “breast tumor,” “cancer of the breast,” and “cancer of breast.“字符的文档。</p>
<p>我比原始的SynonymFilterFactory更进一步，针对一个特定的查询构建了所有可能的同义词组合查询。比如查询”dog bite“,同义词文件是：</p>
<pre><code>dog,hound,pooch
bite,nibble
</code></pre><p>… then the query will be expanded into:</p>
<p>查询将会被扩展为：</p>
<pre><code>dog bite
hound bite
pooch bite
dog nibble
hound nibble
pooch nibble
</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;当使用Solr来构建搜索引擎的时候，你可能经常会遇到这样的场景：你有一个同义词列表，并且你想用户查询也能够命中到同义词。听起来很简单不是吗？为什么搜索“dog”的时候，不能命中包含“hound(猎犬)”或者“pooch(狗)”的文档呢？甚至包含“Rover(流浪者)”和“canis familiaris(犬)”?&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/blog/2014/File-Licking_the_staffy_pup.JPG&quot; alt=&quot;solr plugin 小狗&quot;&gt;&lt;/p&gt;
&lt;p&gt;叫Rover或者其他名字，可能只是为了让小狗听起来很可爱。&lt;/p&gt;
&lt;p&gt;事实证明，Solr的同义词扩展没有你想象的那么简单。但是我们有很多好的方法来搬石头砸自己的脚。&lt;/p&gt;
    
    </summary>
    
      <category term="solr" scheme="https://www.shenyanchao.cn/categories/solr/"/>
    
    
      <category term="同义词" scheme="https://www.shenyanchao.cn/tags/%E5%90%8C%E4%B9%89%E8%AF%8D/"/>
    
      <category term="solr" scheme="https://www.shenyanchao.cn/tags/solr/"/>
    
      <category term="lucene" scheme="https://www.shenyanchao.cn/tags/lucene/"/>
    
  </entry>
  
  <entry>
    <title>使用mahout对Sogou语料库进行分类</title>
    <link href="https://www.shenyanchao.cn/blog/2014/11/14/use-mahout-to-classify-sogou-corpus/"/>
    <id>https://www.shenyanchao.cn/blog/2014/11/14/use-mahout-to-classify-sogou-corpus/</id>
    <published>2014-11-14T05:26:00.000Z</published>
    <updated>2018-12-24T06:52:54.060Z</updated>
    
    <content type="html"><![CDATA[<h3 id="软件版本"><a href="#软件版本" class="headerlink" title="软件版本"></a>软件版本</h3><ul>
<li>Ubuntu Linux</li>
<li><a href="http://mirror.bit.edu.cn/apache/mahout/0.9/mahout-distribution-0.9.tar.gz" target="_blank" rel="external">mahout-0.9</a>,本文写作的时候的最新版本</li>
<li><a href="http://download.labs.sogou.com/dl/sogoulabdown/SogouC.reduced.20061102.tar.gz" target="_blank" rel="external">Sogou语料库</a>精简版</li>
<li><a href="https://github.com/blueshen/ik-analyzer" target="_blank" rel="external">ik-analyzer</a>, 这个版本是专门为了在mahout中进行分词而单独做的版本，源码从官方拿来。只更改了停用词，以及适配lucene4.6.1版本。maven化更方便使用。</li>
</ul>
<h3 id="Sogou语料库处理"><a href="#Sogou语料库处理" class="headerlink" title="Sogou语料库处理"></a>Sogou语料库处理</h3><p>下载后的预料库，文档都是GB2312编码的。虽然mahout支持不同的编码方式，但是为了更方便的放到Hadoop里跑，还是建议先转化为标准的UTF-8.<br>语料库解压后，是sogou目录。我们执行以下代码进行转化，转换后的在utf/sogou目录下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">find sogou -type d -exec mkdir -p utf/&#123;&#125; \;</div><div class="line">find sogou -type f -exec iconv -f GB2312 -t UTF-8 &#123;&#125; -o utf/&#123;&#125; \;</div></pre></td></tr></table></figure>
<h3 id="使用mahout生成sequence-file"><a href="#使用mahout生成sequence-file" class="headerlink" title="使用mahout生成sequence file"></a>使用mahout生成sequence file</h3><p>进入utf/sogou目录，执行：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mahout seqdirectory -i sogou -o sogou-seq -c UTF-8 -ow</div></pre></td></tr></table></figure>
<p>生成的sequence file存放在sogou-seq目录内。<br>可以通过seqdumper命令查看：<br><a id="more"></a><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mahout seqdumper -i sogou-seq/part-m-00000 | more</div></pre></td></tr></table></figure></p>
<p><img src="/images/blog/2014/sogou-seqfile.png" alt="搜狗seqfile"></p>
<p>如果是在hadoop上跑，可以这样看。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">hadoop fs -text sogou-seq/part-m-00000 | more</div></pre></td></tr></table></figure>
<h3 id="使用seq2sparse生成Vectors"><a href="#使用seq2sparse生成Vectors" class="headerlink" title="使用seq2sparse生成Vectors"></a>使用seq2sparse生成Vectors</h3><p>执行命令：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mahout seq2sparse -i sogou-seq  -o sogou-vectors -lnorm -nv -wt tfidf -a org.wltea.analyzer.lucene.IKAnalyzer -ow</div></pre></td></tr></table></figure>
<p>查看生成的vector<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mahout vectordump -i sogou-vectors/tfidf-vectors/part-r-00000 | more</div></pre></td></tr></table></figure></p>
<p><img src="/images/blog/2014/sogou-vector.png" alt="搜狗 vector"> </p>
<p>需要注意的是<code>org.wltea.analyzer.lucene.IKAnalyzer</code>，是上面提到的ik-analyzer里的。需要将ik-analyzer打包，然后将打出的包，放入$MAHOUT_HOME/lib内。默认是英文的，使用的是<code>org.apache.lucene.analysis.standard.StandardAnalyzer</code>，空格分割明显不适用中文。</p>
<h3 id="切分训练集和测试集"><a href="#切分训练集和测试集" class="headerlink" title="切分训练集和测试集"></a>切分训练集和测试集</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mahout split -i sogou-vectors/tfidf-vectors/ --trainingOutput sogou-train-vectors --testOutput sogou-test-vectors --randomSelectionPct 40 --overwrite --sequenceFiles -xm sequential</div></pre></td></tr></table></figure>
<h3 id="使用Native-Bayes训练model"><a href="#使用Native-Bayes训练model" class="headerlink" title="使用Native Bayes训练model"></a>使用Native Bayes训练model</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mahout trainnb -i sogou-train-vectors -el -o sogou-model -li sogou-labelindex -ow -c</div></pre></td></tr></table></figure>
<h3 id="使用测试集来查看效果"><a href="#使用测试集来查看效果" class="headerlink" title="使用测试集来查看效果"></a>使用测试集来查看效果</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mahout testnb -i sogou-test-vectors -m sogou-model -l sogou-labelindex -ow -o sogou-testing -c</div></pre></td></tr></table></figure>
<p><img src="/images/blog/2014/sogou-result.png" alt="mahout"></p>
<p>可以看出87%的正确率还是不错的。</p>
<hr>
<p>参考文档：</p>
<p><a href="http://mahout.apache.org/users/classification/twenty-newsgroups.html" target="_blank" rel="external">http://mahout.apache.org/users/classification/twenty-newsgroups.html</a><br><a href="http://www.sogou.com/labs/dl/c.html" target="_blank" rel="external">http://www.sogou.com/labs/dl/c.html</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;软件版本&quot;&gt;&lt;a href=&quot;#软件版本&quot; class=&quot;headerlink&quot; title=&quot;软件版本&quot;&gt;&lt;/a&gt;软件版本&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;Ubuntu Linux&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://mirror.bit.edu.cn/apache/mahout/0.9/mahout-distribution-0.9.tar.gz&quot;&gt;mahout-0.9&lt;/a&gt;,本文写作的时候的最新版本&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://download.labs.sogou.com/dl/sogoulabdown/SogouC.reduced.20061102.tar.gz&quot;&gt;Sogou语料库&lt;/a&gt;精简版&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/blueshen/ik-analyzer&quot;&gt;ik-analyzer&lt;/a&gt;, 这个版本是专门为了在mahout中进行分词而单独做的版本，源码从官方拿来。只更改了停用词，以及适配lucene4.6.1版本。maven化更方便使用。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;Sogou语料库处理&quot;&gt;&lt;a href=&quot;#Sogou语料库处理&quot; class=&quot;headerlink&quot; title=&quot;Sogou语料库处理&quot;&gt;&lt;/a&gt;Sogou语料库处理&lt;/h3&gt;&lt;p&gt;下载后的预料库，文档都是GB2312编码的。虽然mahout支持不同的编码方式，但是为了更方便的放到Hadoop里跑，还是建议先转化为标准的UTF-8.&lt;br&gt;语料库解压后，是sogou目录。我们执行以下代码进行转化，转换后的在utf/sogou目录下：&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;find sogou -type d -exec mkdir -p utf/&amp;#123;&amp;#125; \;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;find sogou -type f -exec iconv -f GB2312 -t UTF-8 &amp;#123;&amp;#125; -o utf/&amp;#123;&amp;#125; \;&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h3 id=&quot;使用mahout生成sequence-file&quot;&gt;&lt;a href=&quot;#使用mahout生成sequence-file&quot; class=&quot;headerlink&quot; title=&quot;使用mahout生成sequence file&quot;&gt;&lt;/a&gt;使用mahout生成sequence file&lt;/h3&gt;&lt;p&gt;进入utf/sogou目录，执行：&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;mahout seqdirectory -i sogou -o sogou-seq -c UTF-8 -ow&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;生成的sequence file存放在sogou-seq目录内。&lt;br&gt;可以通过seqdumper命令查看：&lt;br&gt;
    
    </summary>
    
      <category term="mahout" scheme="https://www.shenyanchao.cn/categories/mahout/"/>
    
    
      <category term="mahout" scheme="https://www.shenyanchao.cn/tags/mahout/"/>
    
      <category term="sogou" scheme="https://www.shenyanchao.cn/tags/sogou/"/>
    
      <category term="ik-analyzer" scheme="https://www.shenyanchao.cn/tags/ik-analyzer/"/>
    
      <category term="ubuntu" scheme="https://www.shenyanchao.cn/tags/ubuntu/"/>
    
  </entry>
  
  <entry>
    <title>Linux中文件编码转换</title>
    <link href="https://www.shenyanchao.cn/blog/2014/11/13/encode-convert-in-linux/"/>
    <id>https://www.shenyanchao.cn/blog/2014/11/13/encode-convert-in-linux/</id>
    <published>2014-11-13T08:20:00.000Z</published>
    <updated>2018-12-24T06:39:00.719Z</updated>
    
    <content type="html"><![CDATA[<p>　在工作中，经常会遇到使用操作系统不一样的环境，从而导致在不同环境下的文件编辑的编码是不一样的，Windows默认是GBK编码格式，Linux默认是UTF-8的格式，这样就会出现把GBK编码的文件拷贝到Linux下出现乱码情况，很是让人头疼，下面给大家介绍下GBK-&gt;UTF-8文件编码批量转换。</p>
<p>Linux命令-enca 查看文件的编码</p>
<p>Enca语法</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">Usage:  enca [-L LANGUAGE] [OPTION]... [FILE]...</div><div class="line">        enconv [-L LANGUAGE] [OPTION]... [FILE]...</div><div class="line">        Detect encoding of text files and convert them if required.</div></pre></td></tr></table></figure>
<p>Enca用法</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">$ enca -L zh_CN file 检查文件的编码</div><div class="line">$ enca -L zh_CN -x UTF-8 file 将文件编码转换为&quot;UTF-8&quot;编码</div><div class="line">$ enca -L zh_CN -x UTF-8 file1 file2 如果不想覆盖原文件可以这样</div></pre></td></tr></table></figure>
<p>除了有检查文件编码的功能以外，”enca”还有一个好处就是如果文件本来就是你要转换的那种编码，它不会报错，还是会print出结果来， 而”iconv”则会报错。这对于脚本编写是比较方便的事情。<br><a id="more"></a><br>转换单个文件的编码</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ enca -L none -x utf-8  index.html</div></pre></td></tr></table></figure>
<p>转换多个文件的编码</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ enca -x utf-8 *</div></pre></td></tr></table></figure>
<p>Linux文件名编码批量转换–convmv</p>
<p>Convmv语法</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ convmv -f 源编码 -t 新编码 [选项] 文件名</div></pre></td></tr></table></figure>
<p>Convmv 常用参数</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">-r 递归处理子文件夹</div><div class="line">–notest 真正进行操作，请注意在默认情况下是不对文件进行真实操作的，而只是试验。</div><div class="line">–list 显示所有支持的编码</div><div class="line">–unescap 可以做一下转义，比如把%20变成空格</div></pre></td></tr></table></figure>
<p>示例</p>
<p>转换一个文件由GBK转换成UTF-8</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">convmv -f GBK -t UTF-8 --notest utf8 filename</div></pre></td></tr></table></figure>
<p>GBK-&gt;UTF-8文件编码批量转换脚本</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ find default -type f -exec convmv -f GBK -t UTF-8 --notest utf8 &#123;&#125; -o utf/&#123;&#125; \;</div></pre></td></tr></table></figure>
<p>使用iconv 转换</p>
<p>Iconv语法</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">iconv -f encoding -t encoding inputfile</div></pre></td></tr></table></figure>
<p>示例</p>
<p>单个文件转换</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ iconv -f GBK -t UTF-8 file1 -o file2</div></pre></td></tr></table></figure>
<p>批量转换</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ find default -type d -exec mkdir -p utf/&#123;&#125; \;</div><div class="line">$ find default -type f -exec iconv -f GBK -t UTF-8 &#123;&#125; -o utf/&#123;&#125; \;</div></pre></td></tr></table></figure>
<p>这两行命令将default目录下的文件由GBK编码转换为UTF-8编码，目录结构不变，转码后的文件保存在utf/default目录下。</p>
<hr>
<p>原文:<a href="http://blog.csdn.net/a280606790/article/details/8504133" target="_blank" rel="external">http://blog.csdn.net/a280606790/article/details/8504133</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;　在工作中，经常会遇到使用操作系统不一样的环境，从而导致在不同环境下的文件编辑的编码是不一样的，Windows默认是GBK编码格式，Linux默认是UTF-8的格式，这样就会出现把GBK编码的文件拷贝到Linux下出现乱码情况，很是让人头疼，下面给大家介绍下GBK-&amp;gt;UTF-8文件编码批量转换。&lt;/p&gt;
&lt;p&gt;Linux命令-enca 查看文件的编码&lt;/p&gt;
&lt;p&gt;Enca语法&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;Usage:  enca [-L LANGUAGE] [OPTION]... [FILE]...&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        enconv [-L LANGUAGE] [OPTION]... [FILE]...&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        Detect encoding of text files and convert them if required.&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;Enca用法&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;$ enca -L zh_CN file 检查文件的编码&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;$ enca -L zh_CN -x UTF-8 file 将文件编码转换为&amp;quot;UTF-8&amp;quot;编码&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;$ enca -L zh_CN -x UTF-8 file1 file2 如果不想覆盖原文件可以这样&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;除了有检查文件编码的功能以外，”enca”还有一个好处就是如果文件本来就是你要转换的那种编码，它不会报错，还是会print出结果来， 而”iconv”则会报错。这对于脚本编写是比较方便的事情。&lt;br&gt;
    
    </summary>
    
      <category term="linux" scheme="https://www.shenyanchao.cn/categories/linux/"/>
    
    
      <category term="enca" scheme="https://www.shenyanchao.cn/tags/enca/"/>
    
      <category term="iconv" scheme="https://www.shenyanchao.cn/tags/iconv/"/>
    
      <category term="convmv" scheme="https://www.shenyanchao.cn/tags/convmv/"/>
    
      <category term="编码" scheme="https://www.shenyanchao.cn/tags/%E7%BC%96%E7%A0%81/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop1.2.1安装部署</title>
    <link href="https://www.shenyanchao.cn/blog/2014/11/13/install-hadoop/"/>
    <id>https://www.shenyanchao.cn/blog/2014/11/13/install-hadoop/</id>
    <published>2014-11-13T05:24:00.000Z</published>
    <updated>2018-12-24T06:45:51.644Z</updated>
    
    <content type="html"><![CDATA[<h3 id="安装需求"><a href="#安装需求" class="headerlink" title="安装需求"></a>安装需求</h3><ul>
<li>Java 1.6</li>
<li>ssh,sshd正常安装</li>
</ul>
<p>确保可以ssh到localhost，并且不需要密码</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">ssh localhost</div></pre></td></tr></table></figure>
<p> 如果报错，connect to host localhost port 22:Connection refused。说明ssh-server未安装或者未启动。<br> 运行：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">ps -ef | grep sshd</div></pre></td></tr></table></figure>
<p>查看sshd进程是否存在，如果不存在，说明没有安装。那么进行安装。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo apt-get install openssh-server</div></pre></td></tr></table></figure>
<p>然后再执行<code>ssh localhost</code>,如果不能无密码登陆，需要做一下操作：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">ssh-keygen -t dsa -P &apos;&apos; -f ~/.ssh/id_dsa</div><div class="line">cat ~/.ssh/id_dsa.pub &gt;&gt; ~/.ssh/authorized_keys</div></pre></td></tr></table></figure>
<a id="more"></a>
<h3 id="相关软件"><a href="#相关软件" class="headerlink" title="相关软件"></a>相关软件</h3><p>Ubuntu Linux为例：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">sudo apt-get install ssh</div><div class="line">sudo apt-get install rsync</div></pre></td></tr></table></figure>
<h3 id="Hadoop下载"><a href="#Hadoop下载" class="headerlink" title="Hadoop下载"></a>Hadoop下载</h3><p>从<a href="http://hadoop.apache.org/releases.html" target="_blank" rel="external">Hadoop官网</a>下载一个稳定版，这里就是1.2.1版本啦。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">wget http://mirror.bit.edu.cn/apache/hadoop/common/hadoop-1.2.1/hadoop-1.2.1.tar.gz</div></pre></td></tr></table></figure>
<h3 id="启动Hadoop"><a href="#启动Hadoop" class="headerlink" title="启动Hadoop"></a>启动Hadoop</h3><p> 1.解压<code>tar -xzvf hadoop-1.2.1.tar.gz</code>，进入conf/hadoop-env.sh，设置JAVA_HOME为你的JDK目录。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">export JAVA_HOME=/path/to/java/home</div></pre></td></tr></table></figure>
<p> 2.进入/hadoop-1.2.1目录，运行<code>bin\hadoop</code>,会显示hadoop的使用说明信息。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line">  Usage: hadoop [--config confdir] COMMAND</div><div class="line">  where COMMAND is one of:</div><div class="line">  namenode -format     format the DFS filesystem</div><div class="line">  secondarynamenode    run the DFS secondary namenode</div><div class="line">  namenode             run the DFS namenode</div><div class="line">  datanode             run a DFS datanode</div><div class="line">  dfsadmin             run a DFS admin client</div><div class="line">  mradmin              run a Map-Reduce admin client</div><div class="line">  fsck                 run a DFS filesystem checking utility</div><div class="line">  fs                   run a generic filesystem user client</div><div class="line">  balancer             run a cluster balancing utility</div><div class="line">  oiv                  apply the offline fsimage viewer to an fsimage</div><div class="line">  fetchdt              fetch a delegation token from the NameNode</div><div class="line">  jobtracker           run the MapReduce job Tracker node</div><div class="line">  pipes                run a Pipes job</div><div class="line">  tasktracker          run a MapReduce task Tracker node</div><div class="line">  historyserver        run job history servers as a standalone daemon</div><div class="line">  job                  manipulate MapReduce jobs</div><div class="line">  queue                get information regarding JobQueues</div><div class="line">  version              print the version</div><div class="line">  jar &lt;jar&gt;            run a jar file</div><div class="line">  distcp &lt;srcurl&gt; &lt;desturl&gt; copy file or directories recursively</div><div class="line">  distcp2 &lt;srcurl&gt; &lt;desturl&gt; DistCp version 2</div><div class="line">  archive -archiveName NAME -p &lt;parent path&gt; &lt;src&gt;* &lt;dest&gt; create a hadoop archive</div><div class="line">  classpath            prints the class path needed to get the</div><div class="line">                       Hadoop jar and the required libraries</div><div class="line">  daemonlog            get/set the log level for each daemon</div><div class="line"> or</div><div class="line">  CLASSNAME            run the class named CLASSNAME</div><div class="line">Most commands print help when invoked w/o parameters.</div></pre></td></tr></table></figure>
<p>  你可以下3中模式来启动hadoop：</p>
<ul>
<li>本地(standalone)模式</li>
<li>伪分布(Pseudo-Distributed)式</li>
<li>全分布(Full-Distributed)式</li>
</ul>
<h4 id="本地-Standalone-模式安装"><a href="#本地-Standalone-模式安装" class="headerlink" title="本地(Standalone)模式安装"></a>本地(Standalone)模式安装</h4><p>  默认情况下，Hadoop就是单机本地模式。方便调试。<br>  下面是一个样例，复制conf目录到input作为输入，找出符合正则的文件，输出到output目录</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">$ mkdir input</div><div class="line">$ cp conf/*.xml input</div><div class="line">$ bin/hadoop jar hadoop-examples-*.jar grep input output &apos;dfs[a-z.]+&apos;</div><div class="line">$ cat output/*</div></pre></td></tr></table></figure>
<h4 id="伪分布-Pseudo-Distributed-式"><a href="#伪分布-Pseudo-Distributed-式" class="headerlink" title="伪分布(Pseudo-Distributed)式"></a>伪分布(Pseudo-Distributed)式</h4><p>配置conf/core-site.xml</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></div><div class="line">     <span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.default.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://localhost:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line">     <span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></div></pre></td></tr></table></figure>
<p>配置conf/hdfs-site.xml</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></div><div class="line">     <span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line">     <span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></div></pre></td></tr></table></figure>
<p>配置conf/mapred-site.xml:</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></div><div class="line">     <span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapred.job.tracker<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>localhost:9001<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line">     <span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></div></pre></td></tr></table></figure>
<p>  格式化一个新的distributed-filesystem</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">bin/hadoop namenode -format</div></pre></td></tr></table></figure>
<p> 启动hadoop：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">bin/start-all.sh</div></pre></td></tr></table></figure>
<p>  此时可以通过WEB UI控制台来监控NameNode，JobTracker，TaskTracker</p>
<ul>
<li>NameNode - <a href="http://localhost:50070/dfshealth.jsp/" target="_blank" rel="external">http://localhost:50070/dfshealth.jsp/</a></li>
<li>JobTracker - <a href="http://localhost:50030/jobtracker.jsp/" target="_blank" rel="external">http://localhost:50030/jobtracker.jsp/</a></li>
<li><p>TaskTracker - <a href="http://localhost:50060/tasktracker.jsp" target="_blank" rel="external">http://localhost:50060/tasktracker.jsp</a></p>
<p>下面使用distributed filesystem来跑样例:<br>拷贝conf目录到hadoop的input目录，此时可以在控制台看到创建了目录。</p>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ bin/hadoop fs -put conf input</div></pre></td></tr></table></figure>
<p>运行:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ bin/hadoop jar hadoop-examples-*.jar grep input output &apos;dfs[a-z.]+&apos;</div></pre></td></tr></table></figure></p>
<p>检查结果：</p>
<p>拷贝output目录到本地并检查:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ bin/hadoop fs -get output output</div><div class="line">$ cat output/*</div></pre></td></tr></table></figure></p>
<p>或者直接在distributed filesystem查看:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ bin/hadoop fs -cat output/*</div></pre></td></tr></table></figure>
<p>使用完，可以这样来关闭：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ bin/stop-all.sh</div></pre></td></tr></table></figure>
<h4 id="Hadoop分布式部署"><a href="#Hadoop分布式部署" class="headerlink" title="Hadoop分布式部署"></a>Hadoop分布式部署</h4><p> 详见<a href="http://hadoop.apache.org/docs/r1.2.1/cluster_setup.html" target="_blank" rel="external">http://hadoop.apache.org/docs/r1.2.1/cluster_setup.html</a></p>
<hr>
<p>参考文档：<a href="http://hadoop.apache.org/docs/r1.2.1/single_node_setup.html" target="_blank" rel="external">http://hadoop.apache.org/docs/r1.2.1/single_node_setup.html</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;安装需求&quot;&gt;&lt;a href=&quot;#安装需求&quot; class=&quot;headerlink&quot; title=&quot;安装需求&quot;&gt;&lt;/a&gt;安装需求&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;Java 1.6&lt;/li&gt;
&lt;li&gt;ssh,sshd正常安装&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;确保可以ssh到localhost，并且不需要密码&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;ssh localhost&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt; 如果报错，connect to host localhost port 22:Connection refused。说明ssh-server未安装或者未启动。&lt;br&gt; 运行：&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;ps -ef | grep sshd&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;查看sshd进程是否存在，如果不存在，说明没有安装。那么进行安装。&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;sudo apt-get install openssh-server&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;然后再执行&lt;code&gt;ssh localhost&lt;/code&gt;,如果不能无密码登陆，需要做一下操作：&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;ssh-keygen -t dsa -P &amp;apos;&amp;apos; -f ~/.ssh/id_dsa&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;cat ~/.ssh/id_dsa.pub &amp;gt;&amp;gt; ~/.ssh/authorized_keys&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
      <category term="hadoop" scheme="https://www.shenyanchao.cn/categories/hadoop/"/>
    
    
      <category term="linux" scheme="https://www.shenyanchao.cn/tags/linux/"/>
    
      <category term="hadoop" scheme="https://www.shenyanchao.cn/tags/hadoop/"/>
    
  </entry>
  
  <entry>
    <title>oryx介绍</title>
    <link href="https://www.shenyanchao.cn/blog/2014/11/11/introduce-oryx/"/>
    <id>https://www.shenyanchao.cn/blog/2014/11/11/introduce-oryx/</id>
    <published>2014-11-11T11:31:00.000Z</published>
    <updated>2018-10-23T08:41:02.826Z</updated>
    
    <content type="html"><![CDATA[<p>Hadoop软件供应商Cloudera去年收购了一家总部位于伦敦的新兴企业<a href="https://github.com/myrrix/myrrix-recommender]" target="_blank" rel="external">Myrrix</a>——但在此之后无论是买家还是卖家在机器学习技术方面都开始归于沉寂。不过无论如何，Myrrix公司的技术方案加上其创始人Sean Owen可能已经足以值回票价。</p>
<p>　　Owen目前的正式头衔为数据科学部门主管，目前他正专注投身于名为<a href="https://github.com/cloudera/oryx" target="_blank" rel="external">Oryx</a>的开源机器学习项目当中。(Oryx意思是剑羚、属于非洲羚羊的一类分支，Cloudera在售的产品中则有一款名为Impala——即黑斑羚)。Oryx的开发意图在于帮助Hadoop用户构建机器学习模式并将其加以部署，这样我们就能够以实时方式查询并获取其结果——例如将其作为垃圾邮件过滤器或者推荐引擎的组成部分。在理想状态下，Oryx能够在接纳输入数据流的同时对自身进行更新。</p>
<a id="more"></a>
<p>　　Owen将此称为Hadoop传统探索性分析(即利用数据寻找可资利用的模式)与运营性分析在最佳有效点方面的区别。“一旦弄清了网站运作的既定模式，我可能会希望利用这部分资源实现其它诉求，”他解释道。“……我们应该在Hadoop当中建立一系列规模化模式，同时也对这些模式进行规模化实施。”</p>
<p>　　作为Hadoop当中实现机器学习模式创建的传统途径，<a href="http://mahout.apache.org/" target="_blank" rel="external">Apache Mahout</a>“已经走到了发展道路的尽头，”Owen指出。它还停留在第一代MapReduce所采用的纯批量处理时代，而且要求用户承担起大量工作以保证工作系统能够落实到位。“Myrrix(属于Mahout的重新编写成果)实现了我长久以来对Mahout的种种期望，”他表示，并补充称如果Mahout真的运作良好、那么Cloudera可能根本不会决定收购Myrrix。Oryx项目当中约有九成代码取向Myrrix，当然其中也包含一部分在被Cloudera收购后才添加进去的代码。</p>
<p>　　开放而且简便的推荐引擎</p>
<p>　　比起构建一套体积庞大的机器学习算法库，Owen将精力主要放在了四大要素身上——回归、分类、聚类与协同过滤(又名推荐)。Owen表示最后一项也是目前人气最高的设计特性，而且他也与Cloudera的多位客户展开合作、希望利用Oryx实现推荐系统。事实上，约有80%的Oryx用户都希望借此建立自己的推荐引擎。</p>
<p>　　将Oryx作为创建推荐系统的标准化工具为该项目带来了极高人气。当然，在Netflix、Amazon以及几乎其它任何一个知名网站上，推荐系统都属于标准配置——不过目前标准类型的数量少得惊人，而开源工具的意义就在于弥合这种欠缺。</p>
<p>　　目前的状况还称不上是什么竞赛，但确实已经有多方参与到标准推荐机制的开发工作中来。举例来说，云计算新兴企业Mortar Data目前正在寻求合作伙伴、希望通过十五家企业联手(免费)在多位知名数据科学家的帮助下建立起定制化推荐引擎。该公司的这一项目于去年正式启动，他们计划借此找到足以改进其开源推荐框架的最佳实践方案。而Expect Labs等其它企业虽然没有选择开源道路，但也同样在尝试通过人工智能API实现自动推荐效果。</p>
<p>　　还只是个项目而非产品</p>
<p>　　Owen认为Cloudera的所有客户(基本上都属于Hadoop用户)都希望能够最终获得运营性机器学习方案——而非仅仅满足于推荐引擎——Oryx则很可能成为帮助他们实现愿望的关键性工具。不过他同时强调称，“在某种程度上，Oryx仍然属于实验性项目。”</p>
<p>　　举例来说，目前Owen正将大量时间投入到Apache Spark的代码贡献工作当中，因为他打算通过重新编写Oryx使Spark成为一套足以取代MapReduce的首选处理框架。“从机器学习的角度来看，Spark拥有大量极具吸引力的特性，”他表示。“……我更愿意把自己的主要精力放在这里。”</p>
<p>　　他的决定其实代表了很多技术人员的心声。正如我们之前所说，Spark正在逐步成为下一代大数据应用程序当中的代表性方案，而包括Cloudera以及Hortonworks在内的多家企业正积极将其打造为代表Hadoop未来的重要解决方案。Cloudera公司CEO Tom Reilly将联同其它大数据企业CEO、数据科学家以及CIO共同参加今年三月的结构数据大会，探讨Hadoop平台的下一步发展方向以及Spark在其中扮演的角色、外加足以转变业务及社交模式的机器学习实际应用。</p>
<p>　　不过虽然作出这么多承诺，Owen却并不认为Oryx能在短时间之内在Cloudera的Hadoop改造版或者相关产品当中发挥实际作用。“客户需要指导、服务以及培训，而这些需求将以软件形式予以交付，”他表示。不过就目前来看：“这些距离真正实现还有很长的路要走。”</p>
<p>　　“现在要让庞大的Hadoop消费市场接受数据科学都还为时过早，”他解释道，“更不用说运营性实时机器学习方案了。</p>
<hr>
<p>参考：<br><a href="http://storage.chinabyte.com/134/12873634.shtml" target="_blank" rel="external">http://storage.chinabyte.com/134/12873634.shtml</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Hadoop软件供应商Cloudera去年收购了一家总部位于伦敦的新兴企业&lt;a href=&quot;https://github.com/myrrix/myrrix-recommender]&quot;&gt;Myrrix&lt;/a&gt;——但在此之后无论是买家还是卖家在机器学习技术方面都开始归于沉寂。不过无论如何，Myrrix公司的技术方案加上其创始人Sean Owen可能已经足以值回票价。&lt;/p&gt;
&lt;p&gt;　　Owen目前的正式头衔为数据科学部门主管，目前他正专注投身于名为&lt;a href=&quot;https://github.com/cloudera/oryx&quot;&gt;Oryx&lt;/a&gt;的开源机器学习项目当中。(Oryx意思是剑羚、属于非洲羚羊的一类分支，Cloudera在售的产品中则有一款名为Impala——即黑斑羚)。Oryx的开发意图在于帮助Hadoop用户构建机器学习模式并将其加以部署，这样我们就能够以实时方式查询并获取其结果——例如将其作为垃圾邮件过滤器或者推荐引擎的组成部分。在理想状态下，Oryx能够在接纳输入数据流的同时对自身进行更新。&lt;/p&gt;
    
    </summary>
    
      <category term="oryx" scheme="https://www.shenyanchao.cn/categories/oryx/"/>
    
    
      <category term="cloudera" scheme="https://www.shenyanchao.cn/tags/cloudera/"/>
    
      <category term="oryx" scheme="https://www.shenyanchao.cn/tags/oryx/"/>
    
      <category term="myrrix" scheme="https://www.shenyanchao.cn/tags/myrrix/"/>
    
  </entry>
  
</feed>
